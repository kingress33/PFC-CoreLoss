{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "import gc\n",
    "gc.collect()  # 強制 Python 回收記憶體"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = 250423\n",
    "target_points = 1024\n",
    "# 設定目錄\n",
    "summary_file = f\"./combine/combined_{date}.csv\"  # 你的總表\n",
    "waveform_dir = \"./waveforms\"  # 波形檔案存放處\n",
    "output_dir = f\"./processed_data/{date}\"  # 輸出目錄\n",
    "output_dir_train = f\"./processed_data/{date}/train\"\n",
    "output_dir_test = f\"./processed_data/{date}/test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(output_dir_train, exist_ok=True)\n",
    "os.makedirs(output_dir_test, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定義自適應下採樣函式\n",
    "# def adaptive_downsample_indices(signal, target_points):\n",
    "#     \"\"\"\n",
    "#     根據信號的離散差分計算累積分佈函數 (CDF)，\n",
    "#     並於 CDF 上等間距抽取 target_points 個點作為下採樣索引，\n",
    "#     使得信號變化大的區段取得較多取樣點。\n",
    "#     \"\"\"\n",
    "#     # 計算相鄰點差分與其絕對值\n",
    "#     diff_signal = np.diff(signal)\n",
    "#     abs_diff = np.abs(diff_signal)\n",
    "\n",
    "#     # 計算累積分佈函數 (CDF)\n",
    "#     cdf = np.cumsum(abs_diff)\n",
    "#     if cdf[-1] == 0:\n",
    "#         # 若信號變化極小，則採均勻取樣\n",
    "#         indices = np.linspace(0, len(signal) - 1, target_points, dtype=int)\n",
    "#         return indices\n",
    "#     cdf = cdf / cdf[-1]  # 正規化至 [0, 1]\n",
    "\n",
    "#     # 在 [0, 1] 區間均勻分布 target_points 個數值\n",
    "#     desired_vals = np.linspace(0, 1, target_points)\n",
    "#     indices = np.searchsorted(cdf, desired_vals)\n",
    "\n",
    "#     # 保證索引不超出範圍且最後一點被選取\n",
    "#     indices[indices >= len(signal)] = len(signal) - 1\n",
    "#     if indices[-1] != len(signal) - 1:\n",
    "#         indices[-1] = len(signal) - 1\n",
    "\n",
    "#     # 若平坦區段出現重複索引，保留唯一索引（依需求調整）\n",
    "#     indices = np.unique(indices)\n",
    "#     return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "處理測試點:   0%|          | 0/2688 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "處理測試點:  53%|█████▎    | 1437/2688 [00:17<00:13, 94.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "檔案 CH467160_DC_TRI_100k_20mT_N20_D0.6_ALL-3_Norm..csv 找不到，跳過...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "處理測試點: 100%|██████████| 2688/2688 [00:32<00:00, 81.61it/s] \n"
     ]
    }
   ],
   "source": [
    "# 讀取總表\n",
    "df = pd.read_csv(summary_file)\n",
    "\n",
    "# 讀取總表\n",
    "df = pd.read_csv(summary_file)\n",
    "\n",
    "# 建立空的列表來存儲機器學習格式的數據\n",
    "B_field_list = []\n",
    "H_field_list = []\n",
    "Duty_P_list = []\n",
    "Duty_N_list = []\n",
    "Turns_list = []\n",
    "Hdc_list = []\n",
    "frequency_list = []\n",
    "temperature_list = []\n",
    "volumetric_loss_list = []\n",
    "\n",
    "# 處理每一筆測試點資料\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"處理測試點\"):\n",
    "    wave_file = str(row[\"Wave_file_name\"])  # 取得對應的波形檔案名稱\n",
    "\n",
    "    if wave_file.lower() == \"none\" or wave_file.strip() == \"\":\n",
    "        continue  # 跳過無效數據\n",
    "\n",
    "    wave_path = os.path.join(waveform_dir, wave_file)  # 取得完整路徑\n",
    "\n",
    "    # 檢查檔案是否存在\n",
    "    if not os.path.exists(wave_path):\n",
    "        print(f\"檔案 {wave_file} 找不到，跳過...\")\n",
    "        continue\n",
    "\n",
    "    # 讀取 B、H 波形數據\n",
    "    wave_data = pd.read_csv(wave_path)\n",
    "\n",
    "    # 假設 CSV 檔案格式固定：\n",
    "    # H DATA(A/m) | B DATA(T) | I DATA(A) | V DATA(V)\n",
    "\n",
    "    H_wave = wave_data.iloc[:, 0].values  # H DATA(A/m)\n",
    "    B_wave = wave_data.iloc[:, 1].values  # B DATA(T)\n",
    "\n",
    "    # # 將波形資料降階成 1024 點\n",
    "    # num_points = 1024\n",
    "    # n_org = len(H_wave)\n",
    "    # if n_org != num_points:\n",
    "    #     x_old = np.linspace(0, 1, n_org)\n",
    "    #     x_new = np.linspace(0, 1, num_points)\n",
    "    #     H_wave = np.interp(x_new, x_old, H_wave)\n",
    "    #     B_wave = np.interp(x_new, x_old, B_wave)\n",
    "\n",
    "    # 存入列表\n",
    "    H_field_list.append(H_wave)\n",
    "    B_field_list.append(B_wave)\n",
    "\n",
    "    # 存入其他數據\n",
    "    frequency_list.append(row[\"Frequency(kHz)\"])\n",
    "    temperature_list.append(row[\"Temp\"])\n",
    "    volumetric_loss_list.append(row[\"Core_Loss(Pcv(kW/m3))\"])\n",
    "    Duty_P_list.append(row[\"Duty_P\"])\n",
    "    Duty_N_list.append(row[\"Duty_N\"])\n",
    "    Hdc_list.append(row[\"Hdc(A/m)\"])\n",
    "    Turns_list.append(row[\"N1\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全部合併一個大檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "數據拆分完成，已存入 ./processed_data/250423 資料夾\n"
     ]
    }
   ],
   "source": [
    "# 轉換為 DataFrame，並讓 **每行代表一筆測試點**\n",
    "H_field_df = pd.DataFrame(H_field_list)\n",
    "B_field_df = pd.DataFrame(B_field_list)\n",
    "frequency_df = pd.DataFrame(frequency_list)\n",
    "temperature_df = pd.DataFrame(temperature_list)\n",
    "Duty_P_df = pd.DataFrame(Duty_P_list)\n",
    "Duty_N_df = pd.DataFrame(Duty_N_list)\n",
    "Turns_df = pd.DataFrame(Turns_list)\n",
    "Hdc_df = pd.DataFrame(Hdc_list)\n",
    "volumetric_loss_df = pd.DataFrame(volumetric_loss_list)\n",
    "\n",
    "# 儲存 CSV\n",
    "H_field_df.to_csv(os.path.join(output_dir, \"H_Field.csv\"),\n",
    "                  index=False,\n",
    "                  header=False)\n",
    "B_field_df.to_csv(os.path.join(output_dir, \"B_Field.csv\"),\n",
    "                  index=False,\n",
    "                  header=False)\n",
    "frequency_df.to_csv(os.path.join(output_dir, \"Frequency.csv\"),\n",
    "                    index=False,\n",
    "                    header=False)\n",
    "temperature_df.to_csv(os.path.join(output_dir, \"Temperature.csv\"),\n",
    "                      index=False,\n",
    "                      header=False)\n",
    "Duty_P_df.to_csv(os.path.join(output_dir, \"Duty_P.csv\"),\n",
    "                 index=False,\n",
    "                 header=False)\n",
    "Duty_N_df.to_csv(os.path.join(output_dir, \"Duty_N.csv\"),\n",
    "                 index=False,\n",
    "                 header=False)\n",
    "Turns_df.to_csv(os.path.join(output_dir, \"Turns.csv\"),\n",
    "                index=False,\n",
    "                header=False)\n",
    "Hdc_df.to_csv(os.path.join(output_dir, \"Hdc.csv\"), index=False, header=False)\n",
    "volumetric_loss_df.to_csv(os.path.join(output_dir, \"Volumetric_Loss.csv\"),\n",
    "                          index=False,\n",
    "                          header=False)\n",
    "\n",
    "print(f\"數據拆分完成，已存入 ./processed_data/{date} 資料夾\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分成Train 跟 Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "數據拆分完成，已存入 ./processed_data/250423/train 與 ./processed_data/250423/test 資料夾\n"
     ]
    }
   ],
   "source": [
    "# 合併成一個大的DataFrame\n",
    "full_data = pd.DataFrame({\n",
    "    'H_field': H_field_list,\n",
    "    'B_field': B_field_list,\n",
    "    'Frequency': frequency_list,\n",
    "    'Temperature': temperature_list,\n",
    "    'Duty_P': Duty_P_list,\n",
    "    'Duty_N': Duty_N_list,\n",
    "    'Turns': Turns_list,\n",
    "    'Hdc': Hdc_list,\n",
    "    'Volumetric_Loss': volumetric_loss_list\n",
    "})\n",
    "\n",
    "# 隨機打亂並分割數據 (80%訓練，20%測試)\n",
    "train_df, test_df = train_test_split(full_data,\n",
    "                                     test_size=0.1,\n",
    "                                     random_state=42,\n",
    "                                     shuffle=True)\n",
    "\n",
    "# 儲存資料\n",
    "for dataset, output_dir in zip([train_df, test_df],\n",
    "                               [output_dir_train, output_dir_test]):\n",
    "    pd.DataFrame(dataset['H_field'].tolist()).to_csv(os.path.join(\n",
    "        output_dir, \"H_Field.csv\"),\n",
    "                                                     index=False,\n",
    "                                                     header=False)\n",
    "    pd.DataFrame(dataset['B_field'].tolist()).to_csv(os.path.join(\n",
    "        output_dir, \"B_Field.csv\"),\n",
    "                                                     index=False,\n",
    "                                                     header=False)\n",
    "    dataset[['Frequency']].to_csv(os.path.join(output_dir, \"Frequency.csv\"),\n",
    "                                  index=False,\n",
    "                                  header=False)\n",
    "    dataset[['Temperature']].to_csv(os.path.join(output_dir,\n",
    "                                                 \"Temperature.csv\"),\n",
    "                                    index=False,\n",
    "                                    header=False)\n",
    "    dataset[['Duty_P']].to_csv(os.path.join(output_dir, \"Duty_P.csv\"),\n",
    "                               index=False,\n",
    "                               header=False)\n",
    "    dataset[['Duty_N']].to_csv(os.path.join(output_dir, \"Duty_N.csv\"),\n",
    "                               index=False,\n",
    "                               header=False)\n",
    "    dataset[['Turns']].to_csv(os.path.join(output_dir, \"Turns.csv\"),\n",
    "                              index=False,\n",
    "                              header=False)\n",
    "    dataset[['Hdc']].to_csv(os.path.join(output_dir, \"Hdc.csv\"),\n",
    "                            index=False,\n",
    "                            header=False)\n",
    "    dataset[['Volumetric_Loss']].to_csv(os.path.join(output_dir,\n",
    "                                                     \"Volumetric_Loss.csv\"),\n",
    "                                        index=False,\n",
    "                                        header=False)\n",
    "\n",
    "print(\n",
    "    f\"數據拆分完成，已存入 ./processed_data/{date}/train 與 ./processed_data/{date}/test 資料夾\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
