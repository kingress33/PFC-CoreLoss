{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6IdDUEup6490"
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import os, json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "material = \"CH467160\"\n",
    "way = \"uesed_for_PFC_test1\"\n",
    "noted = \"使用一般FNＮ訓練\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5LA1kae860Q"
   },
   "outputs": [],
   "source": [
    "# Define model structures and functions\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 load_pretrained: bool = False,\n",
    "                 pretrained_model_path: str = \"None\"):\n",
    "        super(Net, self).__init__()\n",
    "        # Define a fully connected layers model with three inputs (frequency, flux density, duty ratio) and one output (power loss).\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "        if load_pretrained and pretrained_model_path is not None:\n",
    "            self.load_pretrained_model(pretrained_model_path)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def load_pretrained_model(self, path):\n",
    "        # 讀取並設置預訓練模型的權重\n",
    "        pretrained_dict = torch.load(path)\n",
    "        # 獲取當前模型的狀態字典\n",
    "        model_dict = self.state_dict()\n",
    "        # 更新當前模型的狀態字典中的權重\n",
    "        model_dict.update(pretrained_dict)\n",
    "        # 更新模型字典以匹配預訓練模型的字典\n",
    "        self.load_state_dict(model_dict)\n",
    "        print('Model is load')\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-6sTpOoAUWZ"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "# Output\n",
    "# output_sd_path = f'.\\output\\Model.sd'\n",
    "# output_pred_path = f'.\\output\\Loss_pred.csv'\n",
    "# output_meas_path = f'.\\output\\Loss_meas.csv'\n",
    "\n",
    "\n",
    "def get_dataset(material, folder, base_path=\"./Data/\"):\n",
    "\n",
    "    B_file_path = f\"{base_path}{material}/{folder}/Bmax.csv\"\n",
    "    Freq_file_path = f\"{base_path}{material}/{folder}/Frequency.csv\"\n",
    "    Duty_P_file_path = f\"{base_path}{material}/{folder}/Duty_P.csv\"\n",
    "    Duty_N_file_path = f\"{base_path}{material}/{folder}/Duty_N.csv\"\n",
    "    Dc_file_path = f\"{base_path}{material}/{folder}/Hdc.csv\"\n",
    "    Temp_file_path = f\"{base_path}{material}/{folder}/Temperature.csv\"\n",
    "    Turns_file_path = f\"{base_path}{material}/{folder}/Turns.csv\"\n",
    "    Power_file_path = f\"{base_path}{material}/{folder}/Volumetric_Loss.csv\"\n",
    "\n",
    "    B = read_csv(B_file_path)\n",
    "    Freq = read_csv(Freq_file_path)\n",
    "    Duty_P = read_csv(Duty_P_file_path)\n",
    "    Duty_N = read_csv(Duty_N_file_path)\n",
    "    Temp = read_csv(Temp_file_path)\n",
    "    Dc = read_csv(Dc_file_path)\n",
    "    Power = read_csv(Power_file_path)\n",
    "    Turns = read_csv(Turns_file_path)\n",
    "\n",
    "    # Compute labels\n",
    "    # There's approximalely an exponential relationship between Loss-Freq and Loss-Flux.\n",
    "    # Using logarithm may help to improve the training.\n",
    "    tensors = {\n",
    "        \"B\": B,\n",
    "        \"Freq\": Freq,\n",
    "        \"Duty_P\": Duty_P,\n",
    "        \"Duty_N\": Duty_N,\n",
    "        \"Temp\": Temp,\n",
    "        \"Turns\": Turns,\n",
    "        \"Dc\": Dc,\n",
    "        \"Power\": Power,\n",
    "    }\n",
    "\n",
    "    for name, arr in tensors.items():\n",
    "        print(f\"{name:<6} → {tuple(arr.shape)}\")\n",
    "\n",
    "    # Reshape data\n",
    "    B = torch.from_numpy(B).float().view(-1, 1)\n",
    "    Freq = torch.from_numpy(Freq).view(-1, 1)\n",
    "    Duty_P = torch.from_numpy(Duty_P).view(-1, 1)\n",
    "    Duty_N = torch.from_numpy(Duty_N).view(-1, 1)\n",
    "    Temp = torch.from_numpy(Temp).view(-1, 1)\n",
    "    Turns = torch.from_numpy(Turns).view(-1, 1)\n",
    "    Dc = torch.from_numpy(Dc).view(-1, 1)\n",
    "    Power = Power.reshape((-1, 1))\n",
    "\n",
    "    # Normalize\n",
    "    eps = 1e-8  # 防 0 除\n",
    "    B_mean, B_std = torch.mean(B), torch.std(B) + eps\n",
    "    F_mean, F_std = torch.mean(Freq), torch.std(Freq) + eps\n",
    "    T_mean, T_std = torch.mean(Temp), torch.std(Temp) + eps\n",
    "    N_mean, N_std = torch.mean(Turns), torch.std(Turns) + eps\n",
    "    Dc_mean, Dc_std = torch.mean(Dc), torch.std(Dc) + eps\n",
    "\n",
    "    B = (B - B_mean) / B_std\n",
    "    Freq = (Freq - F_mean) / F_std\n",
    "    Temp = (Temp - T_mean) / T_std\n",
    "    Turns = (Turns - N_mean) / N_std\n",
    "    Dc = (Dc - Dc_mean) / Dc_std\n",
    "\n",
    "    print(np.shape(B))\n",
    "    print(np.shape(Freq))\n",
    "    print(np.shape(Duty_P))\n",
    "    print(np.shape(Duty_N))\n",
    "    print(np.shape(Temp))\n",
    "    print(np.shape(Turns))\n",
    "    print(np.shape(Dc))\n",
    "    print(np.shape(Power))\n",
    "\n",
    "    temp = np.concatenate((B, Freq, Duty_P, Duty_N, Temp, Dc, Turns), axis=1)\n",
    "\n",
    "    in_tensors = torch.from_numpy(temp).view(-1, 7)\n",
    "    out_tensors = torch.from_numpy(Power).view(-1, 1)\n",
    "\n",
    "    return torch.utils.data.TensorDataset(in_tensors, out_tensors)\n",
    "\n",
    "\n",
    "def read_csv(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', newline='', encoding='utf-8-sig') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for row in csv_reader:\n",
    "            values = [float(value) for value in row]\n",
    "            data.append(values)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLogger:\n",
    "\n",
    "    def __init__(self, result_dir, exp_name, config):\n",
    "        self.result_dir = result_dir\n",
    "        os.makedirs(self.result_dir, exist_ok=True)\n",
    "        with open(os.path.join(self.result_dir, \"config.json\"), \"w\") as f:\n",
    "            json.dump(config, f, indent=2, ensure_ascii=False)\n",
    "        self.metrics = {}\n",
    "\n",
    "    def log_metrics(self, **kwargs):\n",
    "        # 將所有要紀錄的值放進字典\n",
    "        self.metrics.update(kwargs)\n",
    "\n",
    "    def save(self):\n",
    "        # 儲存 metrics.json\n",
    "        with open(os.path.join(self.result_dir, \"metrics.json\"), \"w\") as f:\n",
    "            json.dump(self.metrics, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HRhRbOaM_ry"
   },
   "source": [
    "# Training and Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9ndXYTq9b9R",
    "outputId": "84e6702a-7d3d-44e1-9f51-8fc49be282c7"
   },
   "outputs": [],
   "source": [
    "# Config the model training\n",
    "\n",
    "\n",
    "def main():\n",
    "    # === 1. 設定隨機種子 & 超參數 ===\n",
    "    # Reproducibility\n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "    torch.manual_seed(1)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # Hyperparameters\n",
    "    NUM_EPOCH = 2000\n",
    "    BATCH_SIZE = 512\n",
    "    DECAY_EPOCH = 200\n",
    "    DECAY_RATIO = 0.5\n",
    "    LR_INI = 0.005\n",
    "    best_loss = math.inf\n",
    "    early_stop_count = 0\n",
    "    early_stop = 500\n",
    "    # Select GPU as default device\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    # === 2. 準備資料與模型 ===\n",
    "    # Load dataset\n",
    "    dataset_train = get_dataset(material, \"train\")\n",
    "    train_size = int(0.8 * len(dataset_train))\n",
    "    valid_size = len(dataset_train) - train_size\n",
    "    train_dataset, valid_dataset = torch.utils.data.random_split(\n",
    "        dataset_train, [train_size, valid_size])\n",
    "\n",
    "    dataset_test = get_dataset(material, \"test\")\n",
    "    test_dataset = dataset_test\n",
    "\n",
    "    print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size: {len(valid_dataset)}\")\n",
    "    print(f\"Test dataset size: {len(dataset_test)}\")\n",
    "\n",
    "    kwargs = {\n",
    "        'num_workers': 0,\n",
    "        'pin_memory': True,\n",
    "        'pin_memory_device': \"cuda\"\n",
    "    }\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                               **kwargs)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=False,\n",
    "                                               **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              shuffle=False,\n",
    "                                              **kwargs)\n",
    "\n",
    "    # Setup network\n",
    "    net = Net().double().to(device)\n",
    "\n",
    "    # Log the number of parameters\n",
    "    print(\"Number of parameters: \", count_parameters(net))\n",
    "\n",
    "    # Setup optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LR_INI)\n",
    "\n",
    "    # === 3. 建立 Logger 並儲存超參數 ===\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    result_dir = f\"./results/{material}_{timestamp}\"\n",
    "    config = {\n",
    "        \"NUM_EPOCH\": NUM_EPOCH,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE,\n",
    "        \"LR_INI\": LR_INI,\n",
    "        \"DECAY_EPOCH\": DECAY_EPOCH,\n",
    "        \"DECAY_RATIO\": DECAY_RATIO,\n",
    "        \"EARLY_STOP\": early_stop,\n",
    "    }\n",
    "    logger = SimpleLogger(result_dir, exp_name=material, config=config)\n",
    "    output_sd_path = os.path.join(result_dir, \"best_model.sd\")\n",
    "    output_pred_path = os.path.join(result_dir, \"pred.csv\")\n",
    "    output_meas_path = os.path.join(result_dir, \"meas.csv\")\n",
    "\n",
    "    # === 4. 開始計時 ===\n",
    "    t_start = time.perf_counter()\n",
    "\n",
    "    # === 5. 訓練迴圈 ===\n",
    "\n",
    "    print(\"=== Start Train  ===\")\n",
    "    print(r\"\"\"\n",
    "    (\\_/)\n",
    "    ( •_•)\n",
    "    / > 我想畢業QQQQQQQQQQQQ\n",
    "    \"\"\")\n",
    "    # Train the network\n",
    "    best_loss = math.inf\n",
    "    early_stop_count = 0\n",
    "    epoch_times = []\n",
    "\n",
    "    for epoch_i in range(NUM_EPOCH):\n",
    "\n",
    "        # Train for one epoch\n",
    "        t0 = time.perf_counter()\n",
    "        epoch_train_loss = 0\n",
    "        net.train()\n",
    "        optimizer.param_groups[0]['lr'] = LR_INI * (DECAY_RATIO**(\n",
    "            0 + epoch_i // DECAY_EPOCH))\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs.to(device))\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "        # Compute Validation Loss\n",
    "        with torch.no_grad():\n",
    "            epoch_valid_loss = 0\n",
    "            for inputs, labels in valid_loader:\n",
    "                outputs = net(inputs.to(device))\n",
    "                loss = criterion(outputs, labels.to(device))\n",
    "\n",
    "                epoch_valid_loss += loss.item()\n",
    "\n",
    "        if (epoch_i + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch_i+1:2d} \"\n",
    "                  f\"Train {epoch_train_loss / len(train_dataset) * 1e5:.5f} \"\n",
    "                  f\"Valid {epoch_valid_loss / len(valid_dataset) * 1e5:.5f}\")\n",
    "\n",
    "        # Early stop\n",
    "        epoch_valid_loss = epoch_valid_loss / len(valid_dataset) * 1e5\n",
    "        if epoch_valid_loss < best_loss:\n",
    "            best_loss = epoch_valid_loss\n",
    "            torch.save(net.state_dict(), output_sd_path)\n",
    "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "            print(f\"Early stop count: {early_stop_count} / {early_stop}\")\n",
    "\n",
    "        if early_stop_count >= early_stop:\n",
    "            print('Model is not improving, so we halt the training session.')\n",
    "            break\n",
    "\n",
    "        te = time.perf_counter() - t0\n",
    "        epoch_times.append(te)\n",
    "        print(f\"---\")\n",
    "        print(f\"Epoch {epoch_i+1:2d} finished in {te:.2f} seconds\")\n",
    "\n",
    "    # === 6. 訓練結束，計算總時間 ===\n",
    "    elapsed_sec = time.perf_counter() - t_start\n",
    "    print(\"Training finished! Model is saved!\")\n",
    "\n",
    "    # === 7. 載入最佳模型並做最終測試 ===\n",
    "    # Load the best model  ====================================================\n",
    "    net.load_state_dict(torch.load(output_sd_path))\n",
    "    print(\"Best model is load to test\")\n",
    "    # =====================================================================\n",
    "\n",
    "    # Test the model\n",
    "    print(\"=== Start Test ===\")\n",
    "    net.load_state_dict(torch.load(output_sd_path))\n",
    "    net.eval()\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            preds = net(inputs.to(device))\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    y_pred = torch.cat(all_preds, dim=0)  # shape = (N, 1)\n",
    "    y_meas = torch.cat(all_labels, dim=0)  # shape = (N, 1)\n",
    "\n",
    "    yy_pred = 10**(y_pred.numpy())\n",
    "    yy_meas = 10**(y_meas.numpy())\n",
    "\n",
    "    # ========= 相對誤差計算 =========\n",
    "    Error_re = np.abs(yy_pred - yy_meas) / np.abs(yy_meas) * 100  # [%]\n",
    "    avg_err = np.mean(Error_re)\n",
    "    pct95 = np.percentile(Error_re, 95)\n",
    "    max_err = np.max(Error_re)\n",
    "\n",
    "    print(\n",
    "        f\"Test Loss : {F.mse_loss(y_meas, y_pred).item() * 1e5 / len(test_dataset):.5f}\"\n",
    "    )\n",
    "    print(f\"AVG Error               : {avg_err:.6f} %\")\n",
    "    print(f\"95-Percentile Error     : {pct95:.6f} %\")\n",
    "    print(f\"MAX Error               : {max_err:.6f} %\")\n",
    "\n",
    "    # ========= Logger 紀錄 =========\n",
    "    logger.log_metrics(test_loss=float(\n",
    "        F.mse_loss(y_meas, y_pred).item() * 1e5 / len(test_dataset)),\n",
    "                       avg_error=float(avg_err),\n",
    "                       error_95pct=float(pct95),\n",
    "                       error_max=float(max_err),\n",
    "                       training_secs=elapsed_sec)\n",
    "    logger.save()  # 會在 result_dir 產生 metrics.json\n",
    "\n",
    "    # ========= Relative Error 直方圖 =========\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(Error_re, bins=100, density=True, alpha=0.9)\n",
    "\n",
    "    # 虛線 + 標籤\n",
    "    plt.axvline(avg_err, linestyle='--', linewidth=1.5)\n",
    "    plt.text(avg_err + 0.5,\n",
    "             plt.ylim()[1] * 0.9,\n",
    "             f\"Avg = {avg_err:.2f}%\",\n",
    "             fontsize=12)\n",
    "\n",
    "    plt.axvline(pct95, linestyle='--', linewidth=1.5)\n",
    "    plt.text(pct95 + 0.5,\n",
    "             plt.ylim()[1] * 0.7,\n",
    "             f\"95-Prct = {pct95:.2f}%\",\n",
    "             fontsize=12)\n",
    "\n",
    "    plt.axvline(max_err, linestyle='--', linewidth=1.5)\n",
    "    plt.text(max_err - 10,\n",
    "             plt.ylim()[1] * 0.3,\n",
    "             f\"Max = {max_err:.2f}%\",\n",
    "             fontsize=12,\n",
    "             ha='right')\n",
    "\n",
    "    plt.title(f\"Error Distribution for {material}\", fontsize=16)\n",
    "    plt.xlabel(\"Relative Error [%]\")\n",
    "    plt.ylabel(\"Ratio of Data Points\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_30324\\655514905.py:52: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  B = (B - torch.mean(B)) / torch.std(B).numpy()\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_30324\\655514905.py:53: RuntimeWarning: invalid value encountered in divide\n",
      "  Freq = (Freq - torch.mean(Freq)) / torch.std(Freq).numpy()\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_30324\\655514905.py:53: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  Freq = (Freq - torch.mean(Freq)) / torch.std(Freq).numpy()\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_30324\\655514905.py:54: RuntimeWarning: invalid value encountered in divide\n",
      "  Temp = (Temp - torch.mean(Temp)) / torch.std(Temp).numpy()\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_30324\\655514905.py:54: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  Temp = (Temp - torch.mean(Temp)) / torch.std(Temp).numpy()\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_30324\\655514905.py:55: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  Turns = (Turns - torch.mean(Turns)) / torch.std(Turns).numpy()\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_30324\\655514905.py:56: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  Dc = (Dc - torch.mean(Dc)) / torch.std(Dc).numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2418, 1])\n",
      "torch.Size([2418, 1])\n",
      "torch.Size([2418, 1])\n",
      "torch.Size([2418, 1])\n",
      "torch.Size([2418, 1])\n",
      "torch.Size([2418, 1])\n",
      "torch.Size([2418, 1])\n",
      "(2418, 1)\n",
      "torch.Size([269, 1])\n",
      "torch.Size([269, 1])\n",
      "torch.Size([269, 1])\n",
      "torch.Size([269, 1])\n",
      "torch.Size([269, 1])\n",
      "torch.Size([269, 1])\n",
      "torch.Size([269, 1])\n",
      "(269, 1)\n",
      "Train dataset size: 1934\n",
      "Validation dataset size: 484\n",
      "Test dataset size: 269\n",
      "Number of parameters:  11265\n",
      "=== Start Train  ===\n",
      "\n",
      "    (\\_/)\n",
      "    ( •_•)\n",
      "    / > 我想畢業QQQQQQQQQQQQ\n",
      "    \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (512x7 and 6x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 112\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m    111\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 112\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m    114\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[15], line 24\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (512x7 and 6x128)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
