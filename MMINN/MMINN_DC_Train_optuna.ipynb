{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Package & Hyperparameter Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸…ç©ºæ‰€æœ‰è®Šæ•¸\n",
    "%reset -f\n",
    "# # å¼·åˆ¶ Python å›æ”¶è¨˜æ†¶é«”\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook ç’°å¢ƒï¼Œè·³éåˆ‡æ›ç›®éŒ„\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "try:\n",
    "    os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "except NameError:\n",
    "    print(\"Notebook ç’°å¢ƒï¼Œè·³éåˆ‡æ›ç›®éŒ„\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Unified Hyperparameter Configuration\n",
    "class Config:\n",
    "    SEED = 1\n",
    "    NUM_EPOCHS = 300\n",
    "    BATCH_SIZE = 128\n",
    "    LEARNING_RATE = 0.002  #è«–æ–‡æä¾›\n",
    "    LR_SCHEDULER_GAMMA = 0.99  #è«–æ–‡æä¾›\n",
    "    DECAY_EPOCH = 200\n",
    "    EARLY_STOPPING_PATIENCE = 150\n",
    "    HIDDEN_SIZE = 30\n",
    "    OPERATOR_SIZE = 30\n",
    "    MAXOUT_H = 1\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(Config.SEED)\n",
    "np.random.seed(Config.SEED)\n",
    "torch.manual_seed(Config.SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Material & Number of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "material = \"CH467160\"\n",
    "fix_way = \"uesed_for_PFC_test\"\n",
    "note = \"optuna_search_1\"\n",
    "note_detail = \"æ‰¾ BATCH_SIZEã€å­¸ç¿’ç‡ã€éš±è—å±¤å¤§å°ã€é‹ç®—å­å¤§å°çš„æœ€ä½³çµ„åˆ\"\n",
    "downsample = 1024\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "result_dir = os.path.join(\"results\",\n",
    "                          f\"{timestamp}_{fix_way}_{material}_{note}\")\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# å®šç¾©ä¿å­˜æ¨¡å‹çš„è·¯å¾‘\n",
    "model_save_dir = result_dir\n",
    "model_save_path = os.path.join(\n",
    "    model_save_dir, f\"{material}_{fix_way}_{note}_{timestamp}.pt\")  # å®šç¾©æ¨¡å‹ä¿å­˜æª”å\n",
    "\n",
    "# Select device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing and data loader generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Preprocess data into a data loader\n",
    "def get_dataloader(data_B,\n",
    "                   data_F,\n",
    "                   data_T,\n",
    "                   data_H,\n",
    "                   data_N,\n",
    "                   data_Hdc,\n",
    "                   data_Duty_P,\n",
    "                   data_Duty_N,\n",
    "                   data_Pcv,\n",
    "                   global_B_max,\n",
    "                   global_H_max,\n",
    "                   batch_size,\n",
    "                   operator_size,\n",
    "                   n_init=16):\n",
    "\n",
    "    # Data pre-process\n",
    "\n",
    "    # â”€â”€ 0. å…¨åŸŸè¨­å®š/é™éšè¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    eps = 1e-8  # é˜²æ­¢é™¤ä»¥ 0\n",
    "    if downsample == 1024:\n",
    "        seq_length = 1024  # å–®ç­†æ³¢å½¢é»æ•¸ (ä¸å† down-sample)\n",
    "    else:\n",
    "        seq_length = downsample\n",
    "        cols = np.linspace(0, 1023, seq_length, dtype=int)\n",
    "        data_B = data_B[:, cols]\n",
    "        data_H = data_H[:, cols]\n",
    "\n",
    "    # â”€â”€ 1. æ³¢å½¢æ‹¼æ¥ (è£œ n_init é»ä½œåˆå§‹ç£åŒ–) â”€â”€â”€â”€\n",
    "    data_length = seq_length + n_init\n",
    "    data_B = np.hstack((data_B[:, -n_init:], data_B))  # (batch, data_length)\n",
    "    data_H = np.hstack((data_H[:, -n_init:], data_H))\n",
    "\n",
    "    # print(\"B shape:\", data_B.shape)\n",
    "    # print(\"H shape:\", data_H.shape)\n",
    "    # print(\"F shape:\", data_F.shape)\n",
    "    # print(\"T shape:\", data_T.shape)\n",
    "    # print(\"Hdc shape:\", data_Hdc.shape)\n",
    "    # print(\"N shape:\", data_N.shape)\n",
    "    # print(\"Duty Pos shape:\", data_Duty_P.shape)\n",
    "    # print(\"Duty Neg shape:\", data_Duty_N.shape)\n",
    "    # print(\"Pcv shape:\", data_Pcv.shape)\n",
    "\n",
    "    # â”€â”€ 2. è½‰æˆ Tensor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    B = torch.from_numpy(data_B).view(-1, data_length, 1).float()  # (B,N,1)\n",
    "    H = torch.from_numpy(data_H).view(-1, data_length, 1).float()\n",
    "    F = torch.log10(torch.from_numpy(data_F).view(-1, 1).float())  # ç´”é‡\n",
    "    T = torch.from_numpy(data_T).view(-1, 1).float()\n",
    "    Hdc = torch.from_numpy(data_Hdc).view(-1, 1).float()\n",
    "    N = torch.from_numpy(data_N).view(-1, 1).float()\n",
    "    Duty_P = torch.from_numpy(data_Duty_P).view(-1, 1).float()\n",
    "    Duty_N = torch.from_numpy(data_Duty_N).view(-1, 1).float()\n",
    "    Pcv = torch.log10(torch.from_numpy(data_Pcv).view(-1, 1).float())\n",
    "\n",
    "    # â”€â”€ 3. æ¯ç­†æ¨£æœ¬å„è‡ªæ‰¾æœ€å¤§å¹…å€¼ (per-profile scale) â”€\n",
    "    # scale_B = torch.max(torch.abs(B), dim=1,\n",
    "    #                     keepdim=True).values + eps  # (B,1,1)\n",
    "    # scale_H = torch.max(torch.abs(H), dim=1, keepdim=True).values + eps\n",
    "\n",
    "    # â”€â”€ 4. å…ˆè¨ˆç®—å°æ•¸ï¼Œå†é™¤ä»¥ scale_B â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    dB = torch.diff(B, dim=1, prepend=B[:, :1])\n",
    "    dB_dt = dB * (seq_length * F.view(-1, 1, 1))  # çœŸå¯¦æ–œç‡\n",
    "    # d2B = torch.diff(dB, dim=1, prepend=dB[:, :1])\n",
    "    # d2B_dt = d2B * (seq_length * F.view(-1, 1, 1))\n",
    "\n",
    "    # â”€â”€ 5. å½¢æˆæ¨¡å‹è¼¸å…¥ (å·²ç¶“ç¸®æ”¾åˆ° [-1,1]) â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # in_B = B / scale_B\n",
    "    # out_H = H / scale_H  # é æ¸¬ç›®æ¨™\n",
    "    # in_dB_dt = dB_dt / scale_B\n",
    "    # å¾ŒçºŒç™¼ç¾d2Bç„¡æ”¹å–„æº–ç¢ºåº¦(å¯èƒ½è¦å¤šæ³¢å½¢ç¨®é¡æ‰æœ‰æ•ˆå¹«åŠ©)ï¼Œå…ˆä»¥è¼¸å…¥0ä»£å…¥\n",
    "    # in_d2B_dt = d2B_dt / scale_B\n",
    "\n",
    "    # *ä¿®æ­£æˆä½¿ç”¨å…¨åŸŸæœ€å¤§å¹…å€¼ (ver.250806)\n",
    "    in_B = B / global_B_max\n",
    "    out_H = H / global_H_max\n",
    "    in_dB_dt = dB_dt / global_B_max\n",
    "    in_d2B_dt = torch.zeros_like(in_dB_dt)\n",
    "\n",
    "    # â”€â”€ 6. ç´”é‡ç‰¹å¾µï¼šè¨ˆç®— z-score åƒæ•¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def safe_mean_std(tensor, eps=1e-8):\n",
    "        m = torch.mean(tensor).item()\n",
    "        s = torch.std(tensor).item()\n",
    "        return [m, 1.0 if s < eps else s]\n",
    "\n",
    "    #  Compute normalization parameters (å‡å€¼ & æ¨™æº–å·®)**\n",
    "    norm = [\n",
    "        safe_mean_std(F),\n",
    "        safe_mean_std(T),\n",
    "        safe_mean_std(Hdc),\n",
    "        safe_mean_std(N),\n",
    "        safe_mean_std(Pcv)\n",
    "    ]\n",
    "\n",
    "    # # ç”¨ä¾†åštestå›ºå®šæ¨™æº–åŒ–åƒæ•¸çš„\n",
    "    # print(\"0.F, 1.T, 2.Hdc, 3.N, 4.Pcv\")\n",
    "    # material_name = f\"{material}\"\n",
    "    # print(f'\"{material_name}\": [')\n",
    "    # for param in norm:\n",
    "    #     print(f\"    {param},\")\n",
    "    # print(\"]\")\n",
    "\n",
    "    # Data Normalization\n",
    "    in_F = (F - norm[0][0]) / norm[0][1]  # F\n",
    "    in_T = (T - norm[1][0]) / norm[1][1]  # T\n",
    "    in_Hdc = (Hdc - norm[2][0]) / norm[2][1]  # Hdc\n",
    "    in_N = (N - norm[3][0]) / norm[3][1]  # N\n",
    "    in_Pcv = (Pcv - norm[4][0]) / norm[4][1]  # Pcv\n",
    "    in_Duty_P = Duty_P  # Duty Pos\n",
    "    in_Duty_N = Duty_N  # Duty Neg\n",
    "\n",
    "    # #   â†’ æ–¹ä¾¿æ¨è«–å¾©åŸï¼Œä¿ç•™ scale_B, scale_H ç•¶ä½œé¡å¤–ç´”é‡\n",
    "    # aux_features = torch.cat(\n",
    "    #     (in_F, in_T, in_Hdc, in_N, in_Duty_P, in_Duty_N, in_Pcv,\n",
    "    #      scale_B.squeeze(-1), scale_H.squeeze(-1)),\n",
    "    #     dim=1)\n",
    "\n",
    "    # â”€â”€ 7. ç”¢ç”Ÿåˆå§‹ Preisach operator ç‹€æ…‹ s0 â”€â”€â”€â”€â”€â”€\n",
    "    max_B, _ = torch.max(in_B, dim=1)\n",
    "    min_B, _ = torch.min(in_B, dim=1)\n",
    "    # s0 = get_operator_init(in_B[:, 0] - dB[:, 0] / scale_B.squeeze(-1),\n",
    "    #                        dB / scale_B, max_B, min_B)\n",
    "\n",
    "    s0 = get_operator_init(in_B[:, 0] - dB[:, 0] / global_B_max.squeeze(-1),\n",
    "                           dB / global_B_max,\n",
    "                           max_B,\n",
    "                           min_B,\n",
    "                           operator_size=operator_size)\n",
    "\n",
    "    # â”€â”€ 8. çµ„åˆ Dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # wave_inputs = torch.cat(\n",
    "    #     (\n",
    "    #         in_B,  # â‘  B\n",
    "    #         dB / scale_B,  # â‘¡ Î”B\n",
    "    #         in_dB_dt,  # â‘¢ dB/dt\n",
    "    #         in_d2B_dt),\n",
    "    #     dim=2)  # â‘£ dÂ²B/dtÂ²   â†’ (B,L,4)\n",
    "\n",
    "    # amps = torch.cat((scale_B.squeeze(-1), scale_H.squeeze(-1)),\n",
    "    #                 dim=1)  # (B,2)\n",
    "\n",
    "    wave_inputs = torch.cat(\n",
    "        (\n",
    "            in_B,  # â‘  B\n",
    "            dB / global_B_max,  # â‘¡ Î”B\n",
    "            in_dB_dt,  # â‘¢ dB/dt\n",
    "            in_d2B_dt),\n",
    "        dim=2)  # â‘£ dÂ²B/dtÂ²   â†’ (B,L,4)\n",
    "\n",
    "    aux_features = torch.cat((in_F, in_T, in_Hdc, in_N, in_Duty_P, in_Duty_N),\n",
    "                             dim=1)  # (B,4)\n",
    "\n",
    "    amp_B = torch.full((len(B), 1), global_B_max, dtype=torch.float32)\n",
    "    amp_H = torch.full((len(B), 1), global_H_max, dtype=torch.float32)\n",
    "    amps = torch.cat((amp_B, amp_H), dim=1)  # ä»çµ¦ RNN2 ç”¨\n",
    "\n",
    "    # é€™è£¡æŠŠ Pcvï¼ˆå·² z-scoreï¼‰å–®ç¨æ‹¿å‡ºä¾†ç•¶å¦ä¸€å€‹ label\n",
    "    target_Pcv = in_Pcv  # (B,1)\n",
    "\n",
    "    full_dataset = torch.utils.data.TensorDataset(\n",
    "        wave_inputs,  # 0  â†’ æ¨¡å‹åºåˆ—è¼¸å…¥\n",
    "        aux_features,  # 1  â†’ 4 å€‹ç´”é‡\n",
    "        amps,  # 2  â†’ å¹…å€¼ä¿‚æ•¸\n",
    "        s0,  # 3  â†’ Preisach åˆå§‹ç‹€æ…‹\n",
    "        out_H,  # 4  â†’ ç›®æ¨™ H  (å·² scale_H)\n",
    "        target_Pcv)  # 5  â†’ ç›®æ¨™ Pcv (å·² z-score)\n",
    "\n",
    "    # â”€â”€ 9. Train / Valid split & DataLoader â”€â”€â”€â”€â”€â”€â”€\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    valid_size = len(full_dataset) - train_size\n",
    "    train_set, valid_set = torch.utils.data.random_split(\n",
    "        full_dataset, [train_size, valid_size],\n",
    "        generator=torch.Generator().manual_seed(Config.SEED))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=0,\n",
    "                                               pin_memory=True,\n",
    "                                               collate_fn=filter_input)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_set,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0,\n",
    "                                               pin_memory=True,\n",
    "                                               collate_fn=filter_input)\n",
    "\n",
    "    return train_loader, valid_loader, norm\n",
    "\n",
    "\n",
    "# %% Predict the operator state at t0\n",
    "def get_operator_init(B1,\n",
    "                      dB,\n",
    "                      Bmax,\n",
    "                      Bmin,\n",
    "                      max_out_H=Config.MAXOUT_H,\n",
    "                      operator_size=Config.OPERATOR_SIZE):\n",
    "    \"\"\"Compute the initial state of hysteresis operators\"\"\"\n",
    "    s0 = torch.zeros((dB.shape[0], operator_size))\n",
    "    operator_thre = torch.from_numpy(\n",
    "        np.linspace(max_out_H / operator_size, max_out_H,\n",
    "                    operator_size)).view(1, -1)\n",
    "\n",
    "    for i in range(dB.shape[0]):\n",
    "        for j in range(operator_size):\n",
    "            r = operator_thre[0, j]\n",
    "            if (Bmax[i] >= r) or (Bmin[i] <= -r):\n",
    "                if dB[i, 0] >= 0:\n",
    "                    if B1[i] > Bmin[i] + 2 * r:\n",
    "                        s0[i, j] = r\n",
    "                    else:\n",
    "                        s0[i, j] = B1[i] - (r + Bmin[i])\n",
    "                else:\n",
    "                    if B1[i] < Bmax[i] - 2 * r:\n",
    "                        s0[i, j] = -r\n",
    "                    else:\n",
    "                        s0[i, j] = B1[i] + (r - Bmax[i])\n",
    "    return s0\n",
    "\n",
    "\n",
    "def filter_input(batch):\n",
    "    inputs, features, amps, s0, target_H, target_Pcv = zip(*batch)\n",
    "\n",
    "    inputs = torch.stack(inputs)\n",
    "    features = torch.stack(features)\n",
    "    amps = torch.stack(amps)\n",
    "    s0 = torch.stack(s0)\n",
    "    target_H = torch.stack(target_H)[:, -downsample:, :]  # ä¿ç•™å…¨é•·\n",
    "    target_Pcv = torch.stack(target_Pcv)  # (B,1)\n",
    "\n",
    "    return inputs, features, amps, s0, target_H, target_Pcv\n",
    "\n",
    "\n",
    "# æº«åº¦é »ç‡ä¸è®ŠåŠ å…¥å¾®å°çš„ epsilon\n",
    "def safe_mean_std(tensor, eps=1e-8):\n",
    "    m_tensor = torch.mean(tensor)  # é‚„æ˜¯ Tensor\n",
    "    s_tensor = torch.std(tensor)  # é‚„æ˜¯ Tensor\n",
    "\n",
    "    m_val = m_tensor.item()  # ç¬¬ä¸€æ¬¡è½‰æˆ float\n",
    "    s_val = s_tensor.item()\n",
    "    if s_val < eps:\n",
    "        s_val = 1.0\n",
    "    return [m_val, s_val]  # ç›´æ¥å›å‚³ float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Magnetization mechansim-determined neural network\n",
    "\"\"\"\n",
    "    Parameters:\n",
    "    - hidden_size: number of eddy current slices (RNN neuron)\n",
    "    - operator_size: number of operators\n",
    "    - input_size: number of inputs (1.B 2.dB 3.dB/dt 4.d2B/dt)\n",
    "    - var_size: number of supplenmentary variables (1.F 2.T 3.Hdc 4.N 5.Duty_P 6.Duty_N)        \n",
    "    - output_size: number of outputs (1.H)\n",
    "    \n",
    "    åªå…ˆæŠŠd2B/dtè€ƒé‡åœ¨EddyCellè£¡é¢\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MMINet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 norm,\n",
    "                 hidden_size,\n",
    "                 operator_size,\n",
    "                 input_size=4,\n",
    "                 var_size=6,\n",
    "                 output_size=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.var_size = var_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.operator_size = operator_size\n",
    "        self.norm = norm\n",
    "\n",
    "        self.rnn1 = StopOperatorCell(self.operator_size)\n",
    "        self.dnn1 = nn.Linear(self.operator_size + self.var_size, 1)\n",
    "        # var_size (F T Hdc N Duty_P Duty_N ) + 3 (B, dB/dt, d2B/dt)\n",
    "        self.rnn2 = EddyCell(var_size + 3, self.hidden_size, output_size)\n",
    "        self.dnn2 = nn.Linear(self.hidden_size, 1)\n",
    "        self.rnn2_hx = None\n",
    "        # var_size=6: 1.F 2.T 3.Hdc 4.N 5.Duty_P 6.Duty_N + 1 for P_prelim\n",
    "        self.loss_mlp = nn.Sequential(nn.Linear(self.var_size + 1, 128),\n",
    "                                      nn.ReLU(), nn.Linear(128, 64), nn.ReLU(),\n",
    "                                      nn.Linear(64, 32), nn.ReLU(),\n",
    "                                      nn.Linear(32, 1))\n",
    "\n",
    "    def forward(self, x, var, amps, s0, n_init=16):\n",
    "        \"\"\"\n",
    "        Parameters: \n",
    "        - x(batch,seq,input_size): Input features (1.B, 2.dB, 3.dB/dt)  \n",
    "        - var(batch,var_size): Supplementary inputs (1.F 2.T 3.Hdc 4.N 5.Duty_P 6.Duty_N) \n",
    "        - s0(batch,1): Operator inital states\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)  # Batch size\n",
    "        seq_size = x.size(1)  # Ser\n",
    "        self.rnn1_hx = s0\n",
    "\n",
    "        # !Initialize DNN2 input (1.B 2.dB/dt 3.d2B)\n",
    "        # x2 = torch.cat((x[:, :, 0:1], x[:, :, 2:3]), dim=2)\n",
    "        # !é¸å– B, dB/dt, d2B/dt\n",
    "        x2 = torch.cat((x[:, :, 0:1], x[:, :, 2:4]), dim=2)\n",
    "\n",
    "        for t in range(seq_size):\n",
    "            # RNN1 input (dB,state)\n",
    "            self.rnn1_hx = self.rnn1(x[:, t, 1:2], self.rnn1_hx)\n",
    "\n",
    "            # DNN1 input (rnn1_hx,F,T,Hdc,N)\n",
    "            dnn1_in = torch.cat((self.rnn1_hx, var), dim=1)\n",
    "\n",
    "            # H hysteresis prediction\n",
    "            H_hyst_pred = self.dnn1(dnn1_in)\n",
    "\n",
    "            # DNN2 input (B,dB/dt,T,F)\n",
    "            rnn2_in = torch.cat((x2[:, t, :], var), dim=1)\n",
    "\n",
    "            # Initialize second rnn state\n",
    "            if t == 0:\n",
    "                H_eddy_init = x[:, t, 0:1] - H_hyst_pred\n",
    "                buffer = x.new_ones(x.size(0), self.hidden_size)\n",
    "                self.rnn2_hx = Variable(\n",
    "                    (buffer / torch.sum(self.dnn2.weight, dim=1)) *\n",
    "                    H_eddy_init)\n",
    "\n",
    "            #rnn2_in = torch.cat((rnn2_in,H_hyst_pred),dim=1)\n",
    "            self.rnn2_hx = self.rnn2(rnn2_in, self.rnn2_hx)\n",
    "\n",
    "            # H eddy prediction\n",
    "            H_eddy = self.dnn2(self.rnn2_hx)\n",
    "\n",
    "            # H total\n",
    "            H_total = (H_hyst_pred + H_eddy).view(batch_size, 1,\n",
    "                                                  self.output_size)\n",
    "            if t == 0:\n",
    "                output = H_total\n",
    "            else:\n",
    "                output = torch.cat((output, H_total), dim=1)\n",
    "\n",
    "        H = (output[:, n_init:, :])\n",
    "\n",
    "        amp_B = amps[:, 0:1]  # (batch,1)\n",
    "        amp_H = amps[:, 1:2]  # (batch,1)\n",
    "        B_amp = x[:, n_init:, 0:1] * amp_B.unsqueeze(1)\n",
    "        H_amp = output[:, n_init:, :] * amp_H.unsqueeze(1)\n",
    "        P_prelim = torch.trapz(H_amp, B_amp, axis=1) * (10**(\n",
    "            var[:, 0:1] * self.norm[0][1] + self.norm[0][0]))\n",
    "        Pcv_log = torch.log10(P_prelim.clamp(min=1e-12))\n",
    "        Pcv = (Pcv_log - self.norm[4][0]) / self.norm[4][1]\n",
    "        mlp_input = torch.cat((var, Pcv), dim=1)  # (batch, 5)\n",
    "        s = self.loss_mlp(mlp_input)\n",
    "        Pcv_mlp = Pcv + s\n",
    "\n",
    "        return H, Pcv_mlp\n",
    "\n",
    "\n",
    "class StopOperatorCell():\n",
    "\n",
    "    def __init__(self, operator_size):\n",
    "        self.operator_thre = torch.from_numpy(\n",
    "            np.linspace(Config.MAXOUT_H / operator_size, Config.MAXOUT_H,\n",
    "                        operator_size)).view(1, -1)\n",
    "\n",
    "    def sslu(self, X):\n",
    "        a = torch.ones_like(X)\n",
    "        return torch.max(-a, torch.min(a, X))\n",
    "\n",
    "    def __call__(self, dB, state):\n",
    "        r = self.operator_thre.to(dB.device)\n",
    "        output = self.sslu((dB + state) / r) * r\n",
    "        return output.float()\n",
    "\n",
    "\n",
    "class EddyCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.x2h = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        hidden = self.x2h(x) + self.h2h(hidden)\n",
    "        hidden = torch.sigmoid(hidden)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def load_dataset(material, base_path=\"./Data/\"):\n",
    "\n",
    "    in_file1 = f\"{base_path}{material}/train/B_Field.csv\"\n",
    "    in_file2 = f\"{base_path}{material}/train/Frequency.csv\"\n",
    "    in_file3 = f\"{base_path}{material}/train/Temperature.csv\"\n",
    "    in_file4 = f\"{base_path}{material}/train/H_Field.csv\"\n",
    "    in_file5 = f\"{base_path}{material}/train/Volumetric_Loss.csv\"\n",
    "    in_file6 = f\"{base_path}{material}/train/Hdc.csv\"\n",
    "    in_file7 = f\"{base_path}{material}/train/Turns.csv\"\n",
    "    in_file8 = f\"{base_path}{material}/train/Duty_P.csv\"\n",
    "    in_file9 = f\"{base_path}{material}/train/Duty_N.csv\"\n",
    "\n",
    "    data_B = np.genfromtxt(in_file1, delimiter=',')  # N x 1024\n",
    "    data_F = np.genfromtxt(in_file2, delimiter=',')  # N x 1\n",
    "    data_T = np.genfromtxt(in_file3, delimiter=',')  # N x 1\n",
    "    data_H = np.genfromtxt(in_file4, delimiter=',')  # N x 1024\n",
    "    data_Pcv = np.genfromtxt(in_file5, delimiter=',')  # N x 1\n",
    "    data_Hdc = np.genfromtxt(in_file6, delimiter=',')  # N x 1\n",
    "    data_N = np.genfromtxt(in_file7, delimiter=',')  # N x 1\n",
    "    data_Duty_P = np.genfromtxt(in_file8, delimiter=',')  # N x 1\n",
    "    data_Duty_N = np.genfromtxt(in_file9, delimiter=',')  # N x 1\n",
    "\n",
    "    return data_B, data_F, data_T, data_H, data_Pcv, data_Hdc, data_N, data_Duty_P, data_Duty_N\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­£åœ¨é€²è¡Œä¸€æ¬¡æ€§æ•¸æ“šè¼‰å…¥ï¼Œè«‹ç¨å€™...\n",
      "âœ… æ•¸æ“šè¼‰å…¥å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ æ­£åœ¨é€²è¡Œä¸€æ¬¡æ€§æ•¸æ“šè¼‰å…¥ï¼Œè«‹ç¨å€™...\")\n",
    "\n",
    "# --- 1. è¼‰å…¥åŸå§‹æ•¸æ“š ---\n",
    "# é€™äº›è®Šæ•¸æœƒè®Šæˆå…¨åŸŸè®Šæ•¸ï¼Œæ‰€æœ‰å‡½å¼éƒ½èƒ½è®€å–\n",
    "data_B, data_F, data_T, data_H, data_Pcv, data_Hdc, data_N, data_Duty_P, data_Duty_N = load_dataset(\n",
    "    material)\n",
    "GLOBAL_B_MAX = np.abs(data_B).max()\n",
    "GLOBAL_H_MAX = np.abs(data_H).max()\n",
    "\n",
    "print(\"âœ… æ•¸æ“šè¼‰å…¥å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate clamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp_learning_rate(optimizer, min_lr=1e-5):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group['lr'] < min_lr:\n",
    "            param_group['lr'] = min_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caculate tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nrmse(y_pred, y_true, eps=1e-9):\n",
    "    \"\"\"\n",
    "    è¨ˆç®— H-field çš„æ­¸ä¸€åŒ–å‡æ–¹æ ¹èª¤å·® (Normalized Root Mean Square Error)ã€‚\n",
    "    é€™å€‹æŒ‡æ¨™ç”¨ä¾†è©•ä¼°æ³¢å½¢ã€Œå½¢ç‹€ã€çš„ç›¸ä¼¼åº¦ï¼Œæ•¸å€¼è¶Šä½è¶Šå¥½ã€‚\n",
    "    \"\"\"\n",
    "    # y_pred, y_true çš„ shape éƒ½æ˜¯ (batch, seq_len, 1)\n",
    "    error = torch.sqrt(torch.mean((y_pred - y_true)**2, dim=1))  # (batch, 1)\n",
    "    norm = torch.sqrt(torch.mean(y_true**2, dim=1))  # (batch, 1)\n",
    "\n",
    "    # è¨ˆç®—å¹³å‡ NRMSE ä¸¦è½‰ç‚ºç™¾åˆ†æ¯”\n",
    "    return torch.mean(error / (norm + eps)).item() * 100\n",
    "\n",
    "\n",
    "def calculate_mape(y_pred, y_true, norm_params, eps=1e-9):\n",
    "    \"\"\"\n",
    "    è¨ˆç®— Pcv çš„å¹³å‡çµ•å°ç™¾åˆ†æ¯”èª¤å·® (Mean Absolute Percentage Error)ã€‚\n",
    "    é€™å€‹æŒ‡æ¨™ç›´æ¥åæ˜ äº†æè€—é æ¸¬å€¼çš„ã€Œç™¾åˆ†æ¯”èª¤å·®ã€ï¼Œæ•¸å€¼è¶Šä½è¶Šå¥½ã€‚\n",
    "    \"\"\"\n",
    "    # y_pred, y_true çš„ shape éƒ½æ˜¯ (batch, 1)ï¼Œä¸¦ä¸”æ˜¯ç¶“é log10 å’Œ z-score è™•ç†çš„\n",
    "    # æ­¥é©Ÿ 1: å°‡ z-score é‚„åŸæˆ log10(Pcv)\n",
    "    # norm_params[4] æ˜¯ Pcv çš„ [mean, std]\n",
    "    pred_log = y_pred * norm_params[4][1] + norm_params[4][0]\n",
    "    true_log = y_true * norm_params[4][1] + norm_params[4][0]\n",
    "\n",
    "    # æ­¥é©Ÿ 2: å°‡ log10(Pcv) é‚„åŸæˆçœŸå¯¦çš„ Pcv\n",
    "    pred_real = 10**pred_log\n",
    "    true_real = 10**true_log\n",
    "\n",
    "    # æ­¥é©Ÿ 3: è¨ˆç®— MAPE ä¸¦è½‰ç‚ºç™¾åˆ†æ¯”\n",
    "    return torch.mean(torch.abs(\n",
    "        (pred_real - true_real) / (true_real + eps))).item() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trial, config_dict, norm, train_loader, valid_loader,\n",
    "                trial_model_save_path):\n",
    "\n",
    "    # --- å¾å‚³å…¥çš„ config_dict å–å¾—é€™æ¬¡ trial çš„è¶…åƒæ•¸ ---\n",
    "    LEARNING_RATE = config_dict['LEARNING_RATE']\n",
    "    LR_SCHEDULER_GAMMA = config_dict['LR_SCHEDULER_GAMMA']\n",
    "    HIDDEN_SIZE = config_dict['HIDDEN_SIZE']\n",
    "    OPERATOR_SIZE = config_dict['OPERATOR_SIZE']\n",
    "\n",
    "    # --- åˆå§‹åŒ–æ¨¡å‹èˆ‡å„ªåŒ–å™¨ (ä½¿ç”¨ trial å»ºè­°çš„åƒæ•¸) ---\n",
    "    model = MMINet(norm, hidden_size=HIDDEN_SIZE,\n",
    "                   operator_size=OPERATOR_SIZE).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "        optimizer, gamma=LR_SCHEDULER_GAMMA)\n",
    "\n",
    "    criterion_H = nn.MSELoss()\n",
    "    criterion_Pcv = nn.MSELoss()\n",
    "\n",
    "    # --- åˆå§‹åŒ–æœ€ä½³æŒ‡æ¨™è¨˜éŒ„ ---\n",
    "    best_nrmse_H = float('inf')\n",
    "    best_mape_Pcv = float('inf')\n",
    "\n",
    "    # --- Early Stopping è¨­å®š ---\n",
    "    wait_H = wait_Pcv = 0\n",
    "    PATIENCE_H = Config.EARLY_STOPPING_PATIENCE\n",
    "    PATIENCE_PCV = Config.EARLY_STOPPING_PATIENCE\n",
    "    joint_phase = False\n",
    "    MIN_DELTA = 1e-6\n",
    "\n",
    "    # # Loss è¨˜éŒ„\n",
    "    # best_val_loss = float('inf')\n",
    "    # best_val_loss_Pcv = float('inf')\n",
    "    # best_val_loss_H = float('inf')\n",
    "\n",
    "    for epoch in range(Config.NUM_EPOCHS):\n",
    "\n",
    "        print(f\"[Trial {trial.number}] Epoch {epoch+1}/{Config.NUM_EPOCHS}\")\n",
    "        alpha = (epoch + 1) / Config.NUM_EPOCHS\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for inputs, features, amps, s0, target_H, target_Pcv in train_loader:\n",
    "\n",
    "            inputs, features, amps, s0, target_H, target_Pcv = inputs.to(\n",
    "                device), features.to(device), amps.to(device), s0.to(\n",
    "                    device), target_H.to(device), target_Pcv.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                outputs_H, outputs_Pcv = model(inputs, features, amps,\n",
    "                                               s0)  # æ¨¡å‹çš„è¼¸å‡º\n",
    "                loss_H = criterion_H(outputs_H, target_H)  # ä½¿ç”¨çœŸå¯¦çš„ H(t) è¨ˆç®—æå¤±\n",
    "                loss_Pcv = criterion_Pcv(outputs_Pcv, target_Pcv)\n",
    "                loss = (1 - alpha) * loss_H + alpha * loss_Pcv\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        scheduler.step()  # scheduler æ›´æ–°\n",
    "        clamp_learning_rate(optimizer)  # é¿å…learning rateæ‰åˆ° 0\n",
    "\n",
    "        # ------------------------------vaildation------------------------------\n",
    "        model.eval()\n",
    "        all_val_nrmse = []\n",
    "        all_val_mape = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, features, amps, s0, target_H, target_Pcv in valid_loader:\n",
    "                inputs, features, amps, s0, target_H, target_Pcv = (\n",
    "                    d.to(device) for d in\n",
    "                    [inputs, features, amps, s0, target_H, target_Pcv])\n",
    "                outputs_H, outputs_Pcv = model(inputs, features, amps, s0)\n",
    "                all_val_nrmse.append(calculate_nrmse(outputs_H, target_H))\n",
    "                all_val_mape.append(\n",
    "                    calculate_mape(outputs_Pcv, target_Pcv, model.norm))\n",
    "\n",
    "        avg_val_nrmse_H = np.mean(all_val_nrmse)\n",
    "        avg_val_mape_Pcv = np.mean(all_val_mape)\n",
    "\n",
    "        scheduler.step()\n",
    "        clamp_learning_rate(optimizer)\n",
    "\n",
    "        # --- æ›´æ–°æœ€ä½³æŒ‡æ¨™ä¸¦åŸ·è¡Œ Early Stopping (ç¾åœ¨æœƒå­˜åˆ°ç¨ç«‹è·¯å¾‘) ---\n",
    "        if not joint_phase:\n",
    "            if avg_val_nrmse_H < best_nrmse_H:\n",
    "                best_nrmse_H = avg_val_nrmse_H\n",
    "                best_mape_Pcv = avg_val_mape_Pcv\n",
    "                best_epoch = epoch + 1\n",
    "                wait_H = 0\n",
    "                torch.save(model.state_dict(), model_save_path)  # <-- ä½¿ç”¨å‚³å…¥çš„è·¯å¾‘\n",
    "            else:\n",
    "                wait_H += 1\n",
    "            if wait_H >= PATIENCE_H:\n",
    "                joint_phase = True\n",
    "                wait_Pcv = 0\n",
    "        else:\n",
    "            if avg_val_mape_Pcv < best_mape_Pcv and avg_val_nrmse_H < best_nrmse_H * 1.10:\n",
    "                best_nrmse_H = avg_val_nrmse_H\n",
    "                best_mape_Pcv = avg_val_mape_Pcv\n",
    "                best_epoch = epoch + 1\n",
    "                wait_Pcv = 0\n",
    "                torch.save(model.state_dict(), model_save_path)  # <-- ä½¿ç”¨å‚³å…¥çš„è·¯å¾‘\n",
    "            else:\n",
    "                wait_Pcv += 1\n",
    "            if wait_Pcv >= PATIENCE_PCV:\n",
    "                print(\n",
    "                    f\"  - Trial {trial.number}: Early stopping at epoch {epoch+1}.\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "    # --- å‘ Optuna å ±å‘Šé€²åº¦ï¼Œä»¥ä¾¿å‰ªæ ---\n",
    "    # é€™è£¡æˆ‘å€‘ç”¨æ¯”è¼ƒç©©å®šçš„ val_loss_Pcv ä¾†å›å ±ï¼Œå› ç‚º MAPE è¨ˆç®—è¼ƒæ…¢\n",
    "        trial.report(avg_val_mape_Pcv, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # --- è¨“ç·´è¿´åœˆçµæŸå¾Œï¼Œå›å‚³åŒ…å«å¤šå€‹è³‡è¨Šçš„ dictionary ---\n",
    "    result = {\n",
    "        \"mape\": best_mape_Pcv,\n",
    "        \"nrmse\": best_nrmse_H,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"model_path\": model_save_path\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    print(f\"ğŸš€ Starting Trial {trial.number}...\")\n",
    "\n",
    "    # --- 1. å®šç¾©è¶…åƒæ•¸çš„æœå°‹ç©ºé–“ ---\n",
    "    config_dict = {\n",
    "        'LEARNING_RATE':\n",
    "        trial.suggest_float(\n",
    "            'LEARNING_RATE',\n",
    "            [0.01, 0.05, 0.1, 0.2],\n",
    "        ),\n",
    "        'BATCH_SIZE':\n",
    "        trial.suggest_categorical('BATCH_SIZE', [64, 128, 256]),\n",
    "        'HIDDEN_SIZE':\n",
    "        trial.suggest_categorical('HIDDEN_SIZE', [20, 30, 40]),\n",
    "        'OPERATOR_SIZE':\n",
    "        trial.suggest_categorical('OPERATOR_SIZE', [20, 30, 40]),\n",
    "        'LR_SCHEDULER_GAMMA':\n",
    "        trial.suggest_float('LR_SCHEDULER_GAMMA', 0.95, 0.99, step=0.01),\n",
    "    }\n",
    "    print(f\"  - Suggested Params: {config_dict}\")\n",
    "\n",
    "    # --- 2. ç‚ºé€™æ¬¡ trial ç”¢ç”Ÿç¨ç«‹çš„æ¨¡å‹å„²å­˜è·¯å¾‘ ---\n",
    "    trial_model_save_path = os.path.join(\n",
    "        result_dir, f\"trial_{trial.number}_best_model.pt\")\n",
    "\n",
    "    # --- 3. æº–å‚™æ•¸æ“š (åªé‡æ–°å»ºç«‹ DataLoader) ---\n",
    "    # é€™æ˜¯å¿…è¦çš„ï¼Œå› ç‚º batch_size å’Œ operator_size åœ¨æ¯å€‹ trial éƒ½å¯èƒ½ä¸åŒ\n",
    "    train_loader, valid_loader, norm_params = get_dataloader(\n",
    "        data_B,\n",
    "        data_F,\n",
    "        data_T,\n",
    "        data_H,\n",
    "        data_N,\n",
    "        data_Hdc,\n",
    "        data_Duty_P,\n",
    "        data_Duty_N,\n",
    "        data_Pcv,\n",
    "        GLOBAL_B_MAX,\n",
    "        GLOBAL_H_MAX,\n",
    "        batch_size=config_dict['BATCH_SIZE'],\n",
    "        operator_size=config_dict['OPERATOR_SIZE'])\n",
    "\n",
    "    # --- 4. åŸ·è¡Œè¨“ç·´ä¸¦å–å¾—çµæœ ---\n",
    "    try:\n",
    "        result_dict = train_model(trial, config_dict, norm_params,\n",
    "                                  train_loader, valid_loader,\n",
    "                                  trial_model_save_path)\n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e):\n",
    "            print(f\"  - ğŸ’¥ Trial {trial.number} failed with OOM. Pruning.\")\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # --- 5. å°‡é¡å¤–è³‡è¨Šè¨˜éŒ„åˆ° trial ä¸­ ---\n",
    "    trial.set_user_attr(\"best_nrmse_H\", result_dict[\"nrmse\"])\n",
    "    trial.set_user_attr(\"model_path\", result_dict[\"model_path\"])\n",
    "    trial.set_user_attr(\"best_epoch\", result_dict[\"best_epoch\"])\n",
    "\n",
    "    final_mape = result_dict[\"mape\"]\n",
    "    print(f\"âœ”ï¸ Finished Trial {trial.number} with MAPE: {final_mape:.4f}%\")\n",
    "\n",
    "    # --- 6. å›å‚³æœ€çµ‚ç›®æ¨™å€¼ ---\n",
    "    return final_mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Find!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # å»ºç«‹ Study ç‰©ä»¶\n",
    "    study_name = f\"{timestamp}_{material}_{note}\"\n",
    "    storage_name = f\"sqlite:///{study_name}.db\"\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage_name,\n",
    "        direction='minimize',  # ç›®æ¨™æ˜¯æœ€å°åŒ– MAPE\n",
    "        pruner=optuna.pruners.MedianPruner(),\n",
    "        load_if_exists=True)\n",
    "\n",
    "    # é–‹å§‹å„ªåŒ–\n",
    "    print(f\"ğŸš€ Starting Optuna optimization for {study_name}...\")\n",
    "    study.optimize(objective, n_trials=100, n_jobs=1, show_progress_bar=True)\n",
    "\n",
    "    # è¼¸å‡ºæœ€ä½³çµæœ\n",
    "    print(\"\\n\\nğŸ‰ Optimization Finished! ğŸ‰\")\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"ğŸ† Best Trial: #{best_trial.number}\")\n",
    "    print(f\"  - ğŸ“ˆ Best MAPE: {best_trial.value:.4f}%\")\n",
    "    # æª¢æŸ¥ user_attrs æ˜¯å¦å­˜åœ¨\n",
    "    if 'best_nrmse_H' in best_trial.user_attrs:\n",
    "        print(\n",
    "            f\"  - ğŸ“ Corresponding NRMSE: {best_trial.user_attrs['best_nrmse_H']:.4f}%\"\n",
    "        )\n",
    "        print(f\"  -  Epoch: {best_trial.user_attrs['best_epoch']}\")\n",
    "        print(f\"  - ğŸ’¾ Best Model Path: {best_trial.user_attrs['model_path']}\")\n",
    "\n",
    "    print(\"\\n  - Optimal Hyperparameters:\")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(f\"    - {key}: {value}\")\n",
    "\n",
    "    # ä¿å­˜æœ€ä½³åƒæ•¸\n",
    "    best_params_file = os.path.join(result_dir, \"best_params.json\")\n",
    "    with open(best_params_file, \"w\") as f:\n",
    "        json.dump(best_trial.params, f, indent=4)\n",
    "    print(f\"\\nâœ… Best parameters saved to {best_params_file}\")\n",
    "\n",
    "    # å•Ÿå‹• Dashboard (åœ¨ terminal ä¸­åŸ·è¡Œ)\n",
    "    print(\n",
    "        \"\\nTo visualize results, run the following command in your terminal:\")\n",
    "    print(f\"optuna-dashboard {storage_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 22:19:35,082] A new study created in RDB with name: 20250807_CH467160_optuna_search_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Optuna optimization for 20250807_CH467160_optuna_search_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Trial 0...\n",
      "  - Suggested Params: {'LEARNING_RATE': 0.004326563970077996, 'BATCH_SIZE': 64, 'HIDDEN_SIZE': 20, 'OPERATOR_SIZE': 30, 'LR_SCHEDULER_GAMMA': 0.9575449313432121}\n",
      "[Trial 0] Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 0] Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 1 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 0] Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 2 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 0] Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 3 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 0] Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 4 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 0] Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\optuna\\trial\\_trial.py:501: UserWarning: The reported value is ignored because this `step` 5 is already reported.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 0] Epoch 7/100\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
