{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step0: Import Package & Hyperparameter Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清空所有變數\n",
    "%reset -f\n",
    "# # 強制 Python 回收記憶體\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 環境，跳過切換目錄\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "try:\n",
    "    os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "except NameError:\n",
    "    print(\"Notebook 環境，跳過切換目錄\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Unified Hyperparameter Configuration\n",
    "class Config:\n",
    "    SEED = 1\n",
    "    NUM_EPOCHS = 100\n",
    "    BATCH_SIZE = 256\n",
    "    LEARNING_RATE = 0.002  #論文提供\n",
    "    LR_SCHEDULER_GAMMA = 0.99  #論文提供\n",
    "    DECAY_EPOCH = 200\n",
    "    EARLY_STOPPING_PATIENCE = 150\n",
    "    HIDDEN_SIZE = 30\n",
    "    OPERATOR_SIZE = 30\n",
    "    MAXOUT_H = 1\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(Config.SEED)\n",
    "np.random.seed(Config.SEED)\n",
    "torch.manual_seed(Config.SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Material & Number of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "material = \"CH467160\"\n",
    "fix_way = \"uesed_for_PFC_test4\"\n",
    "note = \"optuna_search_1.3\"\n",
    "note_detail = \"找 BATCH_SIZE、學習率、隱藏層大小、運算子大小的最佳組合\"\n",
    "downsample = 1024\n",
    "save_figure = False\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# 訓練情況況\n",
    "plot_interval = 150\n",
    "train_show_sample = 1\n",
    "\n",
    "result_dir = os.path.join(\"results\",\n",
    "                          f\"{timestamp}_{fix_way}_{material}_{note}\")\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# 定義保存模型的路徑\n",
    "model_save_dir = result_dir\n",
    "model_save_path = os.path.join(\n",
    "    model_save_dir, f\"{material}_{fix_way}_{note}_{timestamp}.pt\")  # 定義模型保存檔名\n",
    "\n",
    "figure_save_base_path = result_dir\n",
    "\n",
    "# Select device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Data processing and data loader generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Preprocess data into a data loader\n",
    "def get_dataloader(data_B,\n",
    "                   data_F,\n",
    "                   data_T,\n",
    "                   data_H,\n",
    "                   data_N,\n",
    "                   data_Hdc,\n",
    "                   data_Duty_P,\n",
    "                   data_Duty_N,\n",
    "                   data_Pcv,\n",
    "                   global_B_max,\n",
    "                   global_H_max,\n",
    "                   batch_size,\n",
    "                   operator_size,\n",
    "                   n_init=16):\n",
    "\n",
    "    # Data pre-process\n",
    "\n",
    "    # ── 0. 全域設定/降階設定 ──────────────────────────────\n",
    "    eps = 1e-8  # 防止除以 0\n",
    "    if downsample == 1024:\n",
    "        seq_length = 1024  # 單筆波形點數 (不再 down-sample)\n",
    "    else:\n",
    "        seq_length = downsample\n",
    "        cols = np.linspace(0, 1023, seq_length, dtype=int)\n",
    "        data_B = data_B[:, cols]\n",
    "        data_H = data_H[:, cols]\n",
    "\n",
    "    # ── 1. 波形拼接 (補 n_init 點作初始磁化) ────\n",
    "    data_length = seq_length + n_init\n",
    "    data_B = np.hstack((data_B[:, -n_init:], data_B))  # (batch, data_length)\n",
    "    data_H = np.hstack((data_H[:, -n_init:], data_H))\n",
    "\n",
    "    # print(\"B shape:\", data_B.shape)\n",
    "    # print(\"H shape:\", data_H.shape)\n",
    "    # print(\"F shape:\", data_F.shape)\n",
    "    # print(\"T shape:\", data_T.shape)\n",
    "    # print(\"Hdc shape:\", data_Hdc.shape)\n",
    "    # print(\"N shape:\", data_N.shape)\n",
    "    # print(\"Duty Pos shape:\", data_Duty_P.shape)\n",
    "    # print(\"Duty Neg shape:\", data_Duty_N.shape)\n",
    "    # print(\"Pcv shape:\", data_Pcv.shape)\n",
    "\n",
    "    # ── 2. 轉成 Tensor ───────────────────────────\n",
    "    B = torch.from_numpy(data_B).view(-1, data_length, 1).float()  # (B,N,1)\n",
    "    H = torch.from_numpy(data_H).view(-1, data_length, 1).float()\n",
    "    F = torch.log10(torch.from_numpy(data_F).view(-1, 1).float())  # 純量\n",
    "    T = torch.from_numpy(data_T).view(-1, 1).float()\n",
    "    Hdc = torch.from_numpy(data_Hdc).view(-1, 1).float()\n",
    "    N = torch.from_numpy(data_N).view(-1, 1).float()\n",
    "    Duty_P = torch.from_numpy(data_Duty_P).view(-1, 1).float()\n",
    "    Duty_N = torch.from_numpy(data_Duty_N).view(-1, 1).float()\n",
    "    Pcv = torch.log10(torch.from_numpy(data_Pcv).view(-1, 1).float())\n",
    "\n",
    "    # ── 3. 每筆樣本各自找最大幅值 (per-profile scale) ─\n",
    "    # scale_B = torch.max(torch.abs(B), dim=1,\n",
    "    #                     keepdim=True).values + eps  # (B,1,1)\n",
    "    # scale_H = torch.max(torch.abs(H), dim=1, keepdim=True).values + eps\n",
    "\n",
    "    # ── 4. 先計算導數，再除以 scale_B ─────────────\n",
    "    dB = torch.diff(B, dim=1, prepend=B[:, :1])\n",
    "    dB_dt = dB * (seq_length * F.view(-1, 1, 1))  # 真實斜率\n",
    "    # d2B = torch.diff(dB, dim=1, prepend=dB[:, :1])\n",
    "    # d2B_dt = d2B * (seq_length * F.view(-1, 1, 1))\n",
    "\n",
    "    # ── 5. 形成模型輸入 (已經縮放到 [-1,1]) ────────\n",
    "    # in_B = B / scale_B\n",
    "    # out_H = H / scale_H  # 預測目標\n",
    "    # in_dB_dt = dB_dt / scale_B\n",
    "    # 後續發現d2B無改善準確度(可能要多波形種類才有效幫助)，先以輸入0代入\n",
    "    # in_d2B_dt = d2B_dt / scale_B\n",
    "\n",
    "    # *修正成使用全域最大幅值 (ver.250806)\n",
    "    in_B = B / global_B_max\n",
    "    out_H = H / global_H_max\n",
    "    in_dB_dt = dB_dt / global_B_max\n",
    "    in_d2B_dt = torch.zeros_like(in_dB_dt)\n",
    "\n",
    "    # ── 6. 純量特徵：計算 z-score 參數 ─────────────\n",
    "    def safe_mean_std(tensor, eps=1e-8):\n",
    "        m = torch.mean(tensor).item()\n",
    "        s = torch.std(tensor).item()\n",
    "        return [m, 1.0 if s < eps else s]\n",
    "\n",
    "    #  Compute normalization parameters (均值 & 標準差)**\n",
    "    norm = [\n",
    "        safe_mean_std(F),\n",
    "        safe_mean_std(T),\n",
    "        safe_mean_std(Hdc),\n",
    "        safe_mean_std(N),\n",
    "        safe_mean_std(Pcv)\n",
    "    ]\n",
    "\n",
    "    # # 用來做test固定標準化參數的\n",
    "    # print(\"0.F, 1.T, 2.Hdc, 3.N, 4.Pcv\")\n",
    "    # material_name = f\"{material}\"\n",
    "    # print(f'\"{material_name}\": [')\n",
    "    # for param in norm:\n",
    "    #     print(f\"    {param},\")\n",
    "    # print(\"]\")\n",
    "\n",
    "    # Data Normalization\n",
    "    in_F = (F - norm[0][0]) / norm[0][1]  # F\n",
    "    in_T = (T - norm[1][0]) / norm[1][1]  # T\n",
    "    in_Hdc = (Hdc - norm[2][0]) / norm[2][1]  # Hdc\n",
    "    in_N = (N - norm[3][0]) / norm[3][1]  # N\n",
    "    in_Pcv = (Pcv - norm[4][0]) / norm[4][1]  # Pcv\n",
    "    in_Duty_P = Duty_P  # Duty Pos\n",
    "    in_Duty_N = Duty_N  # Duty Neg\n",
    "\n",
    "    # #   → 方便推論復原，保留 scale_B, scale_H 當作額外純量\n",
    "    # aux_features = torch.cat(\n",
    "    #     (in_F, in_T, in_Hdc, in_N, in_Duty_P, in_Duty_N, in_Pcv,\n",
    "    #      scale_B.squeeze(-1), scale_H.squeeze(-1)),\n",
    "    #     dim=1)\n",
    "\n",
    "    # ── 7. 產生初始 Preisach operator 狀態 s0 ──────\n",
    "    max_B, _ = torch.max(in_B, dim=1)\n",
    "    min_B, _ = torch.min(in_B, dim=1)\n",
    "    # s0 = get_operator_init(in_B[:, 0] - dB[:, 0] / scale_B.squeeze(-1),\n",
    "    #                        dB / scale_B, max_B, min_B)\n",
    "\n",
    "    s0 = get_operator_init(in_B[:, 0] - dB[:, 0] / global_B_max.squeeze(-1),\n",
    "                           dB / global_B_max,\n",
    "                           max_B,\n",
    "                           min_B,\n",
    "                           operator_size=operator_size)\n",
    "\n",
    "    # ── 8. 組合 Dataset ───────────────────────────\n",
    "    # wave_inputs = torch.cat(\n",
    "    #     (\n",
    "    #         in_B,  # ① B\n",
    "    #         dB / scale_B,  # ② ΔB\n",
    "    #         in_dB_dt,  # ③ dB/dt\n",
    "    #         in_d2B_dt),\n",
    "    #     dim=2)  # ④ d²B/dt²   → (B,L,4)\n",
    "\n",
    "    # amps = torch.cat((scale_B.squeeze(-1), scale_H.squeeze(-1)),\n",
    "    #                 dim=1)  # (B,2)\n",
    "\n",
    "    wave_inputs = torch.cat(\n",
    "        (\n",
    "            in_B,  # ① B\n",
    "            dB / global_B_max,  # ② ΔB\n",
    "            in_dB_dt,  # ③ dB/dt\n",
    "            in_d2B_dt),\n",
    "        dim=2)  # ④ d²B/dt²   → (B,L,4)\n",
    "\n",
    "    aux_features = torch.cat((in_F, in_T, in_Hdc, in_N, in_Duty_P, in_Duty_N),\n",
    "                             dim=1)  # (B,4)\n",
    "\n",
    "    amp_B = torch.full((len(B), 1), global_B_max, dtype=torch.float32)\n",
    "    amp_H = torch.full((len(B), 1), global_H_max, dtype=torch.float32)\n",
    "    amps = torch.cat((amp_B, amp_H), dim=1)  # 仍給 RNN2 用\n",
    "\n",
    "    # 這裡把 Pcv（已 z-score）單獨拿出來當另一個 label\n",
    "    target_Pcv = in_Pcv  # (B,1)\n",
    "\n",
    "    full_dataset = torch.utils.data.TensorDataset(\n",
    "        wave_inputs,  # 0  → 模型序列輸入\n",
    "        aux_features,  # 1  → 4 個純量\n",
    "        amps,  # 2  → 幅值係數\n",
    "        s0,  # 3  → Preisach 初始狀態\n",
    "        out_H,  # 4  → 目標 H  (已 scale_H)\n",
    "        target_Pcv)  # 5  → 目標 Pcv (已 z-score)\n",
    "\n",
    "    # ── 9. Train / Valid split & DataLoader ───────\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    valid_size = len(full_dataset) - train_size\n",
    "    train_set, valid_set = torch.utils.data.random_split(\n",
    "        full_dataset, [train_size, valid_size],\n",
    "        generator=torch.Generator().manual_seed(Config.SEED))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=0,\n",
    "                                               pin_memory=True,\n",
    "                                               collate_fn=filter_input)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_set,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0,\n",
    "                                               pin_memory=True,\n",
    "                                               collate_fn=filter_input)\n",
    "\n",
    "    return train_loader, valid_loader, norm\n",
    "\n",
    "\n",
    "# %% Predict the operator state at t0\n",
    "def get_operator_init(B1,\n",
    "                      dB,\n",
    "                      Bmax,\n",
    "                      Bmin,\n",
    "                      max_out_H=Config.MAXOUT_H,\n",
    "                      operator_size=Config.OPERATOR_SIZE):\n",
    "    \"\"\"Compute the initial state of hysteresis operators\"\"\"\n",
    "    s0 = torch.zeros((dB.shape[0], operator_size))\n",
    "    operator_thre = torch.from_numpy(\n",
    "        np.linspace(max_out_H / operator_size, max_out_H,\n",
    "                    operator_size)).view(1, -1)\n",
    "\n",
    "    for i in range(dB.shape[0]):\n",
    "        for j in range(operator_size):\n",
    "            r = operator_thre[0, j]\n",
    "            if (Bmax[i] >= r) or (Bmin[i] <= -r):\n",
    "                if dB[i, 0] >= 0:\n",
    "                    if B1[i] > Bmin[i] + 2 * r:\n",
    "                        s0[i, j] = r\n",
    "                    else:\n",
    "                        s0[i, j] = B1[i] - (r + Bmin[i])\n",
    "                else:\n",
    "                    if B1[i] < Bmax[i] - 2 * r:\n",
    "                        s0[i, j] = -r\n",
    "                    else:\n",
    "                        s0[i, j] = B1[i] + (r - Bmax[i])\n",
    "    return s0\n",
    "\n",
    "\n",
    "def filter_input(batch):\n",
    "    inputs, features, amps, s0, target_H, target_Pcv = zip(*batch)\n",
    "\n",
    "    inputs = torch.stack(inputs)\n",
    "    features = torch.stack(features)\n",
    "    amps = torch.stack(amps)\n",
    "    s0 = torch.stack(s0)\n",
    "    target_H = torch.stack(target_H)[:, -downsample:, :]  # 保留全長\n",
    "    target_Pcv = torch.stack(target_Pcv)  # (B,1)\n",
    "\n",
    "    return inputs, features, amps, s0, target_H, target_Pcv\n",
    "\n",
    "\n",
    "# 溫度頻率不變加入微小的 epsilon\n",
    "def safe_mean_std(tensor, eps=1e-8):\n",
    "    m_tensor = torch.mean(tensor)  # 還是 Tensor\n",
    "    s_tensor = torch.std(tensor)  # 還是 Tensor\n",
    "\n",
    "    m_val = m_tensor.item()  # 第一次轉成 float\n",
    "    s_val = s_tensor.item()\n",
    "    if s_val < eps:\n",
    "        s_val = 1.0\n",
    "    return [m_val, s_val]  # 直接回傳 float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Define Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Magnetization mechansim-determined neural network\n",
    "\"\"\"\n",
    "    Parameters:\n",
    "    - hidden_size: number of eddy current slices (RNN neuron)\n",
    "    - operator_size: number of operators\n",
    "    - input_size: number of inputs (1.B 2.dB 3.dB/dt 4.d2B/dt)\n",
    "    - var_size: number of supplenmentary variables (1.F 2.T 3.Hdc 4.N 5.Duty_P 6.Duty_N)        \n",
    "    - output_size: number of outputs (1.H)\n",
    "    \n",
    "    只先把d2B/dt考量在EddyCell裡面\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MMINet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 norm,\n",
    "                 hidden_size,\n",
    "                 operator_size,\n",
    "                 input_size=4,\n",
    "                 var_size=6,\n",
    "                 output_size=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.var_size = var_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.operator_size = operator_size\n",
    "        self.norm = norm\n",
    "\n",
    "        self.rnn1 = StopOperatorCell(self.operator_size)\n",
    "        self.dnn1 = nn.Linear(self.operator_size + self.var_size, 1)\n",
    "        # var_size (F T Hdc N Duty_P Duty_N ) + 3 (B, dB/dt, d2B/dt)\n",
    "        self.rnn2 = EddyCell(var_size + 3, self.hidden_size, output_size)\n",
    "        self.dnn2 = nn.Linear(self.hidden_size, 1)\n",
    "        self.rnn2_hx = None\n",
    "        # var_size=6: 1.F 2.T 3.Hdc 4.N 5.Duty_P 6.Duty_N + 1 for P_prelim\n",
    "        self.loss_mlp = nn.Sequential(nn.Linear(self.var_size + 1, 128),\n",
    "                                      nn.ReLU(), nn.Linear(128, 64), nn.ReLU(),\n",
    "                                      nn.Linear(64, 32), nn.ReLU(),\n",
    "                                      nn.Linear(32, 1))\n",
    "\n",
    "    def forward(self, x, var, amps, s0, n_init=16):\n",
    "        \"\"\"\n",
    "        Parameters: \n",
    "        - x(batch,seq,input_size): Input features (1.B, 2.dB, 3.dB/dt)  \n",
    "        - var(batch,var_size): Supplementary inputs (1.F 2.T 3.Hdc 4.N 5.Duty_P 6.Duty_N) \n",
    "        - s0(batch,1): Operator inital states\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)  # Batch size\n",
    "        seq_size = x.size(1)  # Ser\n",
    "        self.rnn1_hx = s0\n",
    "\n",
    "        # !Initialize DNN2 input (1.B 2.dB/dt 3.d2B)\n",
    "        # x2 = torch.cat((x[:, :, 0:1], x[:, :, 2:3]), dim=2)\n",
    "        # !選取 B, dB/dt, d2B/dt\n",
    "        x2 = torch.cat((x[:, :, 0:1], x[:, :, 2:4]), dim=2)\n",
    "\n",
    "        for t in range(seq_size):\n",
    "            # RNN1 input (dB,state)\n",
    "            self.rnn1_hx = self.rnn1(x[:, t, 1:2], self.rnn1_hx)\n",
    "\n",
    "            # DNN1 input (rnn1_hx,F,T,Hdc,N)\n",
    "            dnn1_in = torch.cat((self.rnn1_hx, var), dim=1)\n",
    "\n",
    "            # H hysteresis prediction\n",
    "            H_hyst_pred = self.dnn1(dnn1_in)\n",
    "\n",
    "            # DNN2 input (B,dB/dt,T,F)\n",
    "            rnn2_in = torch.cat((x2[:, t, :], var), dim=1)\n",
    "\n",
    "            # Initialize second rnn state\n",
    "            if t == 0:\n",
    "                H_eddy_init = x[:, t, 0:1] - H_hyst_pred\n",
    "                buffer = x.new_ones(x.size(0), self.hidden_size)\n",
    "                self.rnn2_hx = Variable(\n",
    "                    (buffer / torch.sum(self.dnn2.weight, dim=1)) *\n",
    "                    H_eddy_init)\n",
    "\n",
    "            #rnn2_in = torch.cat((rnn2_in,H_hyst_pred),dim=1)\n",
    "            self.rnn2_hx = self.rnn2(rnn2_in, self.rnn2_hx)\n",
    "\n",
    "            # H eddy prediction\n",
    "            H_eddy = self.dnn2(self.rnn2_hx)\n",
    "\n",
    "            # H total\n",
    "            H_total = (H_hyst_pred + H_eddy).view(batch_size, 1,\n",
    "                                                  self.output_size)\n",
    "            if t == 0:\n",
    "                output = H_total\n",
    "            else:\n",
    "                output = torch.cat((output, H_total), dim=1)\n",
    "\n",
    "        H = (output[:, n_init:, :])\n",
    "\n",
    "        amp_B = amps[:, 0:1]  # (batch,1)\n",
    "        amp_H = amps[:, 1:2]  # (batch,1)\n",
    "        B_amp = x[:, n_init:, 0:1] * amp_B.unsqueeze(1)\n",
    "        H_amp = output[:, n_init:, :] * amp_H.unsqueeze(1)\n",
    "        P_prelim = torch.trapz(H_amp, B_amp, axis=1) * (10**(\n",
    "            var[:, 0:1] * self.norm[0][1] + self.norm[0][0]))\n",
    "        Pcv_log = torch.log10(P_prelim.clamp(min=1e-12))\n",
    "        Pcv = (Pcv_log - self.norm[4][0]) / self.norm[4][1]\n",
    "        mlp_input = torch.cat((var, Pcv), dim=1)  # (batch, 5)\n",
    "        s = self.loss_mlp(mlp_input)\n",
    "        Pcv_mlp = Pcv + s\n",
    "\n",
    "        return H, Pcv_mlp\n",
    "\n",
    "\n",
    "class StopOperatorCell():\n",
    "\n",
    "    def __init__(self, operator_size):\n",
    "        self.operator_thre = torch.from_numpy(\n",
    "            np.linspace(Config.MAXOUT_H / operator_size, Config.MAXOUT_H,\n",
    "                        operator_size)).view(1, -1)\n",
    "\n",
    "    def sslu(self, X):\n",
    "        a = torch.ones_like(X)\n",
    "        return torch.max(-a, torch.min(a, X))\n",
    "\n",
    "    def __call__(self, dB, state):\n",
    "        r = self.operator_thre.to(dB.device)\n",
    "        output = self.sslu((dB + state) / r) * r\n",
    "        return output.float()\n",
    "\n",
    "\n",
    "class EddyCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.x2h = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        hidden = self.x2h(x) + self.h2h(hidden)\n",
    "        hidden = torch.sigmoid(hidden)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def load_dataset(material, base_path=\"./Data/\"):\n",
    "\n",
    "    in_file1 = f\"{base_path}{material}/train/B_Field.csv\"\n",
    "    in_file2 = f\"{base_path}{material}/train/Frequency.csv\"\n",
    "    in_file3 = f\"{base_path}{material}/train/Temperature.csv\"\n",
    "    in_file4 = f\"{base_path}{material}/train/H_Field.csv\"\n",
    "    in_file5 = f\"{base_path}{material}/train/Volumetric_Loss.csv\"\n",
    "    in_file6 = f\"{base_path}{material}/train/Hdc.csv\"\n",
    "    in_file7 = f\"{base_path}{material}/train/Turns.csv\"\n",
    "    in_file8 = f\"{base_path}{material}/train/Duty_P.csv\"\n",
    "    in_file9 = f\"{base_path}{material}/train/Duty_N.csv\"\n",
    "\n",
    "    data_B = np.genfromtxt(in_file1, delimiter=',')  # N x 1024\n",
    "    data_F = np.genfromtxt(in_file2, delimiter=',')  # N x 1\n",
    "    data_T = np.genfromtxt(in_file3, delimiter=',')  # N x 1\n",
    "    data_H = np.genfromtxt(in_file4, delimiter=',')  # N x 1024\n",
    "    data_Pcv = np.genfromtxt(in_file5, delimiter=',')  # N x 1\n",
    "    data_Hdc = np.genfromtxt(in_file6, delimiter=',')  # N x 1\n",
    "    data_N = np.genfromtxt(in_file7, delimiter=',')  # N x 1\n",
    "    data_Duty_P = np.genfromtxt(in_file8, delimiter=',')  # N x 1\n",
    "    data_Duty_N = np.genfromtxt(in_file9, delimiter=',')  # N x 1\n",
    "\n",
    "    return data_B, data_F, data_T, data_H, data_Pcv, data_Hdc, data_N, data_Duty_P, data_Duty_N\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp_learning_rate(optimizer, min_lr=1e-4):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group['lr'] < min_lr:\n",
    "            param_group['lr'] = min_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trial, config_dict, norm, train_loader, valid_loader):\n",
    "\n",
    "    # 從傳入的 config_dict 取得超參數\n",
    "    LEARNING_RATE = config_dict['LEARNING_RATE']\n",
    "    LR_SCHEDULER_GAMMA = config_dict['LR_SCHEDULER_GAMMA']\n",
    "    HIDDEN_SIZE = config_dict['HIDDEN_SIZE']\n",
    "    OPERATOR_SIZE = config_dict['OPERATOR_SIZE']\n",
    "    BATCH_SIZE = config_dict['BATCH_SIZE']\n",
    "    DECAY_EPOCH = config_dict.get('DECAY_EPOCH', Config.DECAY_EPOCH)\n",
    "\n",
    "    best_loss_H = float('inf')\n",
    "    best_loss_Pcv = float('inf')\n",
    "    wait_H = wait_Pcv = 0\n",
    "    MIN_DELTA = 1e-6  # 低進步門檻:驗證損失在後期常卡在小數點後幾位來回抖動；若不設門檻，模型可能因微小雜訊一直重置等待計數，永遠觸發不了早停\n",
    "    PATIENCE_H = Config.EARLY_STOPPING_PATIENCE\n",
    "    PATIENCE_PCV = Config.EARLY_STOPPING_PATIENCE\n",
    "    joint_phase = False\n",
    "\n",
    "    # model = MMINet(norm=norm).to(device)\n",
    "    model = MMINet(norm, hidden_size=HIDDEN_SIZE,\n",
    "                   operator_size=OPERATOR_SIZE).to(device)\n",
    "\n",
    "    criterion_H = nn.MSELoss()\n",
    "    criterion_Pcv = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "        optimizer, gamma=Config.LR_SCHEDULER_GAMMA)\n",
    "\n",
    "    # Loss 記錄\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_loss_Pcv = float('inf')\n",
    "    best_val_loss_H = float('inf')\n",
    "\n",
    "    for epoch in range(Config.NUM_EPOCHS):\n",
    "\n",
    "        print(f\"[Trial {trial.number}] Epoch {epoch+1}/{Config.NUM_EPOCHS}\")\n",
    "        alpha = (epoch + 1) / Config.NUM_EPOCHS\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for inputs, features, amps, s0, target_H, target_Pcv in train_loader:\n",
    "\n",
    "            inputs, features, amps, s0, target_H, target_Pcv = inputs.to(\n",
    "                device), features.to(device), amps.to(device), s0.to(\n",
    "                    device), target_H.to(device), target_Pcv.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                outputs_H, outputs_Pcv = model(inputs, features, amps,\n",
    "                                               s0)  # 模型的輸出\n",
    "                loss_H = criterion_H(outputs_H, target_H)  # 使用真實的 H(t) 計算損失\n",
    "                loss_Pcv = criterion_Pcv(outputs_Pcv, target_Pcv)\n",
    "\n",
    "                loss = (1 - alpha) * loss_H + alpha * loss_Pcv\n",
    "                # alpha = 0.5\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # ------------------------------vaildation------------------------------\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_loss_H = 0.0\n",
    "        val_loss_Pcv = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, features, amps, s0, target_H, target_Pcv in valid_loader:\n",
    "                inputs, features, amps, s0, target_H, target_Pcv = inputs.to(\n",
    "                    device), features.to(device), amps.to(device), s0.to(\n",
    "                        device), target_H.to(device), target_Pcv.to(device)\n",
    "\n",
    "                outputs_H, outputs_Pcv = model(inputs, features, amps,\n",
    "                                               s0)  # 模型的輸出\n",
    "                loss_H = criterion_H(outputs_H, target_H)  # 使用真實的 H(t) 計算損失\n",
    "                loss_Pcv = criterion_Pcv(outputs_Pcv, target_Pcv)\n",
    "\n",
    "                loss = (1 - alpha) * loss_H + alpha * loss_Pcv\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_loss_H += loss_H.item()\n",
    "                val_loss_Pcv += loss_Pcv.item()\n",
    "\n",
    "        # 求驗證集平均\n",
    "        val_loss_H /= len(valid_loader)\n",
    "        val_loss_Pcv /= len(valid_loader)\n",
    "        val_loss /= len(valid_loader)\n",
    "\n",
    "        scheduler.step()  # scheduler 更新\n",
    "        clamp_learning_rate(optimizer)  # 避免learning rate掉到 0\n",
    "\n",
    "        # early stopping 條件\n",
    "        if val_loss_H < best_val_loss_H and val_loss_Pcv < best_val_loss_Pcv:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_loss_H = val_loss_H\n",
    "            best_val_loss_Pcv = val_loss_Pcv\n",
    "\n",
    "        if not joint_phase:  # H-phase\n",
    "            if val_loss_H < best_loss_H - MIN_DELTA:\n",
    "                best_loss_H = val_loss_H\n",
    "                best_loss_Pcv = val_loss_Pcv\n",
    "                # best_epoch = epoch + 1\n",
    "                wait_H = 0\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "                # print(f\"✅ Save best H @ epoch {best_epoch}\")\n",
    "            else:\n",
    "                wait_H += 1\n",
    "                # print(f\"  H 無改善 wait_H={wait_H}/{PATIENCE_H}\")\n",
    "\n",
    "            if wait_H >= PATIENCE_H:  # ← 不再 break！\n",
    "                print(f\"[Trial {trial.number}]🔸 H 早停 → 切到 Pcv-phase\")\n",
    "                joint_phase = True  # 切旗標\n",
    "                wait_Pcv = 0  # 重設計數\n",
    "                continue  # 直接下一個 epoch\n",
    "\n",
    "        else:  # Pcv-phase\n",
    "            if val_loss_Pcv < best_loss_Pcv - MIN_DELTA and val_loss_H < best_loss_H * 1.05 - MIN_DELTA:\n",
    "                best_loss_H = val_loss_H\n",
    "                best_loss_Pcv = val_loss_Pcv\n",
    "                # best_epoch = epoch + 1\n",
    "                wait_Pcv = 0\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "                # print(f\"✅ Save best Pcv @ epoch {best_epoch}\")\n",
    "            else:\n",
    "                wait_Pcv += 1\n",
    "                # print(f\"  Pcv 無改善 wait_Pcv={wait_Pcv}/{PATIENCE_PCV}\")\n",
    "\n",
    "            if wait_Pcv >= PATIENCE_PCV:  # 真正結束\n",
    "                print(f\"[Trial {trial.number}] 🔸 Pcv 早停觸發，整體訓練結束\")\n",
    "                break\n",
    "\n",
    "        trial.report(val_loss, epoch)  # 用 Pcv 當指標（也可改成 val_H+val_P）\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # 訓練迴圈結束後，回傳這次試驗的最佳驗證損失\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Train!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    print(f\"→ Start trial {trial.number}\")\n",
    "    # --- 1. 定義要搜尋的超參數空間 ---\n",
    "    # 我先選幾個關鍵的當範例，你可以自己增加或修改\n",
    "    config_dict = {\n",
    "        'LEARNING_RATE':\n",
    "        trial.suggest_categorical('LEARNING_RATE', [0.01, 0.05, 0.1, 0.2]),\n",
    "        'BATCH_SIZE':\n",
    "        trial.suggest_int('BATCH_SIZE', 64, 256, step=64),\n",
    "        'HIDDEN_SIZE':\n",
    "        trial.suggest_int('HIDDEN_SIZE', 10, 40, step=10),\n",
    "        'OPERATOR_SIZE':\n",
    "        trial.suggest_int('OPERATOR_SIZE', 10, 40, step=10),\n",
    "        'LR_SCHEDULER_GAMMA':\n",
    "        trial.suggest_float('LR_SCHEDULER_GAMMA', [0.01, 0.05, 0.1, 0.2]),\n",
    "    }\n",
    "\n",
    "    # --- 2. 準備數據 ---\n",
    "    # 每次試驗都重新載入數據，確保獨立性\n",
    "    data_B, data_F, data_T, data_H, data_Pcv, data_Hdc, data_N, data_Duty_P, data_Duty_N = load_dataset(\n",
    "        material)\n",
    "    GLOBAL_B_MAX = np.abs(data_B).max()\n",
    "    GLOBAL_H_MAX = np.abs(data_H).max()\n",
    "\n",
    "    # 這裡的 get_operator_init 可能也需要 operator_size\n",
    "    # 我們需要在 get_dataloader 內部調用時傳入\n",
    "    # 為了簡化，我們先在 get_dataloader 內部直接呼叫 get_operator_init 時固定或傳入\n",
    "    # 我已在上面 get_dataloader 和 get_operator_init 做了修改\n",
    "\n",
    "    train_loader, valid_loader, norm = get_dataloader(\n",
    "        data_B,\n",
    "        data_F,\n",
    "        data_T,\n",
    "        data_H,\n",
    "        data_N,\n",
    "        data_Hdc,\n",
    "        data_Duty_P,\n",
    "        data_Duty_N,\n",
    "        data_Pcv,\n",
    "        GLOBAL_B_MAX,\n",
    "        GLOBAL_H_MAX,\n",
    "        batch_size=config_dict['BATCH_SIZE'],  # 使用 Optuna 建議的 batch size\n",
    "        operator_size=config_dict['OPERATOR_SIZE'])\n",
    "\n",
    "    # --- 3. 執行訓練並取得結果 ---\n",
    "    try:\n",
    "        val_loss = train_model(trial, config_dict, norm, train_loader,\n",
    "                               valid_loader)\n",
    "    except RuntimeError as e:\n",
    "        # 有時參數組合不好會導致 CUDA out of memory，這時我們告訴 Optuna 這次試驗失敗\n",
    "        if \"out of memory\" in str(e):\n",
    "            print(f\"Trial {trial.number} failed with OOM. Pruning.\")\n",
    "            # 回傳一個很大的數字，Optuna 就知道這是不好的參數\n",
    "            # 並且透過 raise TrialPruned() 來標記為剪枝\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # --- 4. 回傳最終目標值 ---\n",
    "    print(f\"← End   trial {trial.number}\")\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    data_B, data_F, data_T, data_H, data_Pcv, data_Hdc, data_N, data_Duty_P, data_Duty_N = load_dataset(\n",
    "        material)\n",
    "\n",
    "    GLOBAL_B_MAX = np.abs(data_B).max()\n",
    "    GLOBAL_H_MAX = np.abs(data_H).max()\n",
    "\n",
    "    train_loader, valid_loader, norm = get_dataloader(\n",
    "        data_B,\n",
    "        data_F,\n",
    "        data_T,\n",
    "        data_H,\n",
    "        data_N,\n",
    "        data_Hdc,\n",
    "        data_Duty_P,\n",
    "        data_Duty_N,\n",
    "        data_Pcv,\n",
    "        GLOBAL_B_MAX,\n",
    "        GLOBAL_H_MAX,\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        operator_size=Config.OPERATOR_SIZE)\n",
    "\n",
    "    # logger = TrainLogger(\n",
    "    #     exp_name=f\"{material}_{note}_{timestamp}\",\n",
    "    #     config_dict={\n",
    "    #         k: getattr(Config, k)\n",
    "    #         for k in dir(Config)\n",
    "    #         if not k.startswith('__') and not callable(getattr(Config, k))\n",
    "    #     },\n",
    "    #     result_dir=result_dir)\n",
    "    # feature_names = [\"F\", \"T\", \"Hdc\", \"N\", \"Pcv\"]\n",
    "    # logger.save_norm_params(norm, feature_names)\n",
    "\n",
    "    # train_model(norm, train_loader, valid_loader, logger)  # logger\n",
    "\n",
    "    # 1. 建立 Study 物件\n",
    "    # 我們可以指定一個 `storage` 來保存進度，這樣中斷後可以接續\n",
    "    # 也可以指定 `study_name`\n",
    "    study_name = f\"{timestamp}_{material}_{note}\"\n",
    "    storage_name = f\"sqlite:///{study_name}.db\"\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=storage_name,\n",
    "        direction='minimize',  # 目標是最小化 val_loss\n",
    "        pruner=optuna.pruners.MedianPruner(),  # 使用中位數剪枝器\n",
    "        load_if_exists=True)\n",
    "\n",
    "    # 2. 開始優化\n",
    "    # n_trials 是你要進行多少次試驗\n",
    "    print(f\"🚀 Starting Optuna optimization for {study_name}...\")\n",
    "    study.optimize(objective, n_trials=100, n_jobs=1, show_progress_bar=True)\n",
    "\n",
    "    # 3. 輸出最佳結果\n",
    "    print(\"\\n\\n🎉 Optimization Finished! 🎉\")\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "    # 4. 保存最佳參數\n",
    "    best_params_file = os.path.join(\"results\",\n",
    "                                    f\"{study_name}_best_params.json\")\n",
    "    with open(best_params_file, \"w\") as f:\n",
    "        json.dump(trial.params, f, indent=4)\n",
    "    print(f\"\\n✅ Best parameters saved to {best_params_file}\")\n",
    "\n",
    "    # 5. 啟動 Dashboard (在 terminal 中執行)\n",
    "    print(\n",
    "        \"\\nTo visualize results, run the following command in your terminal:\")\n",
    "    print(f\"optuna-dashboard {storage_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 10:13:50,093] A new study created in RDB with name: 20250807_CH467160_optuna_search_1.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Optuna optimization for 20250807_CH467160_optuna_search_1.3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Start trial 0\n",
      "[Trial 0] Epoch 1/100\n",
      "[Trial 0] Epoch 2/100\n",
      "[Trial 0] Epoch 3/100\n",
      "[Trial 0] Epoch 4/100\n",
      "[Trial 0] Epoch 5/100\n",
      "[Trial 0] Epoch 6/100\n",
      "[Trial 0] Epoch 7/100\n",
      "[Trial 0] Epoch 8/100\n",
      "[Trial 0] Epoch 9/100\n",
      "[Trial 0] Epoch 10/100\n",
      "[Trial 0] Epoch 11/100\n",
      "[Trial 0] Epoch 12/100\n",
      "[Trial 0] Epoch 13/100\n",
      "[Trial 0] Epoch 14/100\n",
      "[Trial 0] Epoch 15/100\n",
      "[Trial 0] Epoch 16/100\n",
      "[Trial 0] Epoch 17/100\n",
      "[Trial 0] Epoch 18/100\n",
      "[Trial 0] Epoch 19/100\n",
      "[Trial 0] Epoch 20/100\n",
      "[Trial 0] Epoch 21/100\n",
      "[Trial 0] Epoch 22/100\n",
      "[Trial 0] Epoch 23/100\n",
      "[Trial 0] Epoch 24/100\n",
      "[Trial 0] Epoch 25/100\n",
      "[Trial 0] Epoch 26/100\n",
      "[Trial 0] Epoch 27/100\n",
      "[Trial 0] Epoch 28/100\n",
      "[Trial 0] Epoch 29/100\n",
      "[Trial 0] Epoch 30/100\n",
      "[Trial 0] Epoch 31/100\n",
      "[Trial 0] Epoch 32/100\n",
      "[Trial 0] Epoch 33/100\n",
      "[Trial 0] Epoch 34/100\n",
      "[Trial 0] Epoch 35/100\n",
      "[Trial 0] Epoch 36/100\n",
      "[Trial 0] Epoch 37/100\n",
      "[Trial 0] Epoch 38/100\n",
      "[Trial 0] Epoch 39/100\n",
      "[Trial 0] Epoch 40/100\n",
      "[Trial 0] Epoch 41/100\n",
      "[Trial 0] Epoch 42/100\n",
      "[Trial 0] Epoch 43/100\n",
      "[Trial 0] Epoch 44/100\n",
      "[Trial 0] Epoch 45/100\n",
      "[Trial 0] Epoch 46/100\n",
      "[Trial 0] Epoch 47/100\n",
      "[Trial 0] Epoch 48/100\n",
      "[Trial 0] Epoch 49/100\n",
      "[Trial 0] Epoch 50/100\n",
      "[Trial 0] Epoch 51/100\n",
      "[Trial 0] Epoch 52/100\n",
      "[Trial 0] Epoch 53/100\n",
      "[Trial 0] Epoch 54/100\n",
      "[Trial 0] Epoch 55/100\n",
      "[Trial 0] Epoch 56/100\n",
      "[Trial 0] Epoch 57/100\n",
      "[Trial 0] Epoch 58/100\n",
      "[Trial 0] Epoch 59/100\n",
      "[Trial 0] Epoch 60/100\n",
      "[Trial 0] Epoch 61/100\n",
      "[Trial 0] Epoch 62/100\n",
      "[Trial 0] Epoch 63/100\n",
      "[Trial 0] Epoch 64/100\n",
      "[Trial 0] Epoch 65/100\n",
      "[Trial 0] Epoch 66/100\n",
      "[Trial 0] Epoch 67/100\n",
      "[Trial 0] Epoch 68/100\n",
      "[Trial 0] Epoch 69/100\n",
      "[Trial 0] Epoch 70/100\n",
      "[Trial 0] Epoch 71/100\n",
      "[Trial 0] Epoch 72/100\n",
      "[Trial 0] Epoch 73/100\n",
      "[Trial 0] Epoch 74/100\n",
      "[Trial 0] Epoch 75/100\n",
      "[Trial 0] Epoch 76/100\n",
      "[Trial 0] Epoch 77/100\n",
      "[Trial 0] Epoch 78/100\n",
      "[Trial 0] Epoch 79/100\n",
      "[Trial 0] Epoch 80/100\n",
      "[Trial 0] Epoch 81/100\n",
      "[Trial 0] Epoch 82/100\n",
      "[Trial 0] Epoch 83/100\n",
      "[Trial 0] Epoch 84/100\n",
      "[Trial 0] Epoch 85/100\n",
      "[Trial 0] Epoch 86/100\n",
      "[Trial 0] Epoch 87/100\n",
      "[Trial 0] Epoch 88/100\n",
      "[Trial 0] Epoch 89/100\n",
      "[Trial 0] Epoch 90/100\n",
      "[Trial 0] Epoch 91/100\n",
      "[Trial 0] Epoch 92/100\n",
      "[Trial 0] Epoch 93/100\n",
      "[Trial 0] Epoch 94/100\n",
      "[Trial 0] Epoch 95/100\n",
      "[Trial 0] Epoch 96/100\n",
      "[Trial 0] Epoch 97/100\n",
      "[Trial 0] Epoch 98/100\n",
      "[Trial 0] Epoch 99/100\n",
      "[Trial 0] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.00456468:   1%|          | 1/100 [16:23<27:02:50, 983.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 0\n",
      "[I 2025-08-07 10:30:13,630] Trial 0 finished with value: 0.004564675880828872 and parameters: {'LEARNING_RATE': 0.01, 'BATCH_SIZE': 128, 'HIDDEN_SIZE': 20, 'OPERATOR_SIZE': 30, 'LR_SCHEDULER_GAMMA': 0.9957584723882923, 'DECAY_EPOCH': 199}. Best is trial 0 with value: 0.004564675880828872.\n",
      "→ Start trial 1\n",
      "[Trial 1] Epoch 1/100\n",
      "[Trial 1] Epoch 2/100\n",
      "[Trial 1] Epoch 3/100\n",
      "[Trial 1] Epoch 4/100\n",
      "[Trial 1] Epoch 5/100\n",
      "[Trial 1] Epoch 6/100\n",
      "[Trial 1] Epoch 7/100\n",
      "[Trial 1] Epoch 8/100\n",
      "[Trial 1] Epoch 9/100\n",
      "[Trial 1] Epoch 10/100\n",
      "[Trial 1] Epoch 11/100\n",
      "[Trial 1] Epoch 12/100\n",
      "[Trial 1] Epoch 13/100\n",
      "[Trial 1] Epoch 14/100\n",
      "[Trial 1] Epoch 15/100\n",
      "[Trial 1] Epoch 16/100\n",
      "[Trial 1] Epoch 17/100\n",
      "[Trial 1] Epoch 18/100\n",
      "[Trial 1] Epoch 19/100\n",
      "[Trial 1] Epoch 20/100\n",
      "[Trial 1] Epoch 21/100\n",
      "[Trial 1] Epoch 22/100\n",
      "[Trial 1] Epoch 23/100\n",
      "[Trial 1] Epoch 24/100\n",
      "[Trial 1] Epoch 25/100\n",
      "[Trial 1] Epoch 26/100\n",
      "[Trial 1] Epoch 27/100\n",
      "[Trial 1] Epoch 28/100\n",
      "[Trial 1] Epoch 29/100\n",
      "[Trial 1] Epoch 30/100\n",
      "[Trial 1] Epoch 31/100\n",
      "[Trial 1] Epoch 32/100\n",
      "[Trial 1] Epoch 33/100\n",
      "[Trial 1] Epoch 34/100\n",
      "[Trial 1] Epoch 35/100\n",
      "[Trial 1] Epoch 36/100\n",
      "[Trial 1] Epoch 37/100\n",
      "[Trial 1] Epoch 38/100\n",
      "[Trial 1] Epoch 39/100\n",
      "[Trial 1] Epoch 40/100\n",
      "[Trial 1] Epoch 41/100\n",
      "[Trial 1] Epoch 42/100\n",
      "[Trial 1] Epoch 43/100\n",
      "[Trial 1] Epoch 44/100\n",
      "[Trial 1] Epoch 45/100\n",
      "[Trial 1] Epoch 46/100\n",
      "[Trial 1] Epoch 47/100\n",
      "[Trial 1] Epoch 48/100\n",
      "[Trial 1] Epoch 49/100\n",
      "[Trial 1] Epoch 50/100\n",
      "[Trial 1] Epoch 51/100\n",
      "[Trial 1] Epoch 52/100\n",
      "[Trial 1] Epoch 53/100\n",
      "[Trial 1] Epoch 54/100\n",
      "[Trial 1] Epoch 55/100\n",
      "[Trial 1] Epoch 56/100\n",
      "[Trial 1] Epoch 57/100\n",
      "[Trial 1] Epoch 58/100\n",
      "[Trial 1] Epoch 59/100\n",
      "[Trial 1] Epoch 60/100\n",
      "[Trial 1] Epoch 61/100\n",
      "[Trial 1] Epoch 62/100\n",
      "[Trial 1] Epoch 63/100\n",
      "[Trial 1] Epoch 64/100\n",
      "[Trial 1] Epoch 65/100\n",
      "[Trial 1] Epoch 66/100\n",
      "[Trial 1] Epoch 67/100\n",
      "[Trial 1] Epoch 68/100\n",
      "[Trial 1] Epoch 69/100\n",
      "[Trial 1] Epoch 70/100\n",
      "[Trial 1] Epoch 71/100\n",
      "[Trial 1] Epoch 72/100\n",
      "[Trial 1] Epoch 73/100\n",
      "[Trial 1] Epoch 74/100\n",
      "[Trial 1] Epoch 75/100\n",
      "[Trial 1] Epoch 76/100\n",
      "[Trial 1] Epoch 77/100\n",
      "[Trial 1] Epoch 78/100\n",
      "[Trial 1] Epoch 79/100\n",
      "[Trial 1] Epoch 80/100\n",
      "[Trial 1] Epoch 81/100\n",
      "[Trial 1] Epoch 82/100\n",
      "[Trial 1] Epoch 83/100\n",
      "[Trial 1] Epoch 84/100\n",
      "[Trial 1] Epoch 85/100\n",
      "[Trial 1] Epoch 86/100\n",
      "[Trial 1] Epoch 87/100\n",
      "[Trial 1] Epoch 88/100\n",
      "[Trial 1] Epoch 89/100\n",
      "[Trial 1] Epoch 90/100\n",
      "[Trial 1] Epoch 91/100\n",
      "[Trial 1] Epoch 92/100\n",
      "[Trial 1] Epoch 93/100\n",
      "[Trial 1] Epoch 94/100\n",
      "[Trial 1] Epoch 95/100\n",
      "[Trial 1] Epoch 96/100\n",
      "[Trial 1] Epoch 97/100\n",
      "[Trial 1] Epoch 98/100\n",
      "[Trial 1] Epoch 99/100\n",
      "[Trial 1] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.00456468:   2%|▏         | 2/100 [33:03<27:01:44, 992.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 1\n",
      "[I 2025-08-07 10:46:53,093] Trial 1 finished with value: 0.12311635352671146 and parameters: {'LEARNING_RATE': 0.2, 'BATCH_SIZE': 128, 'HIDDEN_SIZE': 40, 'OPERATOR_SIZE': 10, 'LR_SCHEDULER_GAMMA': 0.9901076955415644, 'DECAY_EPOCH': 199}. Best is trial 0 with value: 0.004564675880828872.\n",
      "→ Start trial 2\n",
      "[Trial 2] Epoch 1/100\n",
      "[Trial 2] Epoch 2/100\n",
      "[Trial 2] Epoch 3/100\n",
      "[Trial 2] Epoch 4/100\n",
      "[Trial 2] Epoch 5/100\n",
      "[Trial 2] Epoch 6/100\n",
      "[Trial 2] Epoch 7/100\n",
      "[Trial 2] Epoch 8/100\n",
      "[Trial 2] Epoch 9/100\n",
      "[Trial 2] Epoch 10/100\n",
      "[Trial 2] Epoch 11/100\n",
      "[Trial 2] Epoch 12/100\n",
      "[Trial 2] Epoch 13/100\n",
      "[Trial 2] Epoch 14/100\n",
      "[Trial 2] Epoch 15/100\n",
      "[Trial 2] Epoch 16/100\n",
      "[Trial 2] Epoch 17/100\n",
      "[Trial 2] Epoch 18/100\n",
      "[Trial 2] Epoch 19/100\n",
      "[Trial 2] Epoch 20/100\n",
      "[Trial 2] Epoch 21/100\n",
      "[Trial 2] Epoch 22/100\n",
      "[Trial 2] Epoch 23/100\n",
      "[Trial 2] Epoch 24/100\n",
      "[Trial 2] Epoch 25/100\n",
      "[Trial 2] Epoch 26/100\n",
      "[Trial 2] Epoch 27/100\n",
      "[Trial 2] Epoch 28/100\n",
      "[Trial 2] Epoch 29/100\n",
      "[Trial 2] Epoch 30/100\n",
      "[Trial 2] Epoch 31/100\n",
      "[Trial 2] Epoch 32/100\n",
      "[Trial 2] Epoch 33/100\n",
      "[Trial 2] Epoch 34/100\n",
      "[Trial 2] Epoch 35/100\n",
      "[Trial 2] Epoch 36/100\n",
      "[Trial 2] Epoch 37/100\n",
      "[Trial 2] Epoch 38/100\n",
      "[Trial 2] Epoch 39/100\n",
      "[Trial 2] Epoch 40/100\n",
      "[Trial 2] Epoch 41/100\n",
      "[Trial 2] Epoch 42/100\n",
      "[Trial 2] Epoch 43/100\n",
      "[Trial 2] Epoch 44/100\n",
      "[Trial 2] Epoch 45/100\n",
      "[Trial 2] Epoch 46/100\n",
      "[Trial 2] Epoch 47/100\n",
      "[Trial 2] Epoch 48/100\n",
      "[Trial 2] Epoch 49/100\n",
      "[Trial 2] Epoch 50/100\n",
      "[Trial 2] Epoch 51/100\n",
      "[Trial 2] Epoch 52/100\n",
      "[Trial 2] Epoch 53/100\n",
      "[Trial 2] Epoch 54/100\n",
      "[Trial 2] Epoch 55/100\n",
      "[Trial 2] Epoch 56/100\n",
      "[Trial 2] Epoch 57/100\n",
      "[Trial 2] Epoch 58/100\n",
      "[Trial 2] Epoch 59/100\n",
      "[Trial 2] Epoch 60/100\n",
      "[Trial 2] Epoch 61/100\n",
      "[Trial 2] Epoch 62/100\n",
      "[Trial 2] Epoch 63/100\n",
      "[Trial 2] Epoch 64/100\n",
      "[Trial 2] Epoch 65/100\n",
      "[Trial 2] Epoch 66/100\n",
      "[Trial 2] Epoch 67/100\n",
      "[Trial 2] Epoch 68/100\n",
      "[Trial 2] Epoch 69/100\n",
      "[Trial 2] Epoch 70/100\n",
      "[Trial 2] Epoch 71/100\n",
      "[Trial 2] Epoch 72/100\n",
      "[Trial 2] Epoch 73/100\n",
      "[Trial 2] Epoch 74/100\n",
      "[Trial 2] Epoch 75/100\n",
      "[Trial 2] Epoch 76/100\n",
      "[Trial 2] Epoch 77/100\n",
      "[Trial 2] Epoch 78/100\n",
      "[Trial 2] Epoch 79/100\n",
      "[Trial 2] Epoch 80/100\n",
      "[Trial 2] Epoch 81/100\n",
      "[Trial 2] Epoch 82/100\n",
      "[Trial 2] Epoch 83/100\n",
      "[Trial 2] Epoch 84/100\n",
      "[Trial 2] Epoch 85/100\n",
      "[Trial 2] Epoch 86/100\n",
      "[Trial 2] Epoch 87/100\n",
      "[Trial 2] Epoch 88/100\n",
      "[Trial 2] Epoch 89/100\n",
      "[Trial 2] Epoch 90/100\n",
      "[Trial 2] Epoch 91/100\n",
      "[Trial 2] Epoch 92/100\n",
      "[Trial 2] Epoch 93/100\n",
      "[Trial 2] Epoch 94/100\n",
      "[Trial 2] Epoch 95/100\n",
      "[Trial 2] Epoch 96/100\n",
      "[Trial 2] Epoch 97/100\n",
      "[Trial 2] Epoch 98/100\n",
      "[Trial 2] Epoch 99/100\n",
      "[Trial 2] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.00456468:   3%|▎         | 3/100 [41:29<20:45:56, 770.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 2\n",
      "[I 2025-08-07 10:55:19,339] Trial 2 finished with value: 0.006902711349539459 and parameters: {'LEARNING_RATE': 0.1, 'BATCH_SIZE': 256, 'HIDDEN_SIZE': 20, 'OPERATOR_SIZE': 10, 'LR_SCHEDULER_GAMMA': 0.9861201648061483, 'DECAY_EPOCH': 155}. Best is trial 0 with value: 0.004564675880828872.\n",
      "→ Start trial 3\n",
      "[Trial 3] Epoch 1/100\n",
      "[Trial 3] Epoch 2/100\n",
      "[Trial 3] Epoch 3/100\n",
      "[Trial 3] Epoch 4/100\n",
      "[Trial 3] Epoch 5/100\n",
      "[Trial 3] Epoch 6/100\n",
      "[Trial 3] Epoch 7/100\n",
      "[Trial 3] Epoch 8/100\n",
      "[Trial 3] Epoch 9/100\n",
      "[Trial 3] Epoch 10/100\n",
      "[Trial 3] Epoch 11/100\n",
      "[Trial 3] Epoch 12/100\n",
      "[Trial 3] Epoch 13/100\n",
      "[Trial 3] Epoch 14/100\n",
      "[Trial 3] Epoch 15/100\n",
      "[Trial 3] Epoch 16/100\n",
      "[Trial 3] Epoch 17/100\n",
      "[Trial 3] Epoch 18/100\n",
      "[Trial 3] Epoch 19/100\n",
      "[Trial 3] Epoch 20/100\n",
      "[Trial 3] Epoch 21/100\n",
      "[Trial 3] Epoch 22/100\n",
      "[Trial 3] Epoch 23/100\n",
      "[Trial 3] Epoch 24/100\n",
      "[Trial 3] Epoch 25/100\n",
      "[Trial 3] Epoch 26/100\n",
      "[Trial 3] Epoch 27/100\n",
      "[Trial 3] Epoch 28/100\n",
      "[Trial 3] Epoch 29/100\n",
      "[Trial 3] Epoch 30/100\n",
      "[Trial 3] Epoch 31/100\n",
      "[Trial 3] Epoch 32/100\n",
      "[Trial 3] Epoch 33/100\n",
      "[Trial 3] Epoch 34/100\n",
      "[Trial 3] Epoch 35/100\n",
      "[Trial 3] Epoch 36/100\n",
      "[Trial 3] Epoch 37/100\n",
      "[Trial 3] Epoch 38/100\n",
      "[Trial 3] Epoch 39/100\n",
      "[Trial 3] Epoch 40/100\n",
      "[Trial 3] Epoch 41/100\n",
      "[Trial 3] Epoch 42/100\n",
      "[Trial 3] Epoch 43/100\n",
      "[Trial 3] Epoch 44/100\n",
      "[Trial 3] Epoch 45/100\n",
      "[Trial 3] Epoch 46/100\n",
      "[Trial 3] Epoch 47/100\n",
      "[Trial 3] Epoch 48/100\n",
      "[Trial 3] Epoch 49/100\n",
      "[Trial 3] Epoch 50/100\n",
      "[Trial 3] Epoch 51/100\n",
      "[Trial 3] Epoch 52/100\n",
      "[Trial 3] Epoch 53/100\n",
      "[Trial 3] Epoch 54/100\n",
      "[Trial 3] Epoch 55/100\n",
      "[Trial 3] Epoch 56/100\n",
      "[Trial 3] Epoch 57/100\n",
      "[Trial 3] Epoch 58/100\n",
      "[Trial 3] Epoch 59/100\n",
      "[Trial 3] Epoch 60/100\n",
      "[Trial 3] Epoch 61/100\n",
      "[Trial 3] Epoch 62/100\n",
      "[Trial 3] Epoch 63/100\n",
      "[Trial 3] Epoch 64/100\n",
      "[Trial 3] Epoch 65/100\n",
      "[Trial 3] Epoch 66/100\n",
      "[Trial 3] Epoch 67/100\n",
      "[Trial 3] Epoch 68/100\n",
      "[Trial 3] Epoch 69/100\n",
      "[Trial 3] Epoch 70/100\n",
      "[Trial 3] Epoch 71/100\n",
      "[Trial 3] Epoch 72/100\n",
      "[Trial 3] Epoch 73/100\n",
      "[Trial 3] Epoch 74/100\n",
      "[Trial 3] Epoch 75/100\n",
      "[Trial 3] Epoch 76/100\n",
      "[Trial 3] Epoch 77/100\n",
      "[Trial 3] Epoch 78/100\n",
      "[Trial 3] Epoch 79/100\n",
      "[Trial 3] Epoch 80/100\n",
      "[Trial 3] Epoch 81/100\n",
      "[Trial 3] Epoch 82/100\n",
      "[Trial 3] Epoch 83/100\n",
      "[Trial 3] Epoch 84/100\n",
      "[Trial 3] Epoch 85/100\n",
      "[Trial 3] Epoch 86/100\n",
      "[Trial 3] Epoch 87/100\n",
      "[Trial 3] Epoch 88/100\n",
      "[Trial 3] Epoch 89/100\n",
      "[Trial 3] Epoch 90/100\n",
      "[Trial 3] Epoch 91/100\n",
      "[Trial 3] Epoch 92/100\n",
      "[Trial 3] Epoch 93/100\n",
      "[Trial 3] Epoch 94/100\n",
      "[Trial 3] Epoch 95/100\n",
      "[Trial 3] Epoch 96/100\n",
      "[Trial 3] Epoch 97/100\n",
      "[Trial 3] Epoch 98/100\n",
      "[Trial 3] Epoch 99/100\n",
      "[Trial 3] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.00456468:   4%|▍         | 4/100 [50:30<18:08:15, 680.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 3\n",
      "[I 2025-08-07 11:04:20,736] Trial 3 finished with value: 0.005223997519351542 and parameters: {'LEARNING_RATE': 0.01, 'BATCH_SIZE': 256, 'HIDDEN_SIZE': 40, 'OPERATOR_SIZE': 20, 'LR_SCHEDULER_GAMMA': 0.9786860996498743, 'DECAY_EPOCH': 101}. Best is trial 0 with value: 0.004564675880828872.\n",
      "→ Start trial 4\n",
      "[Trial 4] Epoch 1/100\n",
      "[Trial 4] Epoch 2/100\n",
      "[Trial 4] Epoch 3/100\n",
      "[Trial 4] Epoch 4/100\n",
      "[Trial 4] Epoch 5/100\n",
      "[Trial 4] Epoch 6/100\n",
      "[Trial 4] Epoch 7/100\n",
      "[Trial 4] Epoch 8/100\n",
      "[Trial 4] Epoch 9/100\n",
      "[Trial 4] Epoch 10/100\n",
      "[Trial 4] Epoch 11/100\n",
      "[Trial 4] Epoch 12/100\n",
      "[Trial 4] Epoch 13/100\n",
      "[Trial 4] Epoch 14/100\n",
      "[Trial 4] Epoch 15/100\n",
      "[Trial 4] Epoch 16/100\n",
      "[Trial 4] Epoch 17/100\n",
      "[Trial 4] Epoch 18/100\n",
      "[Trial 4] Epoch 19/100\n",
      "[Trial 4] Epoch 20/100\n",
      "[Trial 4] Epoch 21/100\n",
      "[Trial 4] Epoch 22/100\n",
      "[Trial 4] Epoch 23/100\n",
      "[Trial 4] Epoch 24/100\n",
      "[Trial 4] Epoch 25/100\n",
      "[Trial 4] Epoch 26/100\n",
      "[Trial 4] Epoch 27/100\n",
      "[Trial 4] Epoch 28/100\n",
      "[Trial 4] Epoch 29/100\n",
      "[Trial 4] Epoch 30/100\n",
      "[Trial 4] Epoch 31/100\n",
      "[Trial 4] Epoch 32/100\n",
      "[Trial 4] Epoch 33/100\n",
      "[Trial 4] Epoch 34/100\n",
      "[Trial 4] Epoch 35/100\n",
      "[Trial 4] Epoch 36/100\n",
      "[Trial 4] Epoch 37/100\n",
      "[Trial 4] Epoch 38/100\n",
      "[Trial 4] Epoch 39/100\n",
      "[Trial 4] Epoch 40/100\n",
      "[Trial 4] Epoch 41/100\n",
      "[Trial 4] Epoch 42/100\n",
      "[Trial 4] Epoch 43/100\n",
      "[Trial 4] Epoch 44/100\n",
      "[Trial 4] Epoch 45/100\n",
      "[Trial 4] Epoch 46/100\n",
      "[Trial 4] Epoch 47/100\n",
      "[Trial 4] Epoch 48/100\n",
      "[Trial 4] Epoch 49/100\n",
      "[Trial 4] Epoch 50/100\n",
      "[Trial 4] Epoch 51/100\n",
      "[Trial 4] Epoch 52/100\n",
      "[Trial 4] Epoch 53/100\n",
      "[Trial 4] Epoch 54/100\n",
      "[Trial 4] Epoch 55/100\n",
      "[Trial 4] Epoch 56/100\n",
      "[Trial 4] Epoch 57/100\n",
      "[Trial 4] Epoch 58/100\n",
      "[Trial 4] Epoch 59/100\n",
      "[Trial 4] Epoch 60/100\n",
      "[Trial 4] Epoch 61/100\n",
      "[Trial 4] Epoch 62/100\n",
      "[Trial 4] Epoch 63/100\n",
      "[Trial 4] Epoch 64/100\n",
      "[Trial 4] Epoch 65/100\n",
      "[Trial 4] Epoch 66/100\n",
      "[Trial 4] Epoch 67/100\n",
      "[Trial 4] Epoch 68/100\n",
      "[Trial 4] Epoch 69/100\n",
      "[Trial 4] Epoch 70/100\n",
      "[Trial 4] Epoch 71/100\n",
      "[Trial 4] Epoch 72/100\n",
      "[Trial 4] Epoch 73/100\n",
      "[Trial 4] Epoch 74/100\n",
      "[Trial 4] Epoch 75/100\n",
      "[Trial 4] Epoch 76/100\n",
      "[Trial 4] Epoch 77/100\n",
      "[Trial 4] Epoch 78/100\n",
      "[Trial 4] Epoch 79/100\n",
      "[Trial 4] Epoch 80/100\n",
      "[Trial 4] Epoch 81/100\n",
      "[Trial 4] Epoch 82/100\n",
      "[Trial 4] Epoch 83/100\n",
      "[Trial 4] Epoch 84/100\n",
      "[Trial 4] Epoch 85/100\n",
      "[Trial 4] Epoch 86/100\n",
      "[Trial 4] Epoch 87/100\n",
      "[Trial 4] Epoch 88/100\n",
      "[Trial 4] Epoch 89/100\n",
      "[Trial 4] Epoch 90/100\n",
      "[Trial 4] Epoch 91/100\n",
      "[Trial 4] Epoch 92/100\n",
      "[Trial 4] Epoch 93/100\n",
      "[Trial 4] Epoch 94/100\n",
      "[Trial 4] Epoch 95/100\n",
      "[Trial 4] Epoch 96/100\n",
      "[Trial 4] Epoch 97/100\n",
      "[Trial 4] Epoch 98/100\n",
      "[Trial 4] Epoch 99/100\n",
      "[Trial 4] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.00456468:   5%|▌         | 5/100 [1:01:41<17:51:23, 676.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 4\n",
      "[I 2025-08-07 11:15:31,201] Trial 4 finished with value: 3.1357113122940063 and parameters: {'LEARNING_RATE': 0.2, 'BATCH_SIZE': 256, 'HIDDEN_SIZE': 40, 'OPERATOR_SIZE': 10, 'LR_SCHEDULER_GAMMA': 0.9709325730640983, 'DECAY_EPOCH': 251}. Best is trial 0 with value: 0.004564675880828872.\n",
      "→ Start trial 5\n",
      "[Trial 5] Epoch 1/100\n",
      "[Trial 5] Epoch 2/100\n",
      "[Trial 5] Epoch 3/100\n",
      "[Trial 5] Epoch 4/100\n",
      "[Trial 5] Epoch 5/100\n",
      "[Trial 5] Epoch 6/100\n",
      "[Trial 5] Epoch 7/100\n",
      "[Trial 5] Epoch 8/100\n",
      "[Trial 5] Epoch 9/100\n",
      "[Trial 5] Epoch 10/100\n",
      "[Trial 5] Epoch 11/100\n",
      "[Trial 5] Epoch 12/100\n",
      "[Trial 5] Epoch 13/100\n",
      "[Trial 5] Epoch 14/100\n",
      "[Trial 5] Epoch 15/100\n",
      "[Trial 5] Epoch 16/100\n",
      "[Trial 5] Epoch 17/100\n",
      "[Trial 5] Epoch 18/100\n",
      "[Trial 5] Epoch 19/100\n",
      "[Trial 5] Epoch 20/100\n",
      "[Trial 5] Epoch 21/100\n",
      "[Trial 5] Epoch 22/100\n",
      "[Trial 5] Epoch 23/100\n",
      "[Trial 5] Epoch 24/100\n",
      "[Trial 5] Epoch 25/100\n",
      "[Trial 5] Epoch 26/100\n",
      "[Trial 5] Epoch 27/100\n",
      "[Trial 5] Epoch 28/100\n",
      "[Trial 5] Epoch 29/100\n",
      "[Trial 5] Epoch 30/100\n",
      "[Trial 5] Epoch 31/100\n",
      "[Trial 5] Epoch 32/100\n",
      "[Trial 5] Epoch 33/100\n",
      "[Trial 5] Epoch 34/100\n",
      "[Trial 5] Epoch 35/100\n",
      "[Trial 5] Epoch 36/100\n",
      "[Trial 5] Epoch 37/100\n",
      "[Trial 5] Epoch 38/100\n",
      "[Trial 5] Epoch 39/100\n",
      "[Trial 5] Epoch 40/100\n",
      "[Trial 5] Epoch 41/100\n",
      "[Trial 5] Epoch 42/100\n",
      "[Trial 5] Epoch 43/100\n",
      "[Trial 5] Epoch 44/100\n",
      "[Trial 5] Epoch 45/100\n",
      "[Trial 5] Epoch 46/100\n",
      "[Trial 5] Epoch 47/100\n",
      "[Trial 5] Epoch 48/100\n",
      "[Trial 5] Epoch 49/100\n",
      "[Trial 5] Epoch 50/100\n",
      "[Trial 5] Epoch 51/100\n",
      "[Trial 5] Epoch 52/100\n",
      "[Trial 5] Epoch 53/100\n",
      "[Trial 5] Epoch 54/100\n",
      "[Trial 5] Epoch 55/100\n",
      "[Trial 5] Epoch 56/100\n",
      "[Trial 5] Epoch 57/100\n",
      "[Trial 5] Epoch 58/100\n",
      "[Trial 5] Epoch 59/100\n",
      "[Trial 5] Epoch 60/100\n",
      "[Trial 5] Epoch 61/100\n",
      "[Trial 5] Epoch 62/100\n",
      "[Trial 5] Epoch 63/100\n",
      "[Trial 5] Epoch 64/100\n",
      "[Trial 5] Epoch 65/100\n",
      "[Trial 5] Epoch 66/100\n",
      "[Trial 5] Epoch 67/100\n",
      "[Trial 5] Epoch 68/100\n",
      "[Trial 5] Epoch 69/100\n",
      "[Trial 5] Epoch 70/100\n",
      "[Trial 5] Epoch 71/100\n",
      "[Trial 5] Epoch 72/100\n",
      "[Trial 5] Epoch 73/100\n",
      "[Trial 5] Epoch 74/100\n",
      "[Trial 5] Epoch 75/100\n",
      "[Trial 5] Epoch 76/100\n",
      "[Trial 5] Epoch 77/100\n",
      "[Trial 5] Epoch 78/100\n",
      "[Trial 5] Epoch 79/100\n",
      "[Trial 5] Epoch 80/100\n",
      "[Trial 5] Epoch 81/100\n",
      "[Trial 5] Epoch 82/100\n",
      "[Trial 5] Epoch 83/100\n",
      "[Trial 5] Epoch 84/100\n",
      "[Trial 5] Epoch 85/100\n",
      "[Trial 5] Epoch 86/100\n",
      "[Trial 5] Epoch 87/100\n",
      "[Trial 5] Epoch 88/100\n",
      "[Trial 5] Epoch 89/100\n",
      "[Trial 5] Epoch 90/100\n",
      "[Trial 5] Epoch 91/100\n",
      "[Trial 5] Epoch 92/100\n",
      "[Trial 5] Epoch 93/100\n",
      "[Trial 5] Epoch 94/100\n",
      "[Trial 5] Epoch 95/100\n",
      "[Trial 5] Epoch 96/100\n",
      "[Trial 5] Epoch 97/100\n",
      "[Trial 5] Epoch 98/100\n",
      "[Trial 5] Epoch 99/100\n",
      "[Trial 5] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.00456468:   6%|▌         | 6/100 [1:22:08<22:33:33, 863.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 5\n",
      "[I 2025-08-07 11:35:58,779] Trial 5 finished with value: 0.005075091205071658 and parameters: {'LEARNING_RATE': 0.1, 'BATCH_SIZE': 128, 'HIDDEN_SIZE': 20, 'OPERATOR_SIZE': 40, 'LR_SCHEDULER_GAMMA': 0.9788050660211298, 'DECAY_EPOCH': 72}. Best is trial 0 with value: 0.004564675880828872.\n",
      "→ Start trial 6\n",
      "[Trial 6] Epoch 1/100\n",
      "[Trial 6] Epoch 2/100\n",
      "[Trial 6] Epoch 3/100\n",
      "[Trial 6] Epoch 4/100\n",
      "[Trial 6] Epoch 5/100\n",
      "[Trial 6] Epoch 6/100\n",
      "[Trial 6] Epoch 7/100\n",
      "[Trial 6] Epoch 8/100\n",
      "[Trial 6] Epoch 9/100\n",
      "[Trial 6] Epoch 10/100\n",
      "[Trial 6] Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.00456468:   7%|▋         | 7/100 [1:26:05<17:01:16, 658.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 11:39:55,413] Trial 6 pruned. \n",
      "→ Start trial 7\n",
      "[Trial 7] Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.00456468:   8%|▊         | 8/100 [1:26:13<11:32:34, 451.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 11:40:03,422] Trial 7 pruned. \n",
      "→ Start trial 8\n",
      "[Trial 8] Epoch 1/100\n",
      "[Trial 8] Epoch 2/100\n",
      "[Trial 8] Epoch 3/100\n",
      "[Trial 8] Epoch 4/100\n",
      "[Trial 8] Epoch 5/100\n",
      "[Trial 8] Epoch 6/100\n",
      "[Trial 8] Epoch 7/100\n",
      "[Trial 8] Epoch 8/100\n",
      "[Trial 8] Epoch 9/100\n",
      "[Trial 8] Epoch 10/100\n",
      "[Trial 8] Epoch 11/100\n",
      "[Trial 8] Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.00456468:   9%|▉         | 9/100 [1:28:16<8:49:25, 349.07s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 11:42:06,888] Trial 8 pruned. \n",
      "→ Start trial 9\n",
      "[Trial 9] Epoch 1/100\n",
      "[Trial 9] Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.00456468:  10%|█         | 10/100 [1:29:01<6:22:34, 255.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 11:42:51,421] Trial 9 pruned. \n",
      "→ Start trial 10\n",
      "[Trial 10] Epoch 1/100\n",
      "[Trial 10] Epoch 2/100\n",
      "[Trial 10] Epoch 3/100\n",
      "[Trial 10] Epoch 4/100\n",
      "[Trial 10] Epoch 5/100\n",
      "[Trial 10] Epoch 6/100\n",
      "[Trial 10] Epoch 7/100\n",
      "[Trial 10] Epoch 8/100\n",
      "[Trial 10] Epoch 9/100\n",
      "[Trial 10] Epoch 10/100\n",
      "[Trial 10] Epoch 11/100\n",
      "[Trial 10] Epoch 12/100\n",
      "[Trial 10] Epoch 13/100\n",
      "[Trial 10] Epoch 14/100\n",
      "[Trial 10] Epoch 15/100\n",
      "[Trial 10] Epoch 16/100\n",
      "[Trial 10] Epoch 17/100\n",
      "[Trial 10] Epoch 18/100\n",
      "[Trial 10] Epoch 19/100\n",
      "[Trial 10] Epoch 20/100\n",
      "[Trial 10] Epoch 21/100\n",
      "[Trial 10] Epoch 22/100\n",
      "[Trial 10] Epoch 23/100\n",
      "[Trial 10] Epoch 24/100\n",
      "[Trial 10] Epoch 25/100\n",
      "[Trial 10] Epoch 26/100\n",
      "[Trial 10] Epoch 27/100\n",
      "[Trial 10] Epoch 28/100\n",
      "[Trial 10] Epoch 29/100\n",
      "[Trial 10] Epoch 30/100\n",
      "[Trial 10] Epoch 31/100\n",
      "[Trial 10] Epoch 32/100\n",
      "[Trial 10] Epoch 33/100\n",
      "[Trial 10] Epoch 34/100\n",
      "[Trial 10] Epoch 35/100\n",
      "[Trial 10] Epoch 36/100\n",
      "[Trial 10] Epoch 37/100\n",
      "[Trial 10] Epoch 38/100\n",
      "[Trial 10] Epoch 39/100\n",
      "[Trial 10] Epoch 40/100\n",
      "[Trial 10] Epoch 41/100\n",
      "[Trial 10] Epoch 42/100\n",
      "[Trial 10] Epoch 43/100\n",
      "[Trial 10] Epoch 44/100\n",
      "[Trial 10] Epoch 45/100\n",
      "[Trial 10] Epoch 46/100\n",
      "[Trial 10] Epoch 47/100\n",
      "[Trial 10] Epoch 48/100\n",
      "[Trial 10] Epoch 49/100\n",
      "[Trial 10] Epoch 50/100\n",
      "[Trial 10] Epoch 51/100\n",
      "[Trial 10] Epoch 52/100\n",
      "[Trial 10] Epoch 53/100\n",
      "[Trial 10] Epoch 54/100\n",
      "[Trial 10] Epoch 55/100\n",
      "[Trial 10] Epoch 56/100\n",
      "[Trial 10] Epoch 57/100\n",
      "[Trial 10] Epoch 58/100\n",
      "[Trial 10] Epoch 59/100\n",
      "[Trial 10] Epoch 60/100\n",
      "[Trial 10] Epoch 61/100\n",
      "[Trial 10] Epoch 62/100\n",
      "[Trial 10] Epoch 63/100\n",
      "[Trial 10] Epoch 64/100\n",
      "[Trial 10] Epoch 65/100\n",
      "[Trial 10] Epoch 66/100\n",
      "[Trial 10] Epoch 67/100\n",
      "[Trial 10] Epoch 68/100\n",
      "[Trial 10] Epoch 69/100\n",
      "[Trial 10] Epoch 70/100\n",
      "[Trial 10] Epoch 71/100\n",
      "[Trial 10] Epoch 72/100\n",
      "[Trial 10] Epoch 73/100\n",
      "[Trial 10] Epoch 74/100\n",
      "[Trial 10] Epoch 75/100\n",
      "[Trial 10] Epoch 76/100\n",
      "[Trial 10] Epoch 77/100\n",
      "[Trial 10] Epoch 78/100\n",
      "[Trial 10] Epoch 79/100\n",
      "[Trial 10] Epoch 80/100\n",
      "[Trial 10] Epoch 81/100\n",
      "[Trial 10] Epoch 82/100\n",
      "[Trial 10] Epoch 83/100\n",
      "[Trial 10] Epoch 84/100\n",
      "[Trial 10] Epoch 85/100\n",
      "[Trial 10] Epoch 86/100\n",
      "[Trial 10] Epoch 87/100\n",
      "[Trial 10] Epoch 88/100\n",
      "[Trial 10] Epoch 89/100\n",
      "[Trial 10] Epoch 90/100\n",
      "[Trial 10] Epoch 91/100\n",
      "[Trial 10] Epoch 92/100\n",
      "[Trial 10] Epoch 93/100\n",
      "[Trial 10] Epoch 94/100\n",
      "[Trial 10] Epoch 95/100\n",
      "[Trial 10] Epoch 96/100\n",
      "[Trial 10] Epoch 97/100\n",
      "[Trial 10] Epoch 98/100\n",
      "[Trial 10] Epoch 99/100\n",
      "[Trial 10] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.0040235:  11%|█         | 11/100 [1:44:27<11:23:06, 460.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 10\n",
      "[I 2025-08-07 11:58:17,824] Trial 10 finished with value: 0.004023504598687093 and parameters: {'LEARNING_RATE': 0.05, 'BATCH_SIZE': 192, 'HIDDEN_SIZE': 10, 'OPERATOR_SIZE': 30, 'LR_SCHEDULER_GAMMA': 0.9985197192545563, 'DECAY_EPOCH': 385}. Best is trial 10 with value: 0.004023504598687093.\n",
      "→ Start trial 11\n",
      "[Trial 11] Epoch 1/100\n",
      "[Trial 11] Epoch 2/100\n",
      "[Trial 11] Epoch 3/100\n",
      "[Trial 11] Epoch 4/100\n",
      "[Trial 11] Epoch 5/100\n",
      "[Trial 11] Epoch 6/100\n",
      "[Trial 11] Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.0040235:  12%|█▏        | 12/100 [1:45:36<8:20:45, 341.43s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 11:59:26,864] Trial 11 pruned. \n",
      "→ Start trial 12\n",
      "[Trial 12] Epoch 1/100\n",
      "[Trial 12] Epoch 2/100\n",
      "[Trial 12] Epoch 3/100\n",
      "[Trial 12] Epoch 4/100\n",
      "[Trial 12] Epoch 5/100\n",
      "[Trial 12] Epoch 6/100\n",
      "[Trial 12] Epoch 7/100\n",
      "[Trial 12] Epoch 8/100\n",
      "[Trial 12] Epoch 9/100\n",
      "[Trial 12] Epoch 10/100\n",
      "[Trial 12] Epoch 11/100\n",
      "[Trial 12] Epoch 12/100\n",
      "[Trial 12] Epoch 13/100\n",
      "[Trial 12] Epoch 14/100\n",
      "[Trial 12] Epoch 15/100\n",
      "[Trial 12] Epoch 16/100\n",
      "[Trial 12] Epoch 17/100\n",
      "[Trial 12] Epoch 18/100\n",
      "[Trial 12] Epoch 19/100\n",
      "[Trial 12] Epoch 20/100\n",
      "[Trial 12] Epoch 21/100\n",
      "[Trial 12] Epoch 22/100\n",
      "[Trial 12] Epoch 23/100\n",
      "[Trial 12] Epoch 24/100\n",
      "[Trial 12] Epoch 25/100\n",
      "[Trial 12] Epoch 26/100\n",
      "[Trial 12] Epoch 27/100\n",
      "[Trial 12] Epoch 28/100\n",
      "[Trial 12] Epoch 29/100\n",
      "[Trial 12] Epoch 30/100\n",
      "[Trial 12] Epoch 31/100\n",
      "[Trial 12] Epoch 32/100\n",
      "[Trial 12] Epoch 33/100\n",
      "[Trial 12] Epoch 34/100\n",
      "[Trial 12] Epoch 35/100\n",
      "[Trial 12] Epoch 36/100\n",
      "[Trial 12] Epoch 37/100\n",
      "[Trial 12] Epoch 38/100\n",
      "[Trial 12] Epoch 39/100\n",
      "[Trial 12] Epoch 40/100\n",
      "[Trial 12] Epoch 41/100\n",
      "[Trial 12] Epoch 42/100\n",
      "[Trial 12] Epoch 43/100\n",
      "[Trial 12] Epoch 44/100\n",
      "[Trial 12] Epoch 45/100\n",
      "[Trial 12] Epoch 46/100\n",
      "[Trial 12] Epoch 47/100\n",
      "[Trial 12] Epoch 48/100\n",
      "[Trial 12] Epoch 49/100\n",
      "[Trial 12] Epoch 50/100\n",
      "[Trial 12] Epoch 51/100\n",
      "[Trial 12] Epoch 52/100\n",
      "[Trial 12] Epoch 53/100\n",
      "[Trial 12] Epoch 54/100\n",
      "[Trial 12] Epoch 55/100\n",
      "[Trial 12] Epoch 56/100\n",
      "[Trial 12] Epoch 57/100\n",
      "[Trial 12] Epoch 58/100\n",
      "[Trial 12] Epoch 59/100\n",
      "[Trial 12] Epoch 60/100\n",
      "[Trial 12] Epoch 61/100\n",
      "[Trial 12] Epoch 62/100\n",
      "[Trial 12] Epoch 63/100\n",
      "[Trial 12] Epoch 64/100\n",
      "[Trial 12] Epoch 65/100\n",
      "[Trial 12] Epoch 66/100\n",
      "[Trial 12] Epoch 67/100\n",
      "[Trial 12] Epoch 68/100\n",
      "[Trial 12] Epoch 69/100\n",
      "[Trial 12] Epoch 70/100\n",
      "[Trial 12] Epoch 71/100\n",
      "[Trial 12] Epoch 72/100\n",
      "[Trial 12] Epoch 73/100\n",
      "[Trial 12] Epoch 74/100\n",
      "[Trial 12] Epoch 75/100\n",
      "[Trial 12] Epoch 76/100\n",
      "[Trial 12] Epoch 77/100\n",
      "[Trial 12] Epoch 78/100\n",
      "[Trial 12] Epoch 79/100\n",
      "[Trial 12] Epoch 80/100\n",
      "[Trial 12] Epoch 81/100\n",
      "[Trial 12] Epoch 82/100\n",
      "[Trial 12] Epoch 83/100\n",
      "[Trial 12] Epoch 84/100\n",
      "[Trial 12] Epoch 85/100\n",
      "[Trial 12] Epoch 86/100\n",
      "[Trial 12] Epoch 87/100\n",
      "[Trial 12] Epoch 88/100\n",
      "[Trial 12] Epoch 89/100\n",
      "[Trial 12] Epoch 90/100\n",
      "[Trial 12] Epoch 91/100\n",
      "[Trial 12] Epoch 92/100\n",
      "[Trial 12] Epoch 93/100\n",
      "[Trial 12] Epoch 94/100\n",
      "[Trial 12] Epoch 95/100\n",
      "[Trial 12] Epoch 96/100\n",
      "[Trial 12] Epoch 97/100\n",
      "[Trial 12] Epoch 98/100\n",
      "[Trial 12] Epoch 99/100\n",
      "[Trial 12] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.00228249:  13%|█▎        | 13/100 [2:01:05<12:32:52, 519.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 12\n",
      "[I 2025-08-07 12:14:55,202] Trial 12 finished with value: 0.002282491923930744 and parameters: {'LEARNING_RATE': 0.05, 'BATCH_SIZE': 192, 'HIDDEN_SIZE': 10, 'OPERATOR_SIZE': 30, 'LR_SCHEDULER_GAMMA': 0.997258429370965, 'DECAY_EPOCH': 499}. Best is trial 12 with value: 0.002282491923930744.\n",
      "→ Start trial 13\n",
      "[Trial 13] Epoch 1/100\n",
      "[Trial 13] Epoch 2/100\n",
      "[Trial 13] Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.00228249:  14%|█▍        | 14/100 [2:01:36<8:53:07, 371.95s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 12:15:26,822] Trial 13 pruned. \n",
      "→ Start trial 14\n",
      "[Trial 14] Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.00228249:  15%|█▌        | 15/100 [2:01:50<6:13:59, 263.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 12:15:40,642] Trial 14 pruned. \n",
      "→ Start trial 15\n",
      "[Trial 15] Epoch 1/100\n",
      "[Trial 15] Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.00228249:  16%|█▌        | 16/100 [2:02:13<4:27:49, 191.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 12:16:03,124] Trial 15 pruned. \n",
      "→ Start trial 16\n",
      "[Trial 16] Epoch 1/100\n",
      "[Trial 16] Epoch 2/100\n",
      "[Trial 16] Epoch 3/100\n",
      "[Trial 16] Epoch 4/100\n",
      "[Trial 16] Epoch 5/100\n",
      "[Trial 16] Epoch 6/100\n",
      "[Trial 16] Epoch 7/100\n",
      "[Trial 16] Epoch 8/100\n",
      "[Trial 16] Epoch 9/100\n",
      "[Trial 16] Epoch 10/100\n",
      "[Trial 16] Epoch 11/100\n",
      "[Trial 16] Epoch 12/100\n",
      "[Trial 16] Epoch 13/100\n",
      "[Trial 16] Epoch 14/100\n",
      "[Trial 16] Epoch 15/100\n",
      "[Trial 16] Epoch 16/100\n",
      "[Trial 16] Epoch 17/100\n",
      "[Trial 16] Epoch 18/100\n",
      "[Trial 16] Epoch 19/100\n",
      "[Trial 16] Epoch 20/100\n",
      "[Trial 16] Epoch 21/100\n",
      "[Trial 16] Epoch 22/100\n",
      "[Trial 16] Epoch 23/100\n",
      "[Trial 16] Epoch 24/100\n",
      "[Trial 16] Epoch 25/100\n",
      "[Trial 16] Epoch 26/100\n",
      "[Trial 16] Epoch 27/100\n",
      "[Trial 16] Epoch 28/100\n",
      "[Trial 16] Epoch 29/100\n",
      "[Trial 16] Epoch 30/100\n",
      "[Trial 16] Epoch 31/100\n",
      "[Trial 16] Epoch 32/100\n",
      "[Trial 16] Epoch 33/100\n",
      "[Trial 16] Epoch 34/100\n",
      "[Trial 16] Epoch 35/100\n",
      "[Trial 16] Epoch 36/100\n",
      "[Trial 16] Epoch 37/100\n",
      "[Trial 16] Epoch 38/100\n",
      "[Trial 16] Epoch 39/100\n",
      "[Trial 16] Epoch 40/100\n",
      "[Trial 16] Epoch 41/100\n",
      "[Trial 16] Epoch 42/100\n",
      "[Trial 16] Epoch 43/100\n",
      "[Trial 16] Epoch 44/100\n",
      "[Trial 16] Epoch 45/100\n",
      "[Trial 16] Epoch 46/100\n",
      "[Trial 16] Epoch 47/100\n",
      "[Trial 16] Epoch 48/100\n",
      "[Trial 16] Epoch 49/100\n",
      "[Trial 16] Epoch 50/100\n",
      "[Trial 16] Epoch 51/100\n",
      "[Trial 16] Epoch 52/100\n",
      "[Trial 16] Epoch 53/100\n",
      "[Trial 16] Epoch 54/100\n",
      "[Trial 16] Epoch 55/100\n",
      "[Trial 16] Epoch 56/100\n",
      "[Trial 16] Epoch 57/100\n",
      "[Trial 16] Epoch 58/100\n",
      "[Trial 16] Epoch 59/100\n",
      "[Trial 16] Epoch 60/100\n",
      "[Trial 16] Epoch 61/100\n",
      "[Trial 16] Epoch 62/100\n",
      "[Trial 16] Epoch 63/100\n",
      "[Trial 16] Epoch 64/100\n",
      "[Trial 16] Epoch 65/100\n",
      "[Trial 16] Epoch 66/100\n",
      "[Trial 16] Epoch 67/100\n",
      "[Trial 16] Epoch 68/100\n",
      "[Trial 16] Epoch 69/100\n",
      "[Trial 16] Epoch 70/100\n",
      "[Trial 16] Epoch 71/100\n",
      "[Trial 16] Epoch 72/100\n",
      "[Trial 16] Epoch 73/100\n",
      "[Trial 16] Epoch 74/100\n",
      "[Trial 16] Epoch 75/100\n",
      "[Trial 16] Epoch 76/100\n",
      "[Trial 16] Epoch 77/100\n",
      "[Trial 16] Epoch 78/100\n",
      "[Trial 16] Epoch 79/100\n",
      "[Trial 16] Epoch 80/100\n",
      "[Trial 16] Epoch 81/100\n",
      "[Trial 16] Epoch 82/100\n",
      "[Trial 16] Epoch 83/100\n",
      "[Trial 16] Epoch 84/100\n",
      "[Trial 16] Epoch 85/100\n",
      "[Trial 16] Epoch 86/100\n",
      "[Trial 16] Epoch 87/100\n",
      "[Trial 16] Epoch 88/100\n",
      "[Trial 16] Epoch 89/100\n",
      "[Trial 16] Epoch 90/100\n",
      "[Trial 16] Epoch 91/100\n",
      "[Trial 16] Epoch 92/100\n",
      "[Trial 16] Epoch 93/100\n",
      "[Trial 16] Epoch 94/100\n",
      "[Trial 16] Epoch 95/100\n",
      "[Trial 16] Epoch 96/100\n",
      "[Trial 16] Epoch 97/100\n",
      "[Trial 16] Epoch 98/100\n",
      "[Trial 16] Epoch 99/100\n",
      "[Trial 16] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.00228249:  17%|█▋        | 17/100 [2:17:12<9:19:08, 404.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 16\n",
      "[I 2025-08-07 12:31:02,445] Trial 16 finished with value: 0.0032647619179139533 and parameters: {'LEARNING_RATE': 0.05, 'BATCH_SIZE': 192, 'HIDDEN_SIZE': 10, 'OPERATOR_SIZE': 20, 'LR_SCHEDULER_GAMMA': 0.9507264252646827, 'DECAY_EPOCH': 352}. Best is trial 12 with value: 0.002282491923930744.\n",
      "→ Start trial 17\n",
      "[Trial 17] Epoch 1/100\n",
      "[Trial 17] Epoch 2/100\n",
      "[Trial 17] Epoch 3/100\n",
      "[Trial 17] Epoch 4/100\n",
      "[Trial 17] Epoch 5/100\n",
      "[Trial 17] Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.00228249:  18%|█▊        | 18/100 [2:18:11<6:50:40, 300.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 12:32:01,505] Trial 17 pruned. \n",
      "→ Start trial 18\n",
      "[Trial 18] Epoch 1/100\n",
      "[Trial 18] Epoch 2/100\n",
      "[Trial 18] Epoch 3/100\n",
      "[Trial 18] Epoch 4/100\n",
      "[Trial 18] Epoch 5/100\n",
      "[Trial 18] Epoch 6/100\n",
      "[Trial 18] Epoch 7/100\n",
      "[Trial 18] Epoch 8/100\n",
      "[Trial 18] Epoch 9/100\n",
      "[Trial 18] Epoch 10/100\n",
      "[Trial 18] Epoch 11/100\n",
      "[Trial 18] Epoch 12/100\n",
      "[Trial 18] Epoch 13/100\n",
      "[Trial 18] Epoch 14/100\n",
      "[Trial 18] Epoch 15/100\n",
      "[Trial 18] Epoch 16/100\n",
      "[Trial 18] Epoch 17/100\n",
      "[Trial 18] Epoch 18/100\n",
      "[Trial 18] Epoch 19/100\n",
      "[Trial 18] Epoch 20/100\n",
      "[Trial 18] Epoch 21/100\n",
      "[Trial 18] Epoch 22/100\n",
      "[Trial 18] Epoch 23/100\n",
      "[Trial 18] Epoch 24/100\n",
      "[Trial 18] Epoch 25/100\n",
      "[Trial 18] Epoch 26/100\n",
      "[Trial 18] Epoch 27/100\n",
      "[Trial 18] Epoch 28/100\n",
      "[Trial 18] Epoch 29/100\n",
      "[Trial 18] Epoch 30/100\n",
      "[Trial 18] Epoch 31/100\n",
      "[Trial 18] Epoch 32/100\n",
      "[Trial 18] Epoch 33/100\n",
      "[Trial 18] Epoch 34/100\n",
      "[Trial 18] Epoch 35/100\n",
      "[Trial 18] Epoch 36/100\n",
      "[Trial 18] Epoch 37/100\n",
      "[Trial 18] Epoch 38/100\n",
      "[Trial 18] Epoch 39/100\n",
      "[Trial 18] Epoch 40/100\n",
      "[Trial 18] Epoch 41/100\n",
      "[Trial 18] Epoch 42/100\n",
      "[Trial 18] Epoch 43/100\n",
      "[Trial 18] Epoch 44/100\n",
      "[Trial 18] Epoch 45/100\n",
      "[Trial 18] Epoch 46/100\n",
      "[Trial 18] Epoch 47/100\n",
      "[Trial 18] Epoch 48/100\n",
      "[Trial 18] Epoch 49/100\n",
      "[Trial 18] Epoch 50/100\n",
      "[Trial 18] Epoch 51/100\n",
      "[Trial 18] Epoch 52/100\n",
      "[Trial 18] Epoch 53/100\n",
      "[Trial 18] Epoch 54/100\n",
      "[Trial 18] Epoch 55/100\n",
      "[Trial 18] Epoch 56/100\n",
      "[Trial 18] Epoch 57/100\n",
      "[Trial 18] Epoch 58/100\n",
      "[Trial 18] Epoch 59/100\n",
      "[Trial 18] Epoch 60/100\n",
      "[Trial 18] Epoch 61/100\n",
      "[Trial 18] Epoch 62/100\n",
      "[Trial 18] Epoch 63/100\n",
      "[Trial 18] Epoch 64/100\n",
      "[Trial 18] Epoch 65/100\n",
      "[Trial 18] Epoch 66/100\n",
      "[Trial 18] Epoch 67/100\n",
      "[Trial 18] Epoch 68/100\n",
      "[Trial 18] Epoch 69/100\n",
      "[Trial 18] Epoch 70/100\n",
      "[Trial 18] Epoch 71/100\n",
      "[Trial 18] Epoch 72/100\n",
      "[Trial 18] Epoch 73/100\n",
      "[Trial 18] Epoch 74/100\n",
      "[Trial 18] Epoch 75/100\n",
      "[Trial 18] Epoch 76/100\n",
      "[Trial 18] Epoch 77/100\n",
      "[Trial 18] Epoch 78/100\n",
      "[Trial 18] Epoch 79/100\n",
      "[Trial 18] Epoch 80/100\n",
      "[Trial 18] Epoch 81/100\n",
      "[Trial 18] Epoch 82/100\n",
      "[Trial 18] Epoch 83/100\n",
      "[Trial 18] Epoch 84/100\n",
      "[Trial 18] Epoch 85/100\n",
      "[Trial 18] Epoch 86/100\n",
      "[Trial 18] Epoch 87/100\n",
      "[Trial 18] Epoch 88/100\n",
      "[Trial 18] Epoch 89/100\n",
      "[Trial 18] Epoch 90/100\n",
      "[Trial 18] Epoch 91/100\n",
      "[Trial 18] Epoch 92/100\n",
      "[Trial 18] Epoch 93/100\n",
      "[Trial 18] Epoch 94/100\n",
      "[Trial 18] Epoch 95/100\n",
      "[Trial 18] Epoch 96/100\n",
      "[Trial 18] Epoch 97/100\n",
      "[Trial 18] Epoch 98/100\n",
      "[Trial 18] Epoch 99/100\n",
      "[Trial 18] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.00228249:  19%|█▉        | 19/100 [2:39:25<13:20:33, 593.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 18\n",
      "[I 2025-08-07 12:53:15,954] Trial 18 finished with value: 0.0031723937718197703 and parameters: {'LEARNING_RATE': 0.05, 'BATCH_SIZE': 128, 'HIDDEN_SIZE': 30, 'OPERATOR_SIZE': 20, 'LR_SCHEDULER_GAMMA': 0.9618986808801977, 'DECAY_EPOCH': 452}. Best is trial 12 with value: 0.002282491923930744.\n",
      "→ Start trial 19\n",
      "[Trial 19] Epoch 1/100\n",
      "[Trial 19] Epoch 2/100\n",
      "[Trial 19] Epoch 3/100\n",
      "[Trial 19] Epoch 4/100\n",
      "[Trial 19] Epoch 5/100\n",
      "[Trial 19] Epoch 6/100\n",
      "[Trial 19] Epoch 7/100\n",
      "[Trial 19] Epoch 8/100\n",
      "[Trial 19] Epoch 9/100\n",
      "[Trial 19] Epoch 10/100\n",
      "[Trial 19] Epoch 11/100\n",
      "[Trial 19] Epoch 12/100\n",
      "[Trial 19] Epoch 13/100\n",
      "[Trial 19] Epoch 14/100\n",
      "[Trial 19] Epoch 15/100\n",
      "[Trial 19] Epoch 16/100\n",
      "[Trial 19] Epoch 17/100\n",
      "[Trial 19] Epoch 18/100\n",
      "[Trial 19] Epoch 19/100\n",
      "[Trial 19] Epoch 20/100\n",
      "[Trial 19] Epoch 21/100\n",
      "[Trial 19] Epoch 22/100\n",
      "[Trial 19] Epoch 23/100\n",
      "[Trial 19] Epoch 24/100\n",
      "[Trial 19] Epoch 25/100\n",
      "[Trial 19] Epoch 26/100\n",
      "[Trial 19] Epoch 27/100\n",
      "[Trial 19] Epoch 28/100\n",
      "[Trial 19] Epoch 29/100\n",
      "[Trial 19] Epoch 30/100\n",
      "[Trial 19] Epoch 31/100\n",
      "[Trial 19] Epoch 32/100\n",
      "[Trial 19] Epoch 33/100\n",
      "[Trial 19] Epoch 34/100\n",
      "[Trial 19] Epoch 35/100\n",
      "[Trial 19] Epoch 36/100\n",
      "[Trial 19] Epoch 37/100\n",
      "[Trial 19] Epoch 38/100\n",
      "[Trial 19] Epoch 39/100\n",
      "[Trial 19] Epoch 40/100\n",
      "[Trial 19] Epoch 41/100\n",
      "[Trial 19] Epoch 42/100\n",
      "[Trial 19] Epoch 43/100\n",
      "[Trial 19] Epoch 44/100\n",
      "[Trial 19] Epoch 45/100\n",
      "[Trial 19] Epoch 46/100\n",
      "[Trial 19] Epoch 47/100\n",
      "[Trial 19] Epoch 48/100\n",
      "[Trial 19] Epoch 49/100\n",
      "[Trial 19] Epoch 50/100\n",
      "[Trial 19] Epoch 51/100\n",
      "[Trial 19] Epoch 52/100\n",
      "[Trial 19] Epoch 53/100\n",
      "[Trial 19] Epoch 54/100\n",
      "[Trial 19] Epoch 55/100\n",
      "[Trial 19] Epoch 56/100\n",
      "[Trial 19] Epoch 57/100\n",
      "[Trial 19] Epoch 58/100\n",
      "[Trial 19] Epoch 59/100\n",
      "[Trial 19] Epoch 60/100\n",
      "[Trial 19] Epoch 61/100\n",
      "[Trial 19] Epoch 62/100\n",
      "[Trial 19] Epoch 63/100\n",
      "[Trial 19] Epoch 64/100\n",
      "[Trial 19] Epoch 65/100\n",
      "[Trial 19] Epoch 66/100\n",
      "[Trial 19] Epoch 67/100\n",
      "[Trial 19] Epoch 68/100\n",
      "[Trial 19] Epoch 69/100\n",
      "[Trial 19] Epoch 70/100\n",
      "[Trial 19] Epoch 71/100\n",
      "[Trial 19] Epoch 72/100\n",
      "[Trial 19] Epoch 73/100\n",
      "[Trial 19] Epoch 74/100\n",
      "[Trial 19] Epoch 75/100\n",
      "[Trial 19] Epoch 76/100\n",
      "[Trial 19] Epoch 77/100\n",
      "[Trial 19] Epoch 78/100\n",
      "[Trial 19] Epoch 79/100\n",
      "[Trial 19] Epoch 80/100\n",
      "[Trial 19] Epoch 81/100\n",
      "[Trial 19] Epoch 82/100\n",
      "[Trial 19] Epoch 83/100\n",
      "[Trial 19] Epoch 84/100\n",
      "[Trial 19] Epoch 85/100\n",
      "[Trial 19] Epoch 86/100\n",
      "[Trial 19] Epoch 87/100\n",
      "[Trial 19] Epoch 88/100\n",
      "[Trial 19] Epoch 89/100\n",
      "[Trial 19] Epoch 90/100\n",
      "[Trial 19] Epoch 91/100\n",
      "[Trial 19] Epoch 92/100\n",
      "[Trial 19] Epoch 93/100\n",
      "[Trial 19] Epoch 94/100\n",
      "[Trial 19] Epoch 95/100\n",
      "[Trial 19] Epoch 96/100\n",
      "[Trial 19] Epoch 97/100\n",
      "[Trial 19] Epoch 98/100\n",
      "[Trial 19] Epoch 99/100\n",
      "[Trial 19] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.00206897:  20%|██        | 20/100 [3:12:55<22:37:48, 1018.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 19\n",
      "[I 2025-08-07 13:26:45,672] Trial 19 finished with value: 0.002068971560220234 and parameters: {'LEARNING_RATE': 0.05, 'BATCH_SIZE': 64, 'HIDDEN_SIZE': 30, 'OPERATOR_SIZE': 20, 'LR_SCHEDULER_GAMMA': 0.9634214105134553, 'DECAY_EPOCH': 445}. Best is trial 19 with value: 0.002068971560220234.\n",
      "→ Start trial 20\n",
      "[Trial 20] Epoch 1/100\n",
      "[Trial 20] Epoch 2/100\n",
      "[Trial 20] Epoch 3/100\n",
      "[Trial 20] Epoch 4/100\n",
      "[Trial 20] Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.00206897:  21%|██        | 21/100 [3:14:43<16:21:05, 745.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 13:28:33,772] Trial 20 pruned. \n",
      "→ Start trial 21\n",
      "[Trial 21] Epoch 1/100\n",
      "[Trial 21] Epoch 2/100\n",
      "[Trial 21] Epoch 3/100\n",
      "[Trial 21] Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.00206897:  22%|██▏       | 22/100 [3:16:09<11:51:22, 547.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 13:29:59,432] Trial 21 pruned. \n",
      "→ Start trial 22\n",
      "[Trial 22] Epoch 1/100\n",
      "[Trial 22] Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.00206897:  23%|██▎       | 23/100 [3:16:34<8:21:08, 390.49s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 13:30:24,396] Trial 22 pruned. \n",
      "→ Start trial 23\n",
      "[Trial 23] Epoch 1/100\n",
      "[Trial 23] Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.00206897:  24%|██▍       | 24/100 [3:17:20<6:03:48, 287.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 13:31:10,685] Trial 23 pruned. \n",
      "→ Start trial 24\n",
      "[Trial 24] Epoch 1/100\n",
      "[Trial 24] Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.00206897:  25%|██▌       | 25/100 [3:17:47<4:21:14, 208.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 13:31:37,181] Trial 24 pruned. \n",
      "→ Start trial 25\n",
      "[Trial 25] Epoch 1/100\n",
      "[Trial 25] Epoch 2/100\n",
      "[Trial 25] Epoch 3/100\n",
      "[Trial 25] Epoch 4/100\n",
      "[Trial 25] Epoch 5/100\n",
      "[Trial 25] Epoch 6/100\n",
      "[Trial 25] Epoch 7/100\n",
      "[Trial 25] Epoch 8/100\n",
      "[Trial 25] Epoch 9/100\n",
      "[Trial 25] Epoch 10/100\n",
      "[Trial 25] Epoch 11/100\n",
      "[Trial 25] Epoch 12/100\n",
      "[Trial 25] Epoch 13/100\n",
      "[Trial 25] Epoch 14/100\n",
      "[Trial 25] Epoch 15/100\n",
      "[Trial 25] Epoch 16/100\n",
      "[Trial 25] Epoch 17/100\n",
      "[Trial 25] Epoch 18/100\n",
      "[Trial 25] Epoch 19/100\n",
      "[Trial 25] Epoch 20/100\n",
      "[Trial 25] Epoch 21/100\n",
      "[Trial 25] Epoch 22/100\n",
      "[Trial 25] Epoch 23/100\n",
      "[Trial 25] Epoch 24/100\n",
      "[Trial 25] Epoch 25/100\n",
      "[Trial 25] Epoch 26/100\n",
      "[Trial 25] Epoch 27/100\n",
      "[Trial 25] Epoch 28/100\n",
      "[Trial 25] Epoch 29/100\n",
      "[Trial 25] Epoch 30/100\n",
      "[Trial 25] Epoch 31/100\n",
      "[Trial 25] Epoch 32/100\n",
      "[Trial 25] Epoch 33/100\n",
      "[Trial 25] Epoch 34/100\n",
      "[Trial 25] Epoch 35/100\n",
      "[Trial 25] Epoch 36/100\n",
      "[Trial 25] Epoch 37/100\n",
      "[Trial 25] Epoch 38/100\n",
      "[Trial 25] Epoch 39/100\n",
      "[Trial 25] Epoch 40/100\n",
      "[Trial 25] Epoch 41/100\n",
      "[Trial 25] Epoch 42/100\n",
      "[Trial 25] Epoch 43/100\n",
      "[Trial 25] Epoch 44/100\n",
      "[Trial 25] Epoch 45/100\n",
      "[Trial 25] Epoch 46/100\n",
      "[Trial 25] Epoch 47/100\n",
      "[Trial 25] Epoch 48/100\n",
      "[Trial 25] Epoch 49/100\n",
      "[Trial 25] Epoch 50/100\n",
      "[Trial 25] Epoch 51/100\n",
      "[Trial 25] Epoch 52/100\n",
      "[Trial 25] Epoch 53/100\n",
      "[Trial 25] Epoch 54/100\n",
      "[Trial 25] Epoch 55/100\n",
      "[Trial 25] Epoch 56/100\n",
      "[Trial 25] Epoch 57/100\n",
      "[Trial 25] Epoch 58/100\n",
      "[Trial 25] Epoch 59/100\n",
      "[Trial 25] Epoch 60/100\n",
      "[Trial 25] Epoch 61/100\n",
      "[Trial 25] Epoch 62/100\n",
      "[Trial 25] Epoch 63/100\n",
      "[Trial 25] Epoch 64/100\n",
      "[Trial 25] Epoch 65/100\n",
      "[Trial 25] Epoch 66/100\n",
      "[Trial 25] Epoch 67/100\n",
      "[Trial 25] Epoch 68/100\n",
      "[Trial 25] Epoch 69/100\n",
      "[Trial 25] Epoch 70/100\n",
      "[Trial 25] Epoch 71/100\n",
      "[Trial 25] Epoch 72/100\n",
      "[Trial 25] Epoch 73/100\n",
      "[Trial 25] Epoch 74/100\n",
      "[Trial 25] Epoch 75/100\n",
      "[Trial 25] Epoch 76/100\n",
      "[Trial 25] Epoch 77/100\n",
      "[Trial 25] Epoch 78/100\n",
      "[Trial 25] Epoch 79/100\n",
      "[Trial 25] Epoch 80/100\n",
      "[Trial 25] Epoch 81/100\n",
      "[Trial 25] Epoch 82/100\n",
      "[Trial 25] Epoch 83/100\n",
      "[Trial 25] Epoch 84/100\n",
      "[Trial 25] Epoch 85/100\n",
      "[Trial 25] Epoch 86/100\n",
      "[Trial 25] Epoch 87/100\n",
      "[Trial 25] Epoch 88/100\n",
      "[Trial 25] Epoch 89/100\n",
      "[Trial 25] Epoch 90/100\n",
      "[Trial 25] Epoch 91/100\n",
      "[Trial 25] Epoch 92/100\n",
      "[Trial 25] Epoch 93/100\n",
      "[Trial 25] Epoch 94/100\n",
      "[Trial 25] Epoch 95/100\n",
      "[Trial 25] Epoch 96/100\n",
      "[Trial 25] Epoch 97/100\n",
      "[Trial 25] Epoch 98/100\n",
      "[Trial 25] Epoch 99/100\n",
      "[Trial 25] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.00206897:  26%|██▌       | 26/100 [3:52:39<15:54:38, 774.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 25\n",
      "[I 2025-08-07 14:06:29,490] Trial 25 finished with value: 0.0024821310362312943 and parameters: {'LEARNING_RATE': 0.05, 'BATCH_SIZE': 64, 'HIDDEN_SIZE': 30, 'OPERATOR_SIZE': 30, 'LR_SCHEDULER_GAMMA': 0.9692377260945819, 'DECAY_EPOCH': 455}. Best is trial 19 with value: 0.002068971560220234.\n",
      "→ Start trial 26\n",
      "[Trial 26] Epoch 1/100\n",
      "[Trial 26] Epoch 2/100\n",
      "[Trial 26] Epoch 3/100\n",
      "[Trial 26] Epoch 4/100\n",
      "[Trial 26] Epoch 5/100\n",
      "[Trial 26] Epoch 6/100\n",
      "[Trial 26] Epoch 7/100\n",
      "[Trial 26] Epoch 8/100\n",
      "[Trial 26] Epoch 9/100\n",
      "[Trial 26] Epoch 10/100\n",
      "[Trial 26] Epoch 11/100\n",
      "[Trial 26] Epoch 12/100\n",
      "[Trial 26] Epoch 13/100\n",
      "[Trial 26] Epoch 14/100\n",
      "[Trial 26] Epoch 15/100\n",
      "[Trial 26] Epoch 16/100\n",
      "[Trial 26] Epoch 17/100\n",
      "[Trial 26] Epoch 18/100\n",
      "[Trial 26] Epoch 19/100\n",
      "[Trial 26] Epoch 20/100\n",
      "[Trial 26] Epoch 21/100\n",
      "[Trial 26] Epoch 22/100\n",
      "[Trial 26] Epoch 23/100\n",
      "[Trial 26] Epoch 24/100\n",
      "[Trial 26] Epoch 25/100\n",
      "[Trial 26] Epoch 26/100\n",
      "[Trial 26] Epoch 27/100\n",
      "[Trial 26] Epoch 28/100\n",
      "[Trial 26] Epoch 29/100\n",
      "[Trial 26] Epoch 30/100\n",
      "[Trial 26] Epoch 31/100\n",
      "[Trial 26] Epoch 32/100\n",
      "[Trial 26] Epoch 33/100\n",
      "[Trial 26] Epoch 34/100\n",
      "[Trial 26] Epoch 35/100\n",
      "[Trial 26] Epoch 36/100\n",
      "[Trial 26] Epoch 37/100\n",
      "[Trial 26] Epoch 38/100\n",
      "[Trial 26] Epoch 39/100\n",
      "[Trial 26] Epoch 40/100\n",
      "[Trial 26] Epoch 41/100\n",
      "[Trial 26] Epoch 42/100\n",
      "[Trial 26] Epoch 43/100\n",
      "[Trial 26] Epoch 44/100\n",
      "[Trial 26] Epoch 45/100\n",
      "[Trial 26] Epoch 46/100\n",
      "[Trial 26] Epoch 47/100\n",
      "[Trial 26] Epoch 48/100\n",
      "[Trial 26] Epoch 49/100\n",
      "[Trial 26] Epoch 50/100\n",
      "[Trial 26] Epoch 51/100\n",
      "[Trial 26] Epoch 52/100\n",
      "[Trial 26] Epoch 53/100\n",
      "[Trial 26] Epoch 54/100\n",
      "[Trial 26] Epoch 55/100\n",
      "[Trial 26] Epoch 56/100\n",
      "[Trial 26] Epoch 57/100\n",
      "[Trial 26] Epoch 58/100\n",
      "[Trial 26] Epoch 59/100\n",
      "[Trial 26] Epoch 60/100\n",
      "[Trial 26] Epoch 61/100\n",
      "[Trial 26] Epoch 62/100\n",
      "[Trial 26] Epoch 63/100\n",
      "[Trial 26] Epoch 64/100\n",
      "[Trial 26] Epoch 65/100\n",
      "[Trial 26] Epoch 66/100\n",
      "[Trial 26] Epoch 67/100\n",
      "[Trial 26] Epoch 68/100\n",
      "[Trial 26] Epoch 69/100\n",
      "[Trial 26] Epoch 70/100\n",
      "[Trial 26] Epoch 71/100\n",
      "[Trial 26] Epoch 72/100\n",
      "[Trial 26] Epoch 73/100\n",
      "[Trial 26] Epoch 74/100\n",
      "[Trial 26] Epoch 75/100\n",
      "[Trial 26] Epoch 76/100\n",
      "[Trial 26] Epoch 77/100\n",
      "[Trial 26] Epoch 78/100\n",
      "[Trial 26] Epoch 79/100\n",
      "[Trial 26] Epoch 80/100\n",
      "[Trial 26] Epoch 81/100\n",
      "[Trial 26] Epoch 82/100\n",
      "[Trial 26] Epoch 83/100\n",
      "[Trial 26] Epoch 84/100\n",
      "[Trial 26] Epoch 85/100\n",
      "[Trial 26] Epoch 86/100\n",
      "[Trial 26] Epoch 87/100\n",
      "[Trial 26] Epoch 88/100\n",
      "[Trial 26] Epoch 89/100\n",
      "[Trial 26] Epoch 90/100\n",
      "[Trial 26] Epoch 91/100\n",
      "[Trial 26] Epoch 92/100\n",
      "[Trial 26] Epoch 93/100\n",
      "[Trial 26] Epoch 94/100\n",
      "[Trial 26] Epoch 95/100\n",
      "[Trial 26] Epoch 96/100\n",
      "[Trial 26] Epoch 97/100\n",
      "[Trial 26] Epoch 98/100\n",
      "[Trial 26] Epoch 99/100\n",
      "[Trial 26] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.00206897:  27%|██▋       | 27/100 [4:26:02<23:10:12, 1142.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 26\n",
      "[I 2025-08-07 14:39:52,115] Trial 26 finished with value: 0.002936861346825026 and parameters: {'LEARNING_RATE': 0.05, 'BATCH_SIZE': 64, 'HIDDEN_SIZE': 20, 'OPERATOR_SIZE': 30, 'LR_SCHEDULER_GAMMA': 0.9695108280746063, 'DECAY_EPOCH': 418}. Best is trial 19 with value: 0.002068971560220234.\n",
      "→ Start trial 27\n",
      "[Trial 27] Epoch 1/100\n",
      "[Trial 27] Epoch 2/100\n",
      "[Trial 27] Epoch 3/100\n",
      "[Trial 27] Epoch 4/100\n",
      "[Trial 27] Epoch 5/100\n",
      "[Trial 27] Epoch 6/100\n",
      "[Trial 27] Epoch 7/100\n",
      "[Trial 27] Epoch 8/100\n",
      "[Trial 27] Epoch 9/100\n",
      "[Trial 27] Epoch 10/100\n",
      "[Trial 27] Epoch 11/100\n",
      "[Trial 27] Epoch 12/100\n",
      "[Trial 27] Epoch 13/100\n",
      "[Trial 27] Epoch 14/100\n",
      "[Trial 27] Epoch 15/100\n",
      "[Trial 27] Epoch 16/100\n",
      "[Trial 27] Epoch 17/100\n",
      "[Trial 27] Epoch 18/100\n",
      "[Trial 27] Epoch 19/100\n",
      "[Trial 27] Epoch 20/100\n",
      "[Trial 27] Epoch 21/100\n",
      "[Trial 27] Epoch 22/100\n",
      "[Trial 27] Epoch 23/100\n",
      "[Trial 27] Epoch 24/100\n",
      "[Trial 27] Epoch 25/100\n",
      "[Trial 27] Epoch 26/100\n",
      "[Trial 27] Epoch 27/100\n",
      "[Trial 27] Epoch 28/100\n",
      "[Trial 27] Epoch 29/100\n",
      "[Trial 27] Epoch 30/100\n",
      "[Trial 27] Epoch 31/100\n",
      "[Trial 27] Epoch 32/100\n",
      "[Trial 27] Epoch 33/100\n",
      "[Trial 27] Epoch 34/100\n",
      "[Trial 27] Epoch 35/100\n",
      "[Trial 27] Epoch 36/100\n",
      "[Trial 27] Epoch 37/100\n",
      "[Trial 27] Epoch 38/100\n",
      "[Trial 27] Epoch 39/100\n",
      "[Trial 27] Epoch 40/100\n",
      "[Trial 27] Epoch 41/100\n",
      "[Trial 27] Epoch 42/100\n",
      "[Trial 27] Epoch 43/100\n",
      "[Trial 27] Epoch 44/100\n",
      "[Trial 27] Epoch 45/100\n",
      "[Trial 27] Epoch 46/100\n",
      "[Trial 27] Epoch 47/100\n",
      "[Trial 27] Epoch 48/100\n",
      "[Trial 27] Epoch 49/100\n",
      "[Trial 27] Epoch 50/100\n",
      "[Trial 27] Epoch 51/100\n",
      "[Trial 27] Epoch 52/100\n",
      "[Trial 27] Epoch 53/100\n",
      "[Trial 27] Epoch 54/100\n",
      "[Trial 27] Epoch 55/100\n",
      "[Trial 27] Epoch 56/100\n",
      "[Trial 27] Epoch 57/100\n",
      "[Trial 27] Epoch 58/100\n",
      "[Trial 27] Epoch 59/100\n",
      "[Trial 27] Epoch 60/100\n",
      "[Trial 27] Epoch 61/100\n",
      "[Trial 27] Epoch 62/100\n",
      "[Trial 27] Epoch 63/100\n",
      "[Trial 27] Epoch 64/100\n",
      "[Trial 27] Epoch 65/100\n",
      "[Trial 27] Epoch 66/100\n",
      "[Trial 27] Epoch 67/100\n",
      "[Trial 27] Epoch 68/100\n",
      "[Trial 27] Epoch 69/100\n",
      "[Trial 27] Epoch 70/100\n",
      "[Trial 27] Epoch 71/100\n",
      "[Trial 27] Epoch 72/100\n",
      "[Trial 27] Epoch 73/100\n",
      "[Trial 27] Epoch 74/100\n",
      "[Trial 27] Epoch 75/100\n",
      "[Trial 27] Epoch 76/100\n",
      "[Trial 27] Epoch 77/100\n",
      "[Trial 27] Epoch 78/100\n",
      "[Trial 27] Epoch 79/100\n",
      "[Trial 27] Epoch 80/100\n",
      "[Trial 27] Epoch 81/100\n",
      "[Trial 27] Epoch 82/100\n",
      "[Trial 27] Epoch 83/100\n",
      "[Trial 27] Epoch 84/100\n",
      "[Trial 27] Epoch 85/100\n",
      "[Trial 27] Epoch 86/100\n",
      "[Trial 27] Epoch 87/100\n",
      "[Trial 27] Epoch 88/100\n",
      "[Trial 27] Epoch 89/100\n",
      "[Trial 27] Epoch 90/100\n",
      "[Trial 27] Epoch 91/100\n",
      "[Trial 27] Epoch 92/100\n",
      "[Trial 27] Epoch 93/100\n",
      "[Trial 27] Epoch 94/100\n",
      "[Trial 27] Epoch 95/100\n",
      "[Trial 27] Epoch 96/100\n",
      "[Trial 27] Epoch 97/100\n",
      "[Trial 27] Epoch 98/100\n",
      "[Trial 27] Epoch 99/100\n",
      "[Trial 27] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.00206897:  28%|██▊       | 28/100 [4:58:15<27:35:46, 1379.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 27\n",
      "[I 2025-08-07 15:12:05,309] Trial 27 finished with value: 0.0027335997147019953 and parameters: {'LEARNING_RATE': 0.05, 'BATCH_SIZE': 64, 'HIDDEN_SIZE': 30, 'OPERATOR_SIZE': 30, 'LR_SCHEDULER_GAMMA': 0.9762516279417551, 'DECAY_EPOCH': 329}. Best is trial 19 with value: 0.002068971560220234.\n",
      "→ Start trial 28\n",
      "[Trial 28] Epoch 1/100\n",
      "[Trial 28] Epoch 2/100\n",
      "[Trial 28] Epoch 3/100\n",
      "[Trial 28] Epoch 4/100\n",
      "[Trial 28] Epoch 5/100\n",
      "[Trial 28] Epoch 6/100\n",
      "[Trial 28] Epoch 7/100\n",
      "[Trial 28] Epoch 8/100\n",
      "[Trial 28] Epoch 9/100\n",
      "[Trial 28] Epoch 10/100\n",
      "[Trial 28] Epoch 11/100\n",
      "[Trial 28] Epoch 12/100\n",
      "[Trial 28] Epoch 13/100\n",
      "[Trial 28] Epoch 14/100\n",
      "[Trial 28] Epoch 15/100\n",
      "[Trial 28] Epoch 16/100\n",
      "[Trial 28] Epoch 17/100\n",
      "[Trial 28] Epoch 18/100\n",
      "[Trial 28] Epoch 19/100\n",
      "[Trial 28] Epoch 20/100\n",
      "[Trial 28] Epoch 21/100\n",
      "[Trial 28] Epoch 22/100\n",
      "[Trial 28] Epoch 23/100\n",
      "[Trial 28] Epoch 24/100\n",
      "[Trial 28] Epoch 25/100\n",
      "[Trial 28] Epoch 26/100\n",
      "[Trial 28] Epoch 27/100\n",
      "[Trial 28] Epoch 28/100\n",
      "[Trial 28] Epoch 29/100\n",
      "[Trial 28] Epoch 30/100\n",
      "[Trial 28] Epoch 31/100\n",
      "[Trial 28] Epoch 32/100\n",
      "[Trial 28] Epoch 33/100\n",
      "[Trial 28] Epoch 34/100\n",
      "[Trial 28] Epoch 35/100\n",
      "[Trial 28] Epoch 36/100\n",
      "[Trial 28] Epoch 37/100\n",
      "[Trial 28] Epoch 38/100\n",
      "[Trial 28] Epoch 39/100\n",
      "[Trial 28] Epoch 40/100\n",
      "[Trial 28] Epoch 41/100\n",
      "[Trial 28] Epoch 42/100\n",
      "[Trial 28] Epoch 43/100\n",
      "[Trial 28] Epoch 44/100\n",
      "[Trial 28] Epoch 45/100\n",
      "[Trial 28] Epoch 46/100\n",
      "[Trial 28] Epoch 47/100\n",
      "[Trial 28] Epoch 48/100\n",
      "[Trial 28] Epoch 49/100\n",
      "[Trial 28] Epoch 50/100\n",
      "[Trial 28] Epoch 51/100\n",
      "[Trial 28] Epoch 52/100\n",
      "[Trial 28] Epoch 53/100\n",
      "[Trial 28] Epoch 54/100\n",
      "[Trial 28] Epoch 55/100\n",
      "[Trial 28] Epoch 56/100\n",
      "[Trial 28] Epoch 57/100\n",
      "[Trial 28] Epoch 58/100\n",
      "[Trial 28] Epoch 59/100\n",
      "[Trial 28] Epoch 60/100\n",
      "[Trial 28] Epoch 61/100\n",
      "[Trial 28] Epoch 62/100\n",
      "[Trial 28] Epoch 63/100\n",
      "[Trial 28] Epoch 64/100\n",
      "[Trial 28] Epoch 65/100\n",
      "[Trial 28] Epoch 66/100\n",
      "[Trial 28] Epoch 67/100\n",
      "[Trial 28] Epoch 68/100\n",
      "[Trial 28] Epoch 69/100\n",
      "[Trial 28] Epoch 70/100\n",
      "[Trial 28] Epoch 71/100\n",
      "[Trial 28] Epoch 72/100\n",
      "[Trial 28] Epoch 73/100\n",
      "[Trial 28] Epoch 74/100\n",
      "[Trial 28] Epoch 75/100\n",
      "[Trial 28] Epoch 76/100\n",
      "[Trial 28] Epoch 77/100\n",
      "[Trial 28] Epoch 78/100\n",
      "[Trial 28] Epoch 79/100\n",
      "[Trial 28] Epoch 80/100\n",
      "[Trial 28] Epoch 81/100\n",
      "[Trial 28] Epoch 82/100\n",
      "[Trial 28] Epoch 83/100\n",
      "[Trial 28] Epoch 84/100\n",
      "[Trial 28] Epoch 85/100\n",
      "[Trial 28] Epoch 86/100\n",
      "[Trial 28] Epoch 87/100\n",
      "[Trial 28] Epoch 88/100\n",
      "[Trial 28] Epoch 89/100\n",
      "[Trial 28] Epoch 90/100\n",
      "[Trial 28] Epoch 91/100\n",
      "[Trial 28] Epoch 92/100\n",
      "[Trial 28] Epoch 93/100\n",
      "[Trial 28] Epoch 94/100\n",
      "[Trial 28] Epoch 95/100\n",
      "[Trial 28] Epoch 96/100\n",
      "[Trial 28] Epoch 97/100\n",
      "[Trial 28] Epoch 98/100\n",
      "[Trial 28] Epoch 99/100\n",
      "[Trial 28] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.00201196:  29%|██▉       | 29/100 [5:30:56<30:39:02, 1554.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 28\n",
      "[I 2025-08-07 15:44:46,099] Trial 28 finished with value: 0.0020119605542276986 and parameters: {'LEARNING_RATE': 0.01, 'BATCH_SIZE': 64, 'HIDDEN_SIZE': 40, 'OPERATOR_SIZE': 30, 'LR_SCHEDULER_GAMMA': 0.9554638635250163, 'DECAY_EPOCH': 379}. Best is trial 28 with value: 0.0020119605542276986.\n",
      "→ Start trial 29\n",
      "[Trial 29] Epoch 1/100\n",
      "[Trial 29] Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.00201196:  30%|███       | 30/100 [5:31:22<21:18:22, 1095.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 15:45:12,357] Trial 29 pruned. \n",
      "→ Start trial 30\n",
      "[Trial 30] Epoch 1/100\n",
      "[Trial 30] Epoch 2/100\n",
      "[Trial 30] Epoch 3/100\n",
      "[Trial 30] Epoch 4/100\n",
      "[Trial 30] Epoch 5/100\n",
      "[Trial 30] Epoch 6/100\n",
      "[Trial 30] Epoch 7/100\n",
      "[Trial 30] Epoch 8/100\n",
      "[Trial 30] Epoch 9/100\n",
      "[Trial 30] Epoch 10/100\n",
      "[Trial 30] Epoch 11/100\n",
      "[Trial 30] Epoch 12/100\n",
      "[Trial 30] Epoch 13/100\n",
      "[Trial 30] Epoch 14/100\n",
      "[Trial 30] Epoch 15/100\n",
      "[Trial 30] Epoch 16/100\n",
      "[Trial 30] Epoch 17/100\n",
      "[Trial 30] Epoch 18/100\n",
      "[Trial 30] Epoch 19/100\n",
      "[Trial 30] Epoch 20/100\n",
      "[Trial 30] Epoch 21/100\n",
      "[Trial 30] Epoch 22/100\n",
      "[Trial 30] Epoch 23/100\n",
      "[Trial 30] Epoch 24/100\n",
      "[Trial 30] Epoch 25/100\n",
      "[Trial 30] Epoch 26/100\n",
      "[Trial 30] Epoch 27/100\n",
      "[Trial 30] Epoch 28/100\n",
      "[Trial 30] Epoch 29/100\n",
      "[Trial 30] Epoch 30/100\n",
      "[Trial 30] Epoch 31/100\n",
      "[Trial 30] Epoch 32/100\n",
      "[Trial 30] Epoch 33/100\n",
      "[Trial 30] Epoch 34/100\n",
      "[Trial 30] Epoch 35/100\n",
      "[Trial 30] Epoch 36/100\n",
      "[Trial 30] Epoch 37/100\n",
      "[Trial 30] Epoch 38/100\n",
      "[Trial 30] Epoch 39/100\n",
      "[Trial 30] Epoch 40/100\n",
      "[Trial 30] Epoch 41/100\n",
      "[Trial 30] Epoch 42/100\n",
      "[Trial 30] Epoch 43/100\n",
      "[Trial 30] Epoch 44/100\n",
      "[Trial 30] Epoch 45/100\n",
      "[Trial 30] Epoch 46/100\n",
      "[Trial 30] Epoch 47/100\n",
      "[Trial 30] Epoch 48/100\n",
      "[Trial 30] Epoch 49/100\n",
      "[Trial 30] Epoch 50/100\n",
      "[Trial 30] Epoch 51/100\n",
      "[Trial 30] Epoch 52/100\n",
      "[Trial 30] Epoch 53/100\n",
      "[Trial 30] Epoch 54/100\n",
      "[Trial 30] Epoch 55/100\n",
      "[Trial 30] Epoch 56/100\n",
      "[Trial 30] Epoch 57/100\n",
      "[Trial 30] Epoch 58/100\n",
      "[Trial 30] Epoch 59/100\n",
      "[Trial 30] Epoch 60/100\n",
      "[Trial 30] Epoch 61/100\n",
      "[Trial 30] Epoch 62/100\n",
      "[Trial 30] Epoch 63/100\n",
      "[Trial 30] Epoch 64/100\n",
      "[Trial 30] Epoch 65/100\n",
      "[Trial 30] Epoch 66/100\n",
      "[Trial 30] Epoch 67/100\n",
      "[Trial 30] Epoch 68/100\n",
      "[Trial 30] Epoch 69/100\n",
      "[Trial 30] Epoch 70/100\n",
      "[Trial 30] Epoch 71/100\n",
      "[Trial 30] Epoch 72/100\n",
      "[Trial 30] Epoch 73/100\n",
      "[Trial 30] Epoch 74/100\n",
      "[Trial 30] Epoch 75/100\n",
      "[Trial 30] Epoch 76/100\n",
      "[Trial 30] Epoch 77/100\n",
      "[Trial 30] Epoch 78/100\n",
      "[Trial 30] Epoch 79/100\n",
      "[Trial 30] Epoch 80/100\n",
      "[Trial 30] Epoch 81/100\n",
      "[Trial 30] Epoch 82/100\n",
      "[Trial 30] Epoch 83/100\n",
      "[Trial 30] Epoch 84/100\n",
      "[Trial 30] Epoch 85/100\n",
      "[Trial 30] Epoch 86/100\n",
      "[Trial 30] Epoch 87/100\n",
      "[Trial 30] Epoch 88/100\n",
      "[Trial 30] Epoch 89/100\n",
      "[Trial 30] Epoch 90/100\n",
      "[Trial 30] Epoch 91/100\n",
      "[Trial 30] Epoch 92/100\n",
      "[Trial 30] Epoch 93/100\n",
      "[Trial 30] Epoch 94/100\n",
      "[Trial 30] Epoch 95/100\n",
      "[Trial 30] Epoch 96/100\n",
      "[Trial 30] Epoch 97/100\n",
      "[Trial 30] Epoch 98/100\n",
      "[Trial 30] Epoch 99/100\n",
      "[Trial 30] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  31%|███       | 31/100 [6:04:21<26:04:55, 1360.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 30\n",
      "[I 2025-08-07 16:18:11,623] Trial 30 finished with value: 0.0016703194560250267 and parameters: {'LEARNING_RATE': 0.01, 'BATCH_SIZE': 64, 'HIDDEN_SIZE': 40, 'OPERATOR_SIZE': 40, 'LR_SCHEDULER_GAMMA': 0.9545861499908413, 'DECAY_EPOCH': 379}. Best is trial 30 with value: 0.0016703194560250267.\n",
      "→ Start trial 31\n",
      "[Trial 31] Epoch 1/100\n",
      "[Trial 31] Epoch 2/100\n",
      "[Trial 31] Epoch 3/100\n",
      "[Trial 31] Epoch 4/100\n",
      "[Trial 31] Epoch 5/100\n",
      "[Trial 31] Epoch 6/100\n",
      "[Trial 31] Epoch 7/100\n",
      "[Trial 31] Epoch 8/100\n",
      "[Trial 31] Epoch 9/100\n",
      "[Trial 31] Epoch 10/100\n",
      "[Trial 31] Epoch 11/100\n",
      "[Trial 31] Epoch 12/100\n",
      "[Trial 31] Epoch 13/100\n",
      "[Trial 31] Epoch 14/100\n",
      "[Trial 31] Epoch 15/100\n",
      "[Trial 31] Epoch 16/100\n",
      "[Trial 31] Epoch 17/100\n",
      "[Trial 31] Epoch 18/100\n",
      "[Trial 31] Epoch 19/100\n",
      "[Trial 31] Epoch 20/100\n",
      "[Trial 31] Epoch 21/100\n",
      "[Trial 31] Epoch 22/100\n",
      "[Trial 31] Epoch 23/100\n",
      "[Trial 31] Epoch 24/100\n",
      "[Trial 31] Epoch 25/100\n",
      "[Trial 31] Epoch 26/100\n",
      "[Trial 31] Epoch 27/100\n",
      "[Trial 31] Epoch 28/100\n",
      "[Trial 31] Epoch 29/100\n",
      "[Trial 31] Epoch 30/100\n",
      "[Trial 31] Epoch 31/100\n",
      "[Trial 31] Epoch 32/100\n",
      "[Trial 31] Epoch 33/100\n",
      "[Trial 31] Epoch 34/100\n",
      "[Trial 31] Epoch 35/100\n",
      "[Trial 31] Epoch 36/100\n",
      "[Trial 31] Epoch 37/100\n",
      "[Trial 31] Epoch 38/100\n",
      "[Trial 31] Epoch 39/100\n",
      "[Trial 31] Epoch 40/100\n",
      "[Trial 31] Epoch 41/100\n",
      "[Trial 31] Epoch 42/100\n",
      "[Trial 31] Epoch 43/100\n",
      "[Trial 31] Epoch 44/100\n",
      "[Trial 31] Epoch 45/100\n",
      "[Trial 31] Epoch 46/100\n",
      "[Trial 31] Epoch 47/100\n",
      "[Trial 31] Epoch 48/100\n",
      "[Trial 31] Epoch 49/100\n",
      "[Trial 31] Epoch 50/100\n",
      "[Trial 31] Epoch 51/100\n",
      "[Trial 31] Epoch 52/100\n",
      "[Trial 31] Epoch 53/100\n",
      "[Trial 31] Epoch 54/100\n",
      "[Trial 31] Epoch 55/100\n",
      "[Trial 31] Epoch 56/100\n",
      "[Trial 31] Epoch 57/100\n",
      "[Trial 31] Epoch 58/100\n",
      "[Trial 31] Epoch 59/100\n",
      "[Trial 31] Epoch 60/100\n",
      "[Trial 31] Epoch 61/100\n",
      "[Trial 31] Epoch 62/100\n",
      "[Trial 31] Epoch 63/100\n",
      "[Trial 31] Epoch 64/100\n",
      "[Trial 31] Epoch 65/100\n",
      "[Trial 31] Epoch 66/100\n",
      "[Trial 31] Epoch 67/100\n",
      "[Trial 31] Epoch 68/100\n",
      "[Trial 31] Epoch 69/100\n",
      "[Trial 31] Epoch 70/100\n",
      "[Trial 31] Epoch 71/100\n",
      "[Trial 31] Epoch 72/100\n",
      "[Trial 31] Epoch 73/100\n",
      "[Trial 31] Epoch 74/100\n",
      "[Trial 31] Epoch 75/100\n",
      "[Trial 31] Epoch 76/100\n",
      "[Trial 31] Epoch 77/100\n",
      "[Trial 31] Epoch 78/100\n",
      "[Trial 31] Epoch 79/100\n",
      "[Trial 31] Epoch 80/100\n",
      "[Trial 31] Epoch 81/100\n",
      "[Trial 31] Epoch 82/100\n",
      "[Trial 31] Epoch 83/100\n",
      "[Trial 31] Epoch 84/100\n",
      "[Trial 31] Epoch 85/100\n",
      "[Trial 31] Epoch 86/100\n",
      "[Trial 31] Epoch 87/100\n",
      "[Trial 31] Epoch 88/100\n",
      "[Trial 31] Epoch 89/100\n",
      "[Trial 31] Epoch 90/100\n",
      "[Trial 31] Epoch 91/100\n",
      "[Trial 31] Epoch 92/100\n",
      "[Trial 31] Epoch 93/100\n",
      "[Trial 31] Epoch 94/100\n",
      "[Trial 31] Epoch 95/100\n",
      "[Trial 31] Epoch 96/100\n",
      "[Trial 31] Epoch 97/100\n",
      "[Trial 31] Epoch 98/100\n",
      "[Trial 31] Epoch 99/100\n",
      "[Trial 31] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  32%|███▏      | 32/100 [6:38:22<29:33:28, 1564.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 31\n",
      "[I 2025-08-07 16:52:12,518] Trial 31 finished with value: 0.0034235340281156823 and parameters: {'LEARNING_RATE': 0.01, 'BATCH_SIZE': 64, 'HIDDEN_SIZE': 40, 'OPERATOR_SIZE': 40, 'LR_SCHEDULER_GAMMA': 0.9543139197286393, 'DECAY_EPOCH': 382}. Best is trial 30 with value: 0.0016703194560250267.\n",
      "→ Start trial 32\n",
      "[Trial 32] Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  33%|███▎      | 33/100 [6:38:50<20:32:30, 1103.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 16:52:40,350] Trial 32 pruned. \n",
      "→ Start trial 33\n",
      "[Trial 33] Epoch 1/100\n",
      "[Trial 33] Epoch 2/100\n",
      "[Trial 33] Epoch 3/100\n",
      "[Trial 33] Epoch 4/100\n",
      "[Trial 33] Epoch 5/100\n",
      "[Trial 33] Epoch 6/100\n",
      "[Trial 33] Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  34%|███▍      | 34/100 [6:40:20<14:39:39, 799.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 16:54:10,602] Trial 33 pruned. \n",
      "→ Start trial 34\n",
      "[Trial 34] Epoch 1/100\n",
      "[Trial 34] Epoch 2/100\n",
      "[Trial 34] Epoch 3/100\n",
      "[Trial 34] Epoch 4/100\n",
      "[Trial 34] Epoch 5/100\n",
      "[Trial 34] Epoch 6/100\n",
      "[Trial 34] Epoch 7/100\n",
      "[Trial 34] Epoch 8/100\n",
      "[Trial 34] Epoch 9/100\n",
      "[Trial 34] Epoch 10/100\n",
      "[Trial 34] Epoch 11/100\n",
      "[Trial 34] Epoch 12/100\n",
      "[Trial 34] Epoch 13/100\n",
      "[Trial 34] Epoch 14/100\n",
      "[Trial 34] Epoch 15/100\n",
      "[Trial 34] Epoch 16/100\n",
      "[Trial 34] Epoch 17/100\n",
      "[Trial 34] Epoch 18/100\n",
      "[Trial 34] Epoch 19/100\n",
      "[Trial 34] Epoch 20/100\n",
      "[Trial 34] Epoch 21/100\n",
      "[Trial 34] Epoch 22/100\n",
      "[Trial 34] Epoch 23/100\n",
      "[Trial 34] Epoch 24/100\n",
      "[Trial 34] Epoch 25/100\n",
      "[Trial 34] Epoch 26/100\n",
      "[Trial 34] Epoch 27/100\n",
      "[Trial 34] Epoch 28/100\n",
      "[Trial 34] Epoch 29/100\n",
      "[Trial 34] Epoch 30/100\n",
      "[Trial 34] Epoch 31/100\n",
      "[Trial 34] Epoch 32/100\n",
      "[Trial 34] Epoch 33/100\n",
      "[Trial 34] Epoch 34/100\n",
      "[Trial 34] Epoch 35/100\n",
      "[Trial 34] Epoch 36/100\n",
      "[Trial 34] Epoch 37/100\n",
      "[Trial 34] Epoch 38/100\n",
      "[Trial 34] Epoch 39/100\n",
      "[Trial 34] Epoch 40/100\n",
      "[Trial 34] Epoch 41/100\n",
      "[Trial 34] Epoch 42/100\n",
      "[Trial 34] Epoch 43/100\n",
      "[Trial 34] Epoch 44/100\n",
      "[Trial 34] Epoch 45/100\n",
      "[Trial 34] Epoch 46/100\n",
      "[Trial 34] Epoch 47/100\n",
      "[Trial 34] Epoch 48/100\n",
      "[Trial 34] Epoch 49/100\n",
      "[Trial 34] Epoch 50/100\n",
      "[Trial 34] Epoch 51/100\n",
      "[Trial 34] Epoch 52/100\n",
      "[Trial 34] Epoch 53/100\n",
      "[Trial 34] Epoch 54/100\n",
      "[Trial 34] Epoch 55/100\n",
      "[Trial 34] Epoch 56/100\n",
      "[Trial 34] Epoch 57/100\n",
      "[Trial 34] Epoch 58/100\n",
      "[Trial 34] Epoch 59/100\n",
      "[Trial 34] Epoch 60/100\n",
      "[Trial 34] Epoch 61/100\n",
      "[Trial 34] Epoch 62/100\n",
      "[Trial 34] Epoch 63/100\n",
      "[Trial 34] Epoch 64/100\n",
      "[Trial 34] Epoch 65/100\n",
      "[Trial 34] Epoch 66/100\n",
      "[Trial 34] Epoch 67/100\n",
      "[Trial 34] Epoch 68/100\n",
      "[Trial 34] Epoch 69/100\n",
      "[Trial 34] Epoch 70/100\n",
      "[Trial 34] Epoch 71/100\n",
      "[Trial 34] Epoch 72/100\n",
      "[Trial 34] Epoch 73/100\n",
      "[Trial 34] Epoch 74/100\n",
      "[Trial 34] Epoch 75/100\n",
      "[Trial 34] Epoch 76/100\n",
      "[Trial 34] Epoch 77/100\n",
      "[Trial 34] Epoch 78/100\n",
      "[Trial 34] Epoch 79/100\n",
      "[Trial 34] Epoch 80/100\n",
      "[Trial 34] Epoch 81/100\n",
      "[Trial 34] Epoch 82/100\n",
      "[Trial 34] Epoch 83/100\n",
      "[Trial 34] Epoch 84/100\n",
      "[Trial 34] Epoch 85/100\n",
      "[Trial 34] Epoch 86/100\n",
      "[Trial 34] Epoch 87/100\n",
      "[Trial 34] Epoch 88/100\n",
      "[Trial 34] Epoch 89/100\n",
      "[Trial 34] Epoch 90/100\n",
      "[Trial 34] Epoch 91/100\n",
      "[Trial 34] Epoch 92/100\n",
      "[Trial 34] Epoch 93/100\n",
      "[Trial 34] Epoch 94/100\n",
      "[Trial 34] Epoch 95/100\n",
      "[Trial 34] Epoch 96/100\n",
      "[Trial 34] Epoch 97/100\n",
      "[Trial 34] Epoch 98/100\n",
      "[Trial 34] Epoch 99/100\n",
      "[Trial 34] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  35%|███▌      | 35/100 [7:21:38<23:31:44, 1303.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 34\n",
      "[I 2025-08-07 17:35:28,471] Trial 34 finished with value: 0.0024500715007889085 and parameters: {'LEARNING_RATE': 0.01, 'BATCH_SIZE': 64, 'HIDDEN_SIZE': 40, 'OPERATOR_SIZE': 30, 'LR_SCHEDULER_GAMMA': 0.9567674027368834, 'DECAY_EPOCH': 477}. Best is trial 30 with value: 0.0016703194560250267.\n",
      "→ Start trial 35\n",
      "[Trial 35] Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  36%|███▌      | 36/100 [7:22:05<16:21:32, 920.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 17:35:55,145] Trial 35 pruned. \n",
      "→ Start trial 36\n",
      "[Trial 36] Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  37%|███▋      | 37/100 [7:22:21<11:21:29, 649.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 17:36:11,484] Trial 36 pruned. \n",
      "→ Start trial 37\n",
      "[Trial 37] Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  38%|███▊      | 38/100 [7:22:31<7:52:32, 457.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 17:36:21,400] Trial 37 pruned. \n",
      "→ Start trial 38\n",
      "[Trial 38] Epoch 1/100\n",
      "[Trial 38] Epoch 2/100\n",
      "[Trial 38] Epoch 3/100\n",
      "[Trial 38] Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  39%|███▉      | 39/100 [7:24:08<5:55:06, 349.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 17:37:58,617] Trial 38 pruned. \n",
      "→ Start trial 39\n",
      "[Trial 39] Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  40%|████      | 40/100 [7:24:25<4:09:26, 249.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 17:38:15,074] Trial 39 pruned. \n",
      "→ Start trial 40\n",
      "[Trial 40] Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  41%|████      | 41/100 [7:24:34<2:54:31, 177.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 17:38:24,658] Trial 40 pruned. \n",
      "→ Start trial 41\n",
      "[Trial 41] Epoch 1/100\n",
      "[Trial 41] Epoch 2/100\n",
      "[Trial 41] Epoch 3/100\n",
      "[Trial 41] Epoch 4/100\n",
      "[Trial 41] Epoch 5/100\n",
      "[Trial 41] Epoch 6/100\n",
      "[Trial 41] Epoch 7/100\n",
      "[Trial 41] Epoch 8/100\n",
      "[Trial 41] Epoch 9/100\n",
      "[Trial 41] Epoch 10/100\n",
      "[Trial 41] Epoch 11/100\n",
      "[Trial 41] Epoch 12/100\n",
      "[Trial 41] Epoch 13/100\n",
      "[Trial 41] Epoch 14/100\n",
      "[Trial 41] Epoch 15/100\n",
      "[Trial 41] Epoch 16/100\n",
      "[Trial 41] Epoch 17/100\n",
      "[Trial 41] Epoch 18/100\n",
      "[Trial 41] Epoch 19/100\n",
      "[Trial 41] Epoch 20/100\n",
      "[Trial 41] Epoch 21/100\n",
      "[Trial 41] Epoch 22/100\n",
      "[Trial 41] Epoch 23/100\n",
      "[Trial 41] Epoch 24/100\n",
      "[Trial 41] Epoch 25/100\n",
      "[Trial 41] Epoch 26/100\n",
      "[Trial 41] Epoch 27/100\n",
      "[Trial 41] Epoch 28/100\n",
      "[Trial 41] Epoch 29/100\n",
      "[Trial 41] Epoch 30/100\n",
      "[Trial 41] Epoch 31/100\n",
      "[Trial 41] Epoch 32/100\n",
      "[Trial 41] Epoch 33/100\n",
      "[Trial 41] Epoch 34/100\n",
      "[Trial 41] Epoch 35/100\n",
      "[Trial 41] Epoch 36/100\n",
      "[Trial 41] Epoch 37/100\n",
      "[Trial 41] Epoch 38/100\n",
      "[Trial 41] Epoch 39/100\n",
      "[Trial 41] Epoch 40/100\n",
      "[Trial 41] Epoch 41/100\n",
      "[Trial 41] Epoch 42/100\n",
      "[Trial 41] Epoch 43/100\n",
      "[Trial 41] Epoch 44/100\n",
      "[Trial 41] Epoch 45/100\n",
      "[Trial 41] Epoch 46/100\n",
      "[Trial 41] Epoch 47/100\n",
      "[Trial 41] Epoch 48/100\n",
      "[Trial 41] Epoch 49/100\n",
      "[Trial 41] Epoch 50/100\n",
      "[Trial 41] Epoch 51/100\n",
      "[Trial 41] Epoch 52/100\n",
      "[Trial 41] Epoch 53/100\n",
      "[Trial 41] Epoch 54/100\n",
      "[Trial 41] Epoch 55/100\n",
      "[Trial 41] Epoch 56/100\n",
      "[Trial 41] Epoch 57/100\n",
      "[Trial 41] Epoch 58/100\n",
      "[Trial 41] Epoch 59/100\n",
      "[Trial 41] Epoch 60/100\n",
      "[Trial 41] Epoch 61/100\n",
      "[Trial 41] Epoch 62/100\n",
      "[Trial 41] Epoch 63/100\n",
      "[Trial 41] Epoch 64/100\n",
      "[Trial 41] Epoch 65/100\n",
      "[Trial 41] Epoch 66/100\n",
      "[Trial 41] Epoch 67/100\n",
      "[Trial 41] Epoch 68/100\n",
      "[Trial 41] Epoch 69/100\n",
      "[Trial 41] Epoch 70/100\n",
      "[Trial 41] Epoch 71/100\n",
      "[Trial 41] Epoch 72/100\n",
      "[Trial 41] Epoch 73/100\n",
      "[Trial 41] Epoch 74/100\n",
      "[Trial 41] Epoch 75/100\n",
      "[Trial 41] Epoch 76/100\n",
      "[Trial 41] Epoch 77/100\n",
      "[Trial 41] Epoch 78/100\n",
      "[Trial 41] Epoch 79/100\n",
      "[Trial 41] Epoch 80/100\n",
      "[Trial 41] Epoch 81/100\n",
      "[Trial 41] Epoch 82/100\n",
      "[Trial 41] Epoch 83/100\n",
      "[Trial 41] Epoch 84/100\n",
      "[Trial 41] Epoch 85/100\n",
      "[Trial 41] Epoch 86/100\n",
      "[Trial 41] Epoch 87/100\n",
      "[Trial 41] Epoch 88/100\n",
      "[Trial 41] Epoch 89/100\n",
      "[Trial 41] Epoch 90/100\n",
      "[Trial 41] Epoch 91/100\n",
      "[Trial 41] Epoch 92/100\n",
      "[Trial 41] Epoch 93/100\n",
      "[Trial 41] Epoch 94/100\n",
      "[Trial 41] Epoch 95/100\n",
      "[Trial 41] Epoch 96/100\n",
      "[Trial 41] Epoch 97/100\n",
      "[Trial 41] Epoch 98/100\n",
      "[Trial 41] Epoch 99/100\n",
      "[Trial 41] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  42%|████▏     | 42/100 [8:06:39<14:12:18, 881.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 41\n",
      "[I 2025-08-07 18:20:29,527] Trial 41 finished with value: 0.0033174399432027712 and parameters: {'LEARNING_RATE': 0.01, 'BATCH_SIZE': 64, 'HIDDEN_SIZE': 40, 'OPERATOR_SIZE': 30, 'LR_SCHEDULER_GAMMA': 0.9561649792601103, 'DECAY_EPOCH': 475}. Best is trial 30 with value: 0.0016703194560250267.\n",
      "→ Start trial 42\n",
      "[Trial 42] Epoch 1/100\n",
      "[Trial 42] Epoch 2/100\n",
      "[Trial 42] Epoch 3/100\n",
      "[Trial 42] Epoch 4/100\n",
      "[Trial 42] Epoch 5/100\n",
      "[Trial 42] Epoch 6/100\n",
      "[Trial 42] Epoch 7/100\n",
      "[Trial 42] Epoch 8/100\n",
      "[Trial 42] Epoch 9/100\n",
      "[Trial 42] Epoch 10/100\n",
      "[Trial 42] Epoch 11/100\n",
      "[Trial 42] Epoch 12/100\n",
      "[Trial 42] Epoch 13/100\n",
      "[Trial 42] Epoch 14/100\n",
      "[Trial 42] Epoch 15/100\n",
      "[Trial 42] Epoch 16/100\n",
      "[Trial 42] Epoch 17/100\n",
      "[Trial 42] Epoch 18/100\n",
      "[Trial 42] Epoch 19/100\n",
      "[Trial 42] Epoch 20/100\n",
      "[Trial 42] Epoch 21/100\n",
      "[Trial 42] Epoch 22/100\n",
      "[Trial 42] Epoch 23/100\n",
      "[Trial 42] Epoch 24/100\n",
      "[Trial 42] Epoch 25/100\n",
      "[Trial 42] Epoch 26/100\n",
      "[Trial 42] Epoch 27/100\n",
      "[Trial 42] Epoch 28/100\n",
      "[Trial 42] Epoch 29/100\n",
      "[Trial 42] Epoch 30/100\n",
      "[Trial 42] Epoch 31/100\n",
      "[Trial 42] Epoch 32/100\n",
      "[Trial 42] Epoch 33/100\n",
      "[Trial 42] Epoch 34/100\n",
      "[Trial 42] Epoch 35/100\n",
      "[Trial 42] Epoch 36/100\n",
      "[Trial 42] Epoch 37/100\n",
      "[Trial 42] Epoch 38/100\n",
      "[Trial 42] Epoch 39/100\n",
      "[Trial 42] Epoch 40/100\n",
      "[Trial 42] Epoch 41/100\n",
      "[Trial 42] Epoch 42/100\n",
      "[Trial 42] Epoch 43/100\n",
      "[Trial 42] Epoch 44/100\n",
      "[Trial 42] Epoch 45/100\n",
      "[Trial 42] Epoch 46/100\n",
      "[Trial 42] Epoch 47/100\n",
      "[Trial 42] Epoch 48/100\n",
      "[Trial 42] Epoch 49/100\n",
      "[Trial 42] Epoch 50/100\n",
      "[Trial 42] Epoch 51/100\n",
      "[Trial 42] Epoch 52/100\n",
      "[Trial 42] Epoch 53/100\n",
      "[Trial 42] Epoch 54/100\n",
      "[Trial 42] Epoch 55/100\n",
      "[Trial 42] Epoch 56/100\n",
      "[Trial 42] Epoch 57/100\n",
      "[Trial 42] Epoch 58/100\n",
      "[Trial 42] Epoch 59/100\n",
      "[Trial 42] Epoch 60/100\n",
      "[Trial 42] Epoch 61/100\n",
      "[Trial 42] Epoch 62/100\n",
      "[Trial 42] Epoch 63/100\n",
      "[Trial 42] Epoch 64/100\n",
      "[Trial 42] Epoch 65/100\n",
      "[Trial 42] Epoch 66/100\n",
      "[Trial 42] Epoch 67/100\n",
      "[Trial 42] Epoch 68/100\n",
      "[Trial 42] Epoch 69/100\n",
      "[Trial 42] Epoch 70/100\n",
      "[Trial 42] Epoch 71/100\n",
      "[Trial 42] Epoch 72/100\n",
      "[Trial 42] Epoch 73/100\n",
      "[Trial 42] Epoch 74/100\n",
      "[Trial 42] Epoch 75/100\n",
      "[Trial 42] Epoch 76/100\n",
      "[Trial 42] Epoch 77/100\n",
      "[Trial 42] Epoch 78/100\n",
      "[Trial 42] Epoch 79/100\n",
      "[Trial 42] Epoch 80/100\n",
      "[Trial 42] Epoch 81/100\n",
      "[Trial 42] Epoch 82/100\n",
      "[Trial 42] Epoch 83/100\n",
      "[Trial 42] Epoch 84/100\n",
      "[Trial 42] Epoch 85/100\n",
      "[Trial 42] Epoch 86/100\n",
      "[Trial 42] Epoch 87/100\n",
      "[Trial 42] Epoch 88/100\n",
      "[Trial 42] Epoch 89/100\n",
      "[Trial 42] Epoch 90/100\n",
      "[Trial 42] Epoch 91/100\n",
      "[Trial 42] Epoch 92/100\n",
      "[Trial 42] Epoch 93/100\n",
      "[Trial 42] Epoch 94/100\n",
      "[Trial 42] Epoch 95/100\n",
      "[Trial 42] Epoch 96/100\n",
      "[Trial 42] Epoch 97/100\n",
      "[Trial 42] Epoch 98/100\n",
      "[Trial 42] Epoch 99/100\n",
      "[Trial 42] Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  43%|████▎     | 43/100 [8:49:32<21:59:32, 1389.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "← End   trial 42\n",
      "[I 2025-08-07 19:03:22,227] Trial 42 finished with value: 0.0029624295493704267 and parameters: {'LEARNING_RATE': 0.01, 'BATCH_SIZE': 64, 'HIDDEN_SIZE': 40, 'OPERATOR_SIZE': 30, 'LR_SCHEDULER_GAMMA': 0.9501228403971864, 'DECAY_EPOCH': 479}. Best is trial 30 with value: 0.0016703194560250267.\n",
      "→ Start trial 43\n",
      "[Trial 43] Epoch 1/100\n",
      "[Trial 43] Epoch 2/100\n",
      "[Trial 43] Epoch 3/100\n",
      "[Trial 43] Epoch 4/100\n",
      "[Trial 43] Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  44%|████▍     | 44/100 [8:51:46<15:45:01, 1012.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 19:05:36,296] Trial 43 pruned. \n",
      "→ Start trial 44\n",
      "[Trial 44] Epoch 1/100\n",
      "[Trial 44] Epoch 2/100\n",
      "[Trial 44] Epoch 3/100\n",
      "[Trial 44] Epoch 4/100\n",
      "[Trial 44] Epoch 5/100\n",
      "[Trial 44] Epoch 6/100\n",
      "[Trial 44] Epoch 7/100\n",
      "[Trial 44] Epoch 8/100\n",
      "[Trial 44] Epoch 9/100\n",
      "[Trial 44] Epoch 10/100\n",
      "[Trial 44] Epoch 11/100\n",
      "[Trial 44] Epoch 12/100\n",
      "[Trial 44] Epoch 13/100\n",
      "[Trial 44] Epoch 14/100\n",
      "[Trial 44] Epoch 15/100\n",
      "[Trial 44] Epoch 16/100\n",
      "[Trial 44] Epoch 17/100\n",
      "[Trial 44] Epoch 18/100\n",
      "[Trial 44] Epoch 19/100\n",
      "[Trial 44] Epoch 20/100\n",
      "[Trial 44] Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.00167032:  44%|████▍     | 44/100 [9:00:30<11:27:55, 737.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-08-07 19:14:20,665] Trial 44 failed with parameters: {'LEARNING_RATE': 0.01, 'BATCH_SIZE': 64, 'HIDDEN_SIZE': 40, 'OPERATOR_SIZE': 30, 'LR_SCHEDULER_GAMMA': 0.9530724321659692, 'DECAY_EPOCH': 467} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch_cu128_pre\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_31080\\4103553183.py\", line 49, in objective\n",
      "    val_loss = train_model(trial, config_dict, norm, train_loader,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_31080\\2026988482.py\", line 77, in train_model\n",
      "    loss.backward()\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch_cu128_pre\\Lib\\site-packages\\torch\\_tensor.py\", line 648, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch_cu128_pre\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\torch_cu128_pre\\Lib\\site-packages\\torch\\autograd\\graph.py\", line 829, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-07 19:14:20,667] Trial 44 failed with value None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# 2. 開始優化\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# n_trials 是你要進行多少次試驗\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m🚀 Starting Optuna optimization for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# 3. 輸出最佳結果\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🎉 Optimization Finished! 🎉\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\torch_cu128_pre\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\torch_cu128_pre\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\torch_cu128_pre\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\torch_cu128_pre\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\torch_cu128_pre\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# --- 3. 執行訓練並取得結果 ---\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     val_loss = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# 有時參數組合不好會導致 CUDA out of memory，這時我們告訴 Optuna 這次試驗失敗\u001b[39;00m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mout of memory\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(trial, config_dict, norm, train_loader, valid_loader)\u001b[39m\n\u001b[32m     74\u001b[39m     loss = (\u001b[32m1\u001b[39m - alpha) * loss_H + alpha * loss_Pcv\n\u001b[32m     75\u001b[39m     \u001b[38;5;66;03m# alpha = 0.5\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m optimizer.step()\n\u001b[32m     79\u001b[39m train_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\torch_cu128_pre\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\torch_cu128_pre\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\torch_cu128_pre\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cu128_pre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
